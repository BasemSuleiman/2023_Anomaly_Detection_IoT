{"cells":[{"cell_type":"markdown","metadata":{"id":"vbV41Z0LqzrD"},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"0hhwV_8iSBQv"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67286,"status":"ok","timestamp":1675498986829,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"nmc7HAfTeHco","outputId":"fe83597b-62e3-4f84-ed53-a993f1bf3341"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["import pandas as pd\n","import datetime\n","import io\n","from google.colab import drive\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error\n","from sklearn import datasets, linear_model\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"markdown","metadata":{"id":"SmacKSYUq22f"},"source":["## Load Federated Learning Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"elapsed":9015,"status":"ok","timestamp":1675499160556,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"cN-6vMa9hZca","outputId":"747b5953-b813-47e9-fb08-0f96ab19c361"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a06bcdef-bb0a-49a6-9f1d-458f6cbcd0aa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>FromInternetUdpPort53IP208.67.220.220/32Packet</th>\n","      <th>FromInternetUdpPort53IP208.67.220.220/32Byte</th>\n","      <th>ToInternetUdpPort53IP208.67.220.220/32Packet</th>\n","      <th>ToInternetUdpPort53IP208.67.220.220/32Byte</th>\n","      <th>FromLocalUdpPort67IP192.168.1.1Packet</th>\n","      <th>FromLocalUdpPort67IP192.168.1.1Byte</th>\n","      <th>FromLocalIcmpPortAllIP192.168.1.1Packet</th>\n","      <th>FromLocalIcmpPortAllIP192.168.1.1Byte</th>\n","      <th>FromLocalUdpPort53IP192.168.1.1Packet</th>\n","      <th>...</th>\n","      <th>FromInternetUdpPort33434Byte</th>\n","      <th>ToInternetTcpPort443Packet</th>\n","      <th>ToInternetTcpPort443Byte</th>\n","      <th>ToInternetUdpPort123Packet</th>\n","      <th>ToInternetUdpPort123Byte</th>\n","      <th>ToInternetTcpPort80Packet</th>\n","      <th>ToInternetTcpPort80Byte</th>\n","      <th>ToInternetUdpPort33434Packet</th>\n","      <th>ToInternetUdpPort33434Byte</th>\n","      <th>NoOfFlows</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1537760161699</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>980</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>198</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1537760221755</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1537760281805</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>5</td>\n","      <td>450</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1537760341861</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1537760401909</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>43723</th>\n","      <td>1540582549573</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>470</td>\n","      <td>1</td>\n","      <td>90</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>66</td>\n","    </tr>\n","    <tr>\n","      <th>43724</th>\n","      <td>1540582609614</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>66</td>\n","    </tr>\n","    <tr>\n","      <th>43725</th>\n","      <td>1540582669696</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>1</td>\n","      <td>90</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>66</td>\n","    </tr>\n","    <tr>\n","      <th>43726</th>\n","      <td>1540582729740</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>1</td>\n","      <td>90</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>66</td>\n","    </tr>\n","    <tr>\n","      <th>43727</th>\n","      <td>1540582789826</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>980</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>298</td>\n","      <td>1</td>\n","      <td>90</td>\n","      <td>6</td>\n","      <td>488</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>66</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>43728 rows Ã— 52 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a06bcdef-bb0a-49a6-9f1d-458f6cbcd0aa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a06bcdef-bb0a-49a6-9f1d-458f6cbcd0aa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a06bcdef-bb0a-49a6-9f1d-458f6cbcd0aa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           Timestamp  FromInternetUdpPort53IP208.67.220.220/32Packet  \\\n","0      1537760161699                                               0   \n","1      1537760221755                                               0   \n","2      1537760281805                                               0   \n","3      1537760341861                                               0   \n","4      1537760401909                                               0   \n","...              ...                                             ...   \n","43723  1540582549573                                               0   \n","43724  1540582609614                                               0   \n","43725  1540582669696                                               0   \n","43726  1540582729740                                               0   \n","43727  1540582789826                                               0   \n","\n","       FromInternetUdpPort53IP208.67.220.220/32Byte  \\\n","0                                                 0   \n","1                                                 0   \n","2                                                 0   \n","3                                                 0   \n","4                                                 0   \n","...                                             ...   \n","43723                                             0   \n","43724                                             0   \n","43725                                             0   \n","43726                                             0   \n","43727                                             0   \n","\n","       ToInternetUdpPort53IP208.67.220.220/32Packet  \\\n","0                                                 0   \n","1                                                 0   \n","2                                                 0   \n","3                                                 0   \n","4                                                 0   \n","...                                             ...   \n","43723                                             0   \n","43724                                             0   \n","43725                                             0   \n","43726                                             0   \n","43727                                             0   \n","\n","       ToInternetUdpPort53IP208.67.220.220/32Byte  \\\n","0                                               0   \n","1                                               0   \n","2                                               0   \n","3                                               0   \n","4                                               0   \n","...                                           ...   \n","43723                                           0   \n","43724                                           0   \n","43725                                           0   \n","43726                                           0   \n","43727                                           0   \n","\n","       FromLocalUdpPort67IP192.168.1.1Packet  \\\n","0                                          0   \n","1                                          0   \n","2                                          0   \n","3                                          0   \n","4                                          0   \n","...                                      ...   \n","43723                                      0   \n","43724                                      0   \n","43725                                      0   \n","43726                                      0   \n","43727                                      0   \n","\n","       FromLocalUdpPort67IP192.168.1.1Byte  \\\n","0                                        0   \n","1                                        0   \n","2                                        0   \n","3                                        0   \n","4                                        0   \n","...                                    ...   \n","43723                                    0   \n","43724                                    0   \n","43725                                    0   \n","43726                                    0   \n","43727                                    0   \n","\n","       FromLocalIcmpPortAllIP192.168.1.1Packet  \\\n","0                                           10   \n","1                                            0   \n","2                                            0   \n","3                                            0   \n","4                                            0   \n","...                                        ...   \n","43723                                        0   \n","43724                                        0   \n","43725                                        0   \n","43726                                        0   \n","43727                                       10   \n","\n","       FromLocalIcmpPortAllIP192.168.1.1Byte  \\\n","0                                        980   \n","1                                          0   \n","2                                          0   \n","3                                          0   \n","4                                          0   \n","...                                      ...   \n","43723                                      0   \n","43724                                      0   \n","43725                                      0   \n","43726                                      0   \n","43727                                    980   \n","\n","       FromLocalUdpPort53IP192.168.1.1Packet  ...  \\\n","0                                          2  ...   \n","1                                          0  ...   \n","2                                          0  ...   \n","3                                          0  ...   \n","4                                          0  ...   \n","...                                      ...  ...   \n","43723                                      0  ...   \n","43724                                      0  ...   \n","43725                                      0  ...   \n","43726                                      0  ...   \n","43727                                      1  ...   \n","\n","       FromInternetUdpPort33434Byte  ToInternetTcpPort443Packet  \\\n","0                                 0                           4   \n","1                                 0                           4   \n","2                                 0                           4   \n","3                                 0                           4   \n","4                                 0                           4   \n","...                             ...                         ...   \n","43723                             0                           5   \n","43724                             0                           4   \n","43725                             0                           4   \n","43726                             0                           4   \n","43727                             0                           4   \n","\n","       ToInternetTcpPort443Byte  ToInternetUdpPort123Packet  \\\n","0                           298                           0   \n","1                           298                           0   \n","2                           298                           5   \n","3                           298                           0   \n","4                           298                           0   \n","...                         ...                         ...   \n","43723                       470                           1   \n","43724                       298                           0   \n","43725                       298                           1   \n","43726                       298                           1   \n","43727                       298                           1   \n","\n","       ToInternetUdpPort123Byte  ToInternetTcpPort80Packet  \\\n","0                             0                          3   \n","1                             0                          0   \n","2                           450                          0   \n","3                             0                          0   \n","4                             0                          0   \n","...                         ...                        ...   \n","43723                        90                          0   \n","43724                         0                          0   \n","43725                        90                          0   \n","43726                        90                          0   \n","43727                        90                          6   \n","\n","       ToInternetTcpPort80Byte  ToInternetUdpPort33434Packet  \\\n","0                          198                             0   \n","1                            0                             0   \n","2                            0                             0   \n","3                            0                             0   \n","4                            0                             0   \n","...                        ...                           ...   \n","43723                        0                             0   \n","43724                        0                             0   \n","43725                        0                             0   \n","43726                        0                             0   \n","43727                      488                             0   \n","\n","       ToInternetUdpPort33434Byte   NoOfFlows  \n","0                               0          77  \n","1                               0          77  \n","2                               0          77  \n","3                               0          77  \n","4                               0          77  \n","...                           ...         ...  \n","43723                           0          66  \n","43724                           0          66  \n","43725                           0          66  \n","43726                           0          66  \n","43727                           0          66  \n","\n","[43728 rows x 52 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df_flow0 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/00166cab6b88_flowstats.csv')\n","df_flow1 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/0017882b9a25_flowstats.csv')\n","df_flow2 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/44650d56ccd3_flowstats.csv')\n","df_flow3 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/50c7bf005639_flowstats.csv')\n","df_flow4 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/70ee50183443_flowstats.csv')\n","df_flow5 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/74c63b29d71d_flowstats.csv')\n","df_flow6 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/d073d5018308_flowstats.csv')\n","df_flow7 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/ec1a5979f489_flowstats.csv')\n","df_flow8 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/ec1a59832811_flowstats.csv')\n","df_flow9 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/flow/f4f5d88f0a3c_flowstats.csv')\n","df_flow2"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":6302,"status":"ok","timestamp":1675499188934,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"Z1b4VUqqwg5O","outputId":"269d90b4-6d6c-4087-c4fb-b363baa27129"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-8ed32695-6601-40da-ba8a-bacc59bfc5a2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Start Time</th>\n","      <th>End Time</th>\n","      <th>Impact</th>\n","      <th>Attack</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1540218159</td>\n","      <td>1540218759</td>\n","      <td>Localfeatures|Allfeatures|Arpfeatures</td>\n","      <td>ArpSpoof100L2D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1540214943</td>\n","      <td>1540215543</td>\n","      <td>Localfeatures|Allfeatures|Arpfeatures</td>\n","      <td>ArpSpoof1L2D</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1540216550</td>\n","      <td>1540217150</td>\n","      <td>Localfeatures|Allfeatures|Arpfeatures</td>\n","      <td>ArpSpoof10L2D</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1540240592</td>\n","      <td>1540241193</td>\n","      <td>Udpfeatures|Localfeatures|Allfeatures|LocalUDP...</td>\n","      <td>UdpDevice1L2D</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1540249401</td>\n","      <td>1540250001</td>\n","      <td>Udpfeatures|Localfeatures|Allfeatures|LocalUDP...</td>\n","      <td>UdpDevice10L2D</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1540251009</td>\n","      <td>1540251609</td>\n","      <td>Udpfeatures|Localfeatures|Allfeatures|LocalUDP...</td>\n","      <td>UdpDevice100L2D</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1540305374</td>\n","      <td>1540305974</td>\n","      <td>internetUdpPort123|Udpfeatures|Internetfeature...</td>\n","      <td>UdpDevice1W2D</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1540305984</td>\n","      <td>1540306584</td>\n","      <td>internetUdpPort123|Udpfeatures|Internetfeature...</td>\n","      <td>UdpDevice10W2D</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1540306594</td>\n","      <td>1540307194</td>\n","      <td>NaN</td>\n","      <td>UdpDevice100W2D</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ed32695-6601-40da-ba8a-bacc59bfc5a2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8ed32695-6601-40da-ba8a-bacc59bfc5a2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8ed32695-6601-40da-ba8a-bacc59bfc5a2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Start Time    End Time                                             Impact  \\\n","0  1540218159  1540218759              Localfeatures|Allfeatures|Arpfeatures   \n","1  1540214943  1540215543              Localfeatures|Allfeatures|Arpfeatures   \n","2  1540216550  1540217150              Localfeatures|Allfeatures|Arpfeatures   \n","3  1540240592  1540241193  Udpfeatures|Localfeatures|Allfeatures|LocalUDP...   \n","4  1540249401  1540250001  Udpfeatures|Localfeatures|Allfeatures|LocalUDP...   \n","5  1540251009  1540251609  Udpfeatures|Localfeatures|Allfeatures|LocalUDP...   \n","6  1540305374  1540305974  internetUdpPort123|Udpfeatures|Internetfeature...   \n","7  1540305984  1540306584  internetUdpPort123|Udpfeatures|Internetfeature...   \n","8  1540306594  1540307194                                                NaN   \n","\n","            Attack  \n","0   ArpSpoof100L2D  \n","1     ArpSpoof1L2D  \n","2    ArpSpoof10L2D  \n","3    UdpDevice1L2D  \n","4   UdpDevice10L2D  \n","5  UdpDevice100L2D  \n","6    UdpDevice1W2D  \n","7   UdpDevice10W2D  \n","8  UdpDevice100W2D  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_attack0 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/00166cab6b88.csv')\n","df_attack1 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/0017882b9a25.csv')\n","df_attack2 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/44650d56ccd3.csv')\n","df_attack3 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/50c7bf005639.csv')\n","df_attack4 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/70ee50183443.csv')\n","df_attack5 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/74c63b29d71d.csv')\n","df_attack6 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/d073d5018308.csv')\n","df_attack7 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/ec1a5979f489.csv')\n","df_attack8 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/ec1a59832811.csv')\n","df_attack9 = pd.read_csv('gdrive/MyDrive/Thesis-NikkiZhang/IoT_Anomaly_Detection_Smart_Homes/Dataset/annotation/f4f5d88f0a3c.csv')\n","df_attack2"]},{"cell_type":"markdown","metadata":{"id":"wfBQTZd9wEsx"},"source":["## Mark attack and attack types"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":233285,"status":"ok","timestamp":1675499446081,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"-1NDbS2D_bx9"},"outputs":[],"source":["def mark_type_function(df_flow,df_attack):\n","    df_flow['Attack'] = 0\n","    df_flow['AttackType'] = 45\n","    for i in range(len(df_flow)):\n","        k=0\n","        for j in range(len(df_attack)):\n","            if(df_flow['Timestamp'][i]>=df_attack['Start Time'][j]*1000 and df_attack['End Time'][j]*1000>=df_flow['Timestamp'][i]):\n","                df_flow['Attack'][i] = 1\n","                if df_attack['Attack'][j] == \"ArpSpoof100L2D\":\n","                    df_flow['AttackType'][i] = 0\n","                elif df_attack['Attack'][j] == \"ArpSpoof1L2D\":\n","                    df_flow['AttackType'][i] = 1\n","                elif df_attack['Attack'][j] == \"ArpSpoof10L2D\":\n","                    df_flow['AttackType'][i] = 2\n","                elif df_attack['Attack'][j] == \"TcpSynDevice1L2D\":\n","                    df_flow['AttackType'][i] = 3\n","                elif df_attack['Attack'][j] == \"TcpSynDevice10L2D\":\n","                    df_flow['AttackType'][i] = 4\n","                elif df_attack['Attack'][j] == \"TcpSynDevice100L2D\":\n","                    df_flow['AttackType'][i] = 5\n","                elif df_attack['Attack'][j] == \"PingOfDeath1L2D\":\n","                    df_flow['AttackType'][i] = 6\n","                elif df_attack['Attack'][j] == \"PingOfDeath10L2D\":\n","                    df_flow['AttackType'][i] = 7\n","                elif df_attack['Attack'][j] == \"PingOfDeath100L2D\":\n","                    df_flow['AttackType'][i] = 8\n","                elif df_attack['Attack'][j] == \"UdpDevice1L2D\":\n","                    df_flow['AttackType'][i] = 9\n","                elif df_attack['Attack'][j] == \"UdpDevice10L2D\":\n","                    df_flow['AttackType'][i] = 10\n","                elif df_attack['Attack'][j] == \"UdpDevice100L2D\":\n","                    df_flow['AttackType'][i] = 11\n","                elif df_attack['Attack'][j] == \"TcpSynReflection100L2D2L\":\n","                    df_flow['AttackType'][i] = 12\n","                elif df_attack['Attack'][j] == \"TcpSynReflection1L2D2L\":\n","                    df_flow['AttackType'][i] = 13\n","                elif df_attack['Attack'][j] == \"TcpSynReflection10L2D2L\":\n","                    df_flow['AttackType'][i] = 14\n","                elif df_attack['Attack'][j] == \"Smurf1L2D2L\":\n","                    df_flow['AttackType'][i] = 15\n","                elif df_attack['Attack'][j] == \"Smurf10L2D2L\":\n","                    df_flow['AttackType'][i] = 16\n","                elif df_attack['Attack'][j] == \"Smurf100L2D2L\":\n","                    df_flow['AttackType'][i] = 17\n","                elif df_attack['Attack'][j] == \"Snmp1L2D2L\":\n","                    df_flow['AttackType'][i] = 18\n","                elif df_attack['Attack'][j] == \"Snmp10L2D2L\":\n","                    df_flow['AttackType'][i] = 19\n","                elif df_attack['Attack'][j] == \"Snmp100L2D2L\":\n","                    df_flow['AttackType'][i] = 20\n","                elif df_attack['Attack'][j] == \"Snmp1L2D2W\":\n","                    df_flow['AttackType'][i] = 21\n","                elif df_attack['Attack'][j] == \"Snmp10L2D2W\":\n","                    df_flow['AttackType'][i] = 22\n","                elif df_attack['Attack'][j] == \"Snmp100L2D2W\":\n","                    df_flow['AttackType'][i] = 23\n","                elif df_attack['Attack'][j] == \"TcpSynReflection100W2D2W\":\n","                    df_flow['AttackType'][i] = 24\n","                elif df_attack['Attack'][j] == \"TcpSynReflection1W2D2W\":\n","                    df_flow['AttackType'][i] = 25\n","                elif df_attack['Attack'][j] == \"TcpSynReflection10W2D2W\":\n","                    df_flow['AttackType'][i] = 26\n","                elif df_attack['Attack'][j] == \"Snmp1W2D2W\":\n","                    df_flow['AttackType'][i] = 27\n","                elif df_attack['Attack'][j] == \"Snmp10W2D2W\":\n","                    df_flow['AttackType'][i] = 28\n","                elif df_attack['Attack'][j] == \"Snmp100W2D2W\":\n","                    df_flow['AttackType'][i] = 29\n","                elif df_attack['Attack'][j] == \"TcpSynDevice1W2D\":\n","                    df_flow['AttackType'][i] = 30\n","                elif df_attack['Attack'][j] == \"TcpSynDevice10W2D\":\n","                    df_flow['AttackType'][i] = 31\n","                elif df_attack['Attack'][j] == \"TcpSynDevice100W2D\":\n","                    df_flow['AttackType'][i] = 32\n","                elif df_attack['Attack'][j] == \"UdpDevice1W2D\":\n","                    df_flow['AttackType'][i] = 33\n","                elif df_attack['Attack'][j] == \"UdpDevice10W2D\":\n","                    df_flow['AttackType'][i] = 34\n","                elif df_attack['Attack'][j] == \"UdpDevice100W2D\":\n","                    df_flow['AttackType'][i] = 35\n","                elif df_attack['Attack'][j] == \"Ssdp100L2D2W\":\n","                    df_flow['AttackType'][i] = 36\n","                elif df_attack['Attack'][j] == \"Ssdp10L2D2W\":\n","                    df_flow['AttackType'][i] = 37\n","                elif df_attack['Attack'][j] == \"Ssdp1L2D2W\":\n","                    df_flow['AttackType'][i] = 38\n","                elif df_attack['Attack'][j] == \"Ssdp1L2D2L\":\n","                    df_flow['AttackType'][i] = 39\n","                elif df_attack['Attack'][j] == \"Ssdp10L2D2L\":\n","                    df_flow['AttackType'][i] = 40\n","                elif df_attack['Attack'][j] == \"Ssdp100L2D2L\":\n","                    df_flow['AttackType'][i] = 41\n","                elif df_attack['Attack'][j] == \"Ssdp1W2D2W\":\n","                    df_flow['AttackType'][i] = 42\n","                elif df_attack['Attack'][j] == \"Ssdp10W2D2W\":\n","                    df_flow['AttackType'][i] = 43\n","                elif df_attack['Attack'][j] == \"Ssdp100W2D2W\":\n","                    df_flow['AttackType'][i] = 44\n","                \n","\n","mark_type_function(df_flow0,df_attack0)\n","mark_type_function(df_flow1,df_attack1)\n","mark_type_function(df_flow2,df_attack2)\n","mark_type_function(df_flow3,df_attack3)\n","mark_type_function(df_flow4,df_attack4)\n","mark_type_function(df_flow5,df_attack5)\n","mark_type_function(df_flow6,df_attack6)\n","mark_type_function(df_flow7,df_attack7)\n","mark_type_function(df_flow8,df_attack8)\n","mark_type_function(df_flow9,df_attack9)\n","     "]},{"cell_type":"markdown","metadata":{"id":"vislTIrawMDv"},"source":["## Concat df"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"elapsed":806,"status":"ok","timestamp":1675499448389,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"RU6hf_1Y_ici","outputId":"e0144522-d5a5-4131-d8d1-92aa2a665dd4"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-3f4c7aed-97a2-433b-ba4d-597f49355188\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>FromInternetTcpPort40000Packet</th>\n","      <th>FromInternetTcpPort40000Byte</th>\n","      <th>FromInternetUdpPortAllPacket</th>\n","      <th>FromInternetUdpPortAllByte</th>\n","      <th>ToInternetTcpPort40000Packet</th>\n","      <th>ToInternetTcpPort40000Byte</th>\n","      <th>ToInternetUdpPortAllPacket</th>\n","      <th>ToInternetUdpPortAllByte</th>\n","      <th>FromLocalTcpPort59486Packet</th>\n","      <th>...</th>\n","      <th>ToLocalTcpPort8008Packet</th>\n","      <th>ToLocalTcpPort8008Byte</th>\n","      <th>FromInternetUdpPort443Packet</th>\n","      <th>FromInternetUdpPort443Byte</th>\n","      <th>FromInternetTcpPort5228Packet</th>\n","      <th>FromInternetTcpPort5228Byte</th>\n","      <th>ToInternetUdpPort443Packet</th>\n","      <th>ToInternetUdpPort443Byte</th>\n","      <th>ToInternetTcpPort5228Packet</th>\n","      <th>ToInternetTcpPort5228Byte</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1527516443794</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1527516503843</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1527516563905</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1527516623958</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>58.0</td>\n","      <td>24324.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>706.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1527516684007</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>138.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>700.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>43724</th>\n","      <td>1540582549556</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>1473.0</td>\n","      <td>21.0</td>\n","      <td>7767.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","      <td>26.0</td>\n","      <td>18572.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>43725</th>\n","      <td>1540582609598</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>8.0</td>\n","      <td>2946.0</td>\n","      <td>6.0</td>\n","      <td>1813.0</td>\n","      <td>2.0</td>\n","      <td>165.0</td>\n","      <td>8.0</td>\n","      <td>4143.0</td>\n","      <td>3.0</td>\n","      <td>231.0</td>\n","    </tr>\n","    <tr>\n","      <th>43726</th>\n","      <td>1540582669678</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>5769.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","      <td>17.0</td>\n","      <td>9789.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>43727</th>\n","      <td>1540582729722</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>1473.0</td>\n","      <td>5.0</td>\n","      <td>1757.0</td>\n","      <td>2.0</td>\n","      <td>165.0</td>\n","      <td>7.0</td>\n","      <td>3767.0</td>\n","      <td>3.0</td>\n","      <td>231.0</td>\n","    </tr>\n","    <tr>\n","      <th>43728</th>\n","      <td>1540582789807</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>8.0</td>\n","      <td>2946.0</td>\n","      <td>401.0</td>\n","      <td>540410.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","      <td>210.0</td>\n","      <td>23305.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>570460 rows Ã— 256 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f4c7aed-97a2-433b-ba4d-597f49355188')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3f4c7aed-97a2-433b-ba4d-597f49355188 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3f4c7aed-97a2-433b-ba4d-597f49355188');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           Timestamp  FromInternetTcpPort40000Packet  \\\n","0      1527516443794                             0.0   \n","1      1527516503843                             0.0   \n","2      1527516563905                             0.0   \n","3      1527516623958                             0.0   \n","4      1527516684007                             0.0   \n","...              ...                             ...   \n","43724  1540582549556                             NaN   \n","43725  1540582609598                             NaN   \n","43726  1540582669678                             NaN   \n","43727  1540582729722                             NaN   \n","43728  1540582789807                             NaN   \n","\n","       FromInternetTcpPort40000Byte  FromInternetUdpPortAllPacket  \\\n","0                               0.0                           0.0   \n","1                               0.0                           0.0   \n","2                               0.0                           0.0   \n","3                               0.0                          58.0   \n","4                               0.0                           1.0   \n","...                             ...                           ...   \n","43724                           NaN                           NaN   \n","43725                           NaN                           NaN   \n","43726                           NaN                           NaN   \n","43727                           NaN                           NaN   \n","43728                           NaN                           NaN   \n","\n","       FromInternetUdpPortAllByte  ToInternetTcpPort40000Packet  \\\n","0                             0.0                           0.0   \n","1                             0.0                           0.0   \n","2                             0.0                           0.0   \n","3                         24324.0                           0.0   \n","4                           138.0                           0.0   \n","...                           ...                           ...   \n","43724                         NaN                           NaN   \n","43725                         NaN                           NaN   \n","43726                         NaN                           NaN   \n","43727                         NaN                           NaN   \n","43728                         NaN                           NaN   \n","\n","       ToInternetTcpPort40000Byte  ToInternetUdpPortAllPacket  \\\n","0                             0.0                         0.0   \n","1                             0.0                         0.0   \n","2                             0.0                         0.0   \n","3                             0.0                        11.0   \n","4                             0.0                        10.0   \n","...                           ...                         ...   \n","43724                         NaN                         NaN   \n","43725                         NaN                         NaN   \n","43726                         NaN                         NaN   \n","43727                         NaN                         NaN   \n","43728                         NaN                         NaN   \n","\n","       ToInternetUdpPortAllByte  FromLocalTcpPort59486Packet  ...  \\\n","0                           0.0                          0.0  ...   \n","1                           0.0                          0.0  ...   \n","2                           0.0                          0.0  ...   \n","3                         706.0                          0.0  ...   \n","4                         700.0                          0.0  ...   \n","...                         ...                          ...  ...   \n","43724                       NaN                          NaN  ...   \n","43725                       NaN                          NaN  ...   \n","43726                       NaN                          NaN  ...   \n","43727                       NaN                          NaN  ...   \n","43728                       NaN                          NaN  ...   \n","\n","       ToLocalTcpPort8008Packet  ToLocalTcpPort8008Byte  \\\n","0                           NaN                     NaN   \n","1                           NaN                     NaN   \n","2                           NaN                     NaN   \n","3                           NaN                     NaN   \n","4                           NaN                     NaN   \n","...                         ...                     ...   \n","43724                       4.0                  1473.0   \n","43725                       8.0                  2946.0   \n","43726                       0.0                     0.0   \n","43727                       4.0                  1473.0   \n","43728                       8.0                  2946.0   \n","\n","       FromInternetUdpPort443Packet  FromInternetUdpPort443Byte  \\\n","0                               NaN                         NaN   \n","1                               NaN                         NaN   \n","2                               NaN                         NaN   \n","3                               NaN                         NaN   \n","4                               NaN                         NaN   \n","...                             ...                         ...   \n","43724                          21.0                      7767.0   \n","43725                           6.0                      1813.0   \n","43726                          14.0                      5769.0   \n","43727                           5.0                      1757.0   \n","43728                         401.0                    540410.0   \n","\n","       FromInternetTcpPort5228Packet  FromInternetTcpPort5228Byte  \\\n","0                                NaN                          NaN   \n","1                                NaN                          NaN   \n","2                                NaN                          NaN   \n","3                                NaN                          NaN   \n","4                                NaN                          NaN   \n","...                              ...                          ...   \n","43724                            1.0                         66.0   \n","43725                            2.0                        165.0   \n","43726                            1.0                         66.0   \n","43727                            2.0                        165.0   \n","43728                            1.0                         66.0   \n","\n","       ToInternetUdpPort443Packet  ToInternetUdpPort443Byte  \\\n","0                             NaN                       NaN   \n","1                             NaN                       NaN   \n","2                             NaN                       NaN   \n","3                             NaN                       NaN   \n","4                             NaN                       NaN   \n","...                           ...                       ...   \n","43724                        26.0                   18572.0   \n","43725                         8.0                    4143.0   \n","43726                        17.0                    9789.0   \n","43727                         7.0                    3767.0   \n","43728                       210.0                   23305.0   \n","\n","       ToInternetTcpPort5228Packet  ToInternetTcpPort5228Byte  \n","0                              NaN                        NaN  \n","1                              NaN                        NaN  \n","2                              NaN                        NaN  \n","3                              NaN                        NaN  \n","4                              NaN                        NaN  \n","...                            ...                        ...  \n","43724                          1.0                       66.0  \n","43725                          3.0                      231.0  \n","43726                          1.0                       66.0  \n","43727                          3.0                      231.0  \n","43728                          1.0                       66.0  \n","\n","[570460 rows x 256 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.concat([df_flow0, df_flow1, df_flow2, df_flow3, df_flow4, df_flow5, df_flow6, df_flow7, df_flow8, df_flow9])\n","df"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1675499448389,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"LwqXJwvDWVhR","outputId":"527cd319-11b9-4e77-da61-91ac7c3da365"},"outputs":[{"data":{"text/plain":["['Timestamp',\n"," 'FromInternetTcpPort40000Packet',\n"," 'FromInternetTcpPort40000Byte',\n"," 'FromInternetUdpPortAllPacket',\n"," 'FromInternetUdpPortAllByte',\n"," 'ToInternetTcpPort40000Packet',\n"," 'ToInternetTcpPort40000Byte',\n"," 'ToInternetUdpPortAllPacket',\n"," 'ToInternetUdpPortAllByte',\n"," 'FromLocalTcpPort59486Packet',\n"," 'FromLocalTcpPort59486Byte',\n"," 'FromLocalTcpPort554Packet',\n"," 'FromLocalTcpPort554Byte',\n"," 'FromLocalIcmpPortAllPacket',\n"," 'FromLocalIcmpPortAllByte',\n"," 'FromLocalUdpPort53IP192.168.1.1Packet',\n"," 'FromLocalUdpPort53IP192.168.1.1Byte',\n"," 'FromLocalTcpPort47893Packet',\n"," 'FromLocalTcpPort47893Byte',\n"," 'FromLocalTcpPort41086Packet',\n"," 'FromLocalTcpPort41086Byte',\n"," 'FromLocalTcpPort54836Packet',\n"," 'FromLocalTcpPort54836Byte',\n"," 'FromLocalTcpPort51125Packet',\n"," 'FromLocalTcpPort51125Byte',\n"," 'FromLocalTcpPort53074Packet',\n"," 'FromLocalTcpPort53074Byte',\n"," 'FromLocalTcpPort56035Packet',\n"," 'FromLocalTcpPort56035Byte',\n"," 'FromLocalUdpPort1900Packet',\n"," 'FromLocalUdpPort1900Byte',\n"," 'FromLocalUdpPort67IP192.168.1.1Packet',\n"," 'FromLocalUdpPort67IP192.168.1.1Byte',\n"," 'FromLocalTcpPort44416Packet',\n"," 'FromLocalTcpPort44416Byte',\n"," 'FromLocalTcpPort49152Packet',\n"," 'FromLocalTcpPort49152Byte',\n"," 'FromLocalTcpPort80Packet',\n"," 'FromLocalTcpPort80Byte',\n"," 'FromLocalArpPortAllPacket',\n"," 'FromLocalArpPortAllByte',\n"," 'ToLocal2PortAllIP224.0.0.251/32Packet',\n"," 'ToLocal2PortAllIP224.0.0.251/32Byte',\n"," 'ToLocal2PortAllIP224.0.0.22/32Packet',\n"," 'ToLocal2PortAllIP224.0.0.22/32Byte',\n"," 'ToLocalTcpPort47893Packet',\n"," 'ToLocalTcpPort47893Byte',\n"," 'ToLocalUdpPort1900IP239.255.255.250/32Packet',\n"," 'ToLocalUdpPort1900IP239.255.255.250/32Byte',\n"," 'ToLocalUdpPort67IP255.255.255.255/32Packet',\n"," 'ToLocalUdpPort67IP255.255.255.255/32Byte',\n"," 'ToLocalTcpPort54836Packet',\n"," 'ToLocalTcpPort54836Byte',\n"," 'ToLocalUdpPort7711IP255.255.255.255/32Packet',\n"," 'ToLocalUdpPort7711IP255.255.255.255/32Byte',\n"," 'ToLocalTcpPort53074Packet',\n"," 'ToLocalTcpPort53074Byte',\n"," 'ToLocalUdpPort1900Packet',\n"," 'ToLocalUdpPort1900Byte',\n"," 'ToLocalTcpPort51125Packet',\n"," 'ToLocalTcpPort51125Byte',\n"," 'ToLocalTcpPort41086Packet',\n"," 'ToLocalTcpPort41086Byte',\n"," 'ToLocal2PortAllIP239.255.255.250/32Packet',\n"," 'ToLocal2PortAllIP239.255.255.250/32Byte',\n"," 'ToLocalTcpPort59486Packet',\n"," 'ToLocalTcpPort59486Byte',\n"," 'ToLocalUdpPort53IP192.168.1.1Packet',\n"," 'ToLocalUdpPort53IP192.168.1.1Byte',\n"," 'ToLocalTcpPort49152Packet',\n"," 'ToLocalTcpPort49152Byte',\n"," 'ToLocalTcpPort443Packet',\n"," 'ToLocalTcpPort443Byte',\n"," 'ToLocalUdpPort67IP192.168.1.1Packet',\n"," 'ToLocalUdpPort67IP192.168.1.1Byte',\n"," 'ToLocalTcpPort444Packet',\n"," 'ToLocalTcpPort444Byte',\n"," 'ToLocalTcpPort554Packet',\n"," 'ToLocalTcpPort554Byte',\n"," 'ToLocalTcpPort56035Packet',\n"," 'ToLocalTcpPort56035Byte',\n"," 'ToLocalUdpPort5353IP224.0.0.251/32Packet',\n"," 'ToLocalUdpPort5353IP224.0.0.251/32Byte',\n"," 'ToLocalTcpPort44416Packet',\n"," 'ToLocalTcpPort44416Byte',\n"," 'ToLocal2PortAllIP224.0.0.2/32Packet',\n"," 'ToLocal2PortAllIP224.0.0.2/32Byte',\n"," 'ToLocalTcpPort80Packet',\n"," 'ToLocalTcpPort80Byte',\n"," 'ToLocalUdpPort1900IPff00::/8Packet',\n"," 'ToLocalUdpPort1900IPff00::/8Byte',\n"," 'ToLocalUdpPort5353IPff00::/8Packet',\n"," 'ToLocalUdpPort5353IPff00::/8Byte',\n"," 'ToLocal0PortAllIPff05:0:0:0:0:0:0:cPacket',\n"," 'ToLocal0PortAllIPff05:0:0:0:0:0:0:cByte',\n"," 'ToLocal0PortAllIPff00::/8Packet',\n"," 'ToLocal0PortAllIPff00::/8Byte',\n"," 'ToLocal0x0006PortAllPacket',\n"," 'ToLocal0x0006PortAllByte',\n"," 'ToLocal0x888ePortAllPacket',\n"," 'ToLocal0x888ePortAllByte',\n"," 'ToLocalArpPortAllPacket',\n"," 'ToLocalArpPortAllByte',\n"," 'FromInternetUdpPort123Packet',\n"," 'FromInternetUdpPort123Byte',\n"," 'FromInternetTcpPort443Packet',\n"," 'FromInternetTcpPort443Byte',\n"," 'FromInternetTcpPort80Packet',\n"," 'FromInternetTcpPort80Byte',\n"," 'FromInternetTcpPort465Packet',\n"," 'FromInternetTcpPort465Byte',\n"," 'FromInternetTcpPort5222Packet',\n"," 'FromInternetTcpPort5222Byte',\n"," 'ToInternetUdpPort123Packet',\n"," 'ToInternetUdpPort123Byte',\n"," 'ToInternetTcpPort5222Packet',\n"," 'ToInternetTcpPort5222Byte',\n"," 'ToInternetTcpPort80Packet',\n"," 'ToInternetTcpPort80Byte',\n"," 'ToInternetTcpPort443Packet',\n"," 'ToInternetTcpPort443Byte',\n"," 'ToInternetTcpPort465Packet',\n"," 'ToInternetTcpPort465Byte',\n"," ' NoOfFlows',\n"," 'Attack',\n"," 'AttackType',\n"," 'FromInternetUdpPort53IP208.67.220.220/32Packet',\n"," 'FromInternetUdpPort53IP208.67.220.220/32Byte',\n"," 'ToInternetUdpPort53IP208.67.220.220/32Packet',\n"," 'ToInternetUdpPort53IP208.67.220.220/32Byte',\n"," 'FromLocalIcmpPortAllIP192.168.1.1Packet',\n"," 'FromLocalIcmpPortAllIP192.168.1.1Byte',\n"," 'FromLocalUdpPort50000Packet',\n"," 'FromLocalUdpPort50000Byte',\n"," 'ToLocalIcmpPortAllIP192.168.1.1Packet',\n"," 'ToLocalIcmpPortAllIP192.168.1.1Byte',\n"," 'FromInternetUdpPort33434Packet',\n"," 'FromInternetUdpPort33434Byte',\n"," 'ToInternetUdpPort33434Packet',\n"," 'ToInternetUdpPort33434Byte',\n"," 'FromLocalTcpPort9999Packet',\n"," 'FromLocalTcpPort9999Byte',\n"," 'ToLocalTcpPort9999Packet',\n"," 'ToLocalTcpPort9999Byte',\n"," 'FromInternetTcpPort50443Packet',\n"," 'FromInternetTcpPort50443Byte',\n"," 'ToInternetTcpPort50443Packet',\n"," 'ToInternetTcpPort50443Byte',\n"," 'ToLocal58PortAllIPff00::/8Packet',\n"," 'ToLocal58PortAllIPff00::/8Byte',\n"," 'FromInternetIcmpPortAllPacket',\n"," 'FromInternetIcmpPortAllByte',\n"," 'FromInternetUdpPort500Packet',\n"," 'FromInternetUdpPort500Byte',\n"," 'FromInternetUdpPort4500Packet',\n"," 'FromInternetUdpPort4500Byte',\n"," 'ToInternetIcmpPortAllPacket',\n"," 'ToInternetIcmpPortAllByte',\n"," 'ToInternetUdpPort4500Packet',\n"," 'ToInternetUdpPort4500Byte',\n"," 'ToInternetUdpPort500Packet',\n"," 'ToInternetUdpPort500Byte',\n"," 'FromInternetUdpPort53IP8.8.8.8/32Packet',\n"," 'FromInternetUdpPort53IP8.8.8.8/32Byte',\n"," 'ToInternetUdpPort53IP8.8.8.8/32Packet',\n"," 'ToInternetUdpPort53IP8.8.8.8/32Byte',\n"," 'FromLocalUdpPort56700Packet',\n"," 'FromLocalUdpPort56700Byte',\n"," 'ToLocalUdpPort56700Packet',\n"," 'ToLocalUdpPort56700Byte',\n"," 'ToLocalUdpPort56700Packet.1',\n"," 'ToLocalUdpPort56700Byte.1',\n"," 'FromInternetTcpPort56700Packet',\n"," 'FromInternetTcpPort56700Byte',\n"," 'ToInternetTcpPort56700Packet',\n"," 'ToInternetTcpPort56700Byte',\n"," 'FromInternetUdpPort123IP130.149.17.8/32Packet',\n"," 'FromInternetUdpPort123IP130.149.17.8/32Byte',\n"," 'FromInternetUdpPort123IP129.132.2.21/32Packet',\n"," 'FromInternetUdpPort123IP129.132.2.21/32Byte',\n"," 'FromInternetIcmpPortAllIP4.2.2.2/32Packet',\n"," 'FromInternetIcmpPortAllIP4.2.2.2/32Byte',\n"," 'FromInternetUdpPort123IP132.163.4.102/32Packet',\n"," 'FromInternetUdpPort123IP132.163.4.102/32Byte',\n"," 'FromInternetTcpPort3478Packet',\n"," 'FromInternetTcpPort3478Byte',\n"," 'ToInternetTcpPort3478Packet',\n"," 'ToInternetTcpPort3478Byte',\n"," 'ToInternetUdpPort123IP129.132.2.21/32Packet',\n"," 'ToInternetUdpPort123IP129.132.2.21/32Byte',\n"," 'ToInternetIcmpPortAllIP4.2.2.2/32Packet',\n"," 'ToInternetIcmpPortAllIP4.2.2.2/32Byte',\n"," 'ToInternetUdpPort123IP130.149.17.8/32Packet',\n"," 'ToInternetUdpPort123IP130.149.17.8/32Byte',\n"," 'ToInternetUdpPort123IP132.163.4.102/32Packet',\n"," 'ToInternetUdpPort123IP132.163.4.102/32Byte',\n"," 'FromLocalTcpPort49153Packet',\n"," 'FromLocalTcpPort49153Byte',\n"," 'FromLocalTcpPort49154Packet',\n"," 'FromLocalTcpPort49154Byte',\n"," 'FromLocalTcpPort8059Packet',\n"," 'FromLocalTcpPort8059Byte',\n"," 'ToLocalTcpPort8059Packet',\n"," 'ToLocalTcpPort8059Byte',\n"," 'ToLocalTcpPort49154Packet',\n"," 'ToLocalTcpPort49154Byte',\n"," 'ToLocalTcpPort49153Packet',\n"," 'ToLocalTcpPort49153Byte',\n"," 'FromInternetTcpPort8899Packet',\n"," 'FromInternetTcpPort8899Byte',\n"," 'FromInternetTcpPort3475Packet',\n"," 'FromInternetTcpPort3475Byte',\n"," 'FromInternetTcpPort8443Packet',\n"," 'FromInternetTcpPort8443Byte',\n"," 'ToInternetTcpPort8443Packet',\n"," 'ToInternetTcpPort8443Byte',\n"," 'ToInternetTcpPort8899Packet',\n"," 'ToInternetTcpPort8899Byte',\n"," 'ToInternetTcpPort3475Packet',\n"," 'ToInternetTcpPort3475Byte',\n"," 'FromLocalUdpPort3306Packet',\n"," 'FromLocalUdpPort3306Byte',\n"," 'FromLocalUdpPort3079Packet',\n"," 'FromLocalUdpPort3079Byte',\n"," 'FromLocalUdpPort3080Packet',\n"," 'FromLocalUdpPort3080Byte',\n"," 'FromLocalUdpPort3087Packet',\n"," 'FromLocalUdpPort3087Byte',\n"," 'ToLocalUdpPort3080Packet',\n"," 'ToLocalUdpPort3080Byte',\n"," 'ToLocalUdpPort3079Packet',\n"," 'ToLocalUdpPort3079Byte',\n"," 'ToLocalUdpPort3306Packet',\n"," 'ToLocalUdpPort3306Byte',\n"," 'ToLocalUdpPort3087Packet',\n"," 'ToLocalUdpPort3087Byte',\n"," 'FromInternetIcmpPortAllIP8.8.8.8/32Packet',\n"," 'FromInternetIcmpPortAllIP8.8.8.8/32Byte',\n"," 'ToInternetIcmpPortAllIP8.8.8.8/32Packet',\n"," 'ToInternetIcmpPortAllIP8.8.8.8/32Byte',\n"," 'FromLocalTcpPort8008Packet',\n"," 'FromLocalTcpPort8008Byte',\n"," 'FromLocalTcpPort8009Packet',\n"," 'FromLocalTcpPort8009Byte',\n"," 'ToLocalTcpPort8009Packet',\n"," 'ToLocalTcpPort8009Byte',\n"," 'ToLocalTcpPort8008Packet',\n"," 'ToLocalTcpPort8008Byte',\n"," 'FromInternetUdpPort443Packet',\n"," 'FromInternetUdpPort443Byte',\n"," 'FromInternetTcpPort5228Packet',\n"," 'FromInternetTcpPort5228Byte',\n"," 'ToInternetUdpPort443Packet',\n"," 'ToInternetUdpPort443Byte',\n"," 'ToInternetTcpPort5228Packet',\n"," 'ToInternetTcpPort5228Byte']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["list(df.columns)"]},{"cell_type":"markdown","metadata":{"id":"Yq9O_qWRd3Kd"},"source":["## Convert NaN to 0"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"elapsed":2413,"status":"ok","timestamp":1675499460007,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"kIoJtoeKd7Eu","outputId":"c36b9a2f-8026-4b5d-b5ce-7ffe62d7e87b"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-1194becd-7572-473a-9c49-8a0f89cd3693\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>FromInternetTcpPort40000Packet</th>\n","      <th>FromInternetTcpPort40000Byte</th>\n","      <th>FromInternetUdpPortAllPacket</th>\n","      <th>FromInternetUdpPortAllByte</th>\n","      <th>ToInternetTcpPort40000Packet</th>\n","      <th>ToInternetTcpPort40000Byte</th>\n","      <th>ToInternetUdpPortAllPacket</th>\n","      <th>ToInternetUdpPortAllByte</th>\n","      <th>FromLocalTcpPort59486Packet</th>\n","      <th>...</th>\n","      <th>ToLocalTcpPort8008Packet</th>\n","      <th>ToLocalTcpPort8008Byte</th>\n","      <th>FromInternetUdpPort443Packet</th>\n","      <th>FromInternetUdpPort443Byte</th>\n","      <th>FromInternetTcpPort5228Packet</th>\n","      <th>FromInternetTcpPort5228Byte</th>\n","      <th>ToInternetUdpPort443Packet</th>\n","      <th>ToInternetUdpPort443Byte</th>\n","      <th>ToInternetTcpPort5228Packet</th>\n","      <th>ToInternetTcpPort5228Byte</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1527516443794</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1527516503843</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1527516563905</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1527516623958</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>58.0</td>\n","      <td>24324.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>706.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1527516684007</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>138.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>700.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>43724</th>\n","      <td>1540582549556</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>1473.0</td>\n","      <td>21.0</td>\n","      <td>7767.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","      <td>26.0</td>\n","      <td>18572.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>43725</th>\n","      <td>1540582609598</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>8.0</td>\n","      <td>2946.0</td>\n","      <td>6.0</td>\n","      <td>1813.0</td>\n","      <td>2.0</td>\n","      <td>165.0</td>\n","      <td>8.0</td>\n","      <td>4143.0</td>\n","      <td>3.0</td>\n","      <td>231.0</td>\n","    </tr>\n","    <tr>\n","      <th>43726</th>\n","      <td>1540582669678</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>5769.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","      <td>17.0</td>\n","      <td>9789.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>43727</th>\n","      <td>1540582729722</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>1473.0</td>\n","      <td>5.0</td>\n","      <td>1757.0</td>\n","      <td>2.0</td>\n","      <td>165.0</td>\n","      <td>7.0</td>\n","      <td>3767.0</td>\n","      <td>3.0</td>\n","      <td>231.0</td>\n","    </tr>\n","    <tr>\n","      <th>43728</th>\n","      <td>1540582789807</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>8.0</td>\n","      <td>2946.0</td>\n","      <td>401.0</td>\n","      <td>540410.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","      <td>210.0</td>\n","      <td>23305.0</td>\n","      <td>1.0</td>\n","      <td>66.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>570460 rows Ã— 256 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1194becd-7572-473a-9c49-8a0f89cd3693')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1194becd-7572-473a-9c49-8a0f89cd3693 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1194becd-7572-473a-9c49-8a0f89cd3693');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           Timestamp  FromInternetTcpPort40000Packet  \\\n","0      1527516443794                             0.0   \n","1      1527516503843                             0.0   \n","2      1527516563905                             0.0   \n","3      1527516623958                             0.0   \n","4      1527516684007                             0.0   \n","...              ...                             ...   \n","43724  1540582549556                             0.0   \n","43725  1540582609598                             0.0   \n","43726  1540582669678                             0.0   \n","43727  1540582729722                             0.0   \n","43728  1540582789807                             0.0   \n","\n","       FromInternetTcpPort40000Byte  FromInternetUdpPortAllPacket  \\\n","0                               0.0                           0.0   \n","1                               0.0                           0.0   \n","2                               0.0                           0.0   \n","3                               0.0                          58.0   \n","4                               0.0                           1.0   \n","...                             ...                           ...   \n","43724                           0.0                           0.0   \n","43725                           0.0                           0.0   \n","43726                           0.0                           0.0   \n","43727                           0.0                           0.0   \n","43728                           0.0                           0.0   \n","\n","       FromInternetUdpPortAllByte  ToInternetTcpPort40000Packet  \\\n","0                             0.0                           0.0   \n","1                             0.0                           0.0   \n","2                             0.0                           0.0   \n","3                         24324.0                           0.0   \n","4                           138.0                           0.0   \n","...                           ...                           ...   \n","43724                         0.0                           0.0   \n","43725                         0.0                           0.0   \n","43726                         0.0                           0.0   \n","43727                         0.0                           0.0   \n","43728                         0.0                           0.0   \n","\n","       ToInternetTcpPort40000Byte  ToInternetUdpPortAllPacket  \\\n","0                             0.0                         0.0   \n","1                             0.0                         0.0   \n","2                             0.0                         0.0   \n","3                             0.0                        11.0   \n","4                             0.0                        10.0   \n","...                           ...                         ...   \n","43724                         0.0                         0.0   \n","43725                         0.0                         0.0   \n","43726                         0.0                         0.0   \n","43727                         0.0                         0.0   \n","43728                         0.0                         0.0   \n","\n","       ToInternetUdpPortAllByte  FromLocalTcpPort59486Packet  ...  \\\n","0                           0.0                          0.0  ...   \n","1                           0.0                          0.0  ...   \n","2                           0.0                          0.0  ...   \n","3                         706.0                          0.0  ...   \n","4                         700.0                          0.0  ...   \n","...                         ...                          ...  ...   \n","43724                       0.0                          0.0  ...   \n","43725                       0.0                          0.0  ...   \n","43726                       0.0                          0.0  ...   \n","43727                       0.0                          0.0  ...   \n","43728                       0.0                          0.0  ...   \n","\n","       ToLocalTcpPort8008Packet  ToLocalTcpPort8008Byte  \\\n","0                           0.0                     0.0   \n","1                           0.0                     0.0   \n","2                           0.0                     0.0   \n","3                           0.0                     0.0   \n","4                           0.0                     0.0   \n","...                         ...                     ...   \n","43724                       4.0                  1473.0   \n","43725                       8.0                  2946.0   \n","43726                       0.0                     0.0   \n","43727                       4.0                  1473.0   \n","43728                       8.0                  2946.0   \n","\n","       FromInternetUdpPort443Packet  FromInternetUdpPort443Byte  \\\n","0                               0.0                         0.0   \n","1                               0.0                         0.0   \n","2                               0.0                         0.0   \n","3                               0.0                         0.0   \n","4                               0.0                         0.0   \n","...                             ...                         ...   \n","43724                          21.0                      7767.0   \n","43725                           6.0                      1813.0   \n","43726                          14.0                      5769.0   \n","43727                           5.0                      1757.0   \n","43728                         401.0                    540410.0   \n","\n","       FromInternetTcpPort5228Packet  FromInternetTcpPort5228Byte  \\\n","0                                0.0                          0.0   \n","1                                0.0                          0.0   \n","2                                0.0                          0.0   \n","3                                0.0                          0.0   \n","4                                0.0                          0.0   \n","...                              ...                          ...   \n","43724                            1.0                         66.0   \n","43725                            2.0                        165.0   \n","43726                            1.0                         66.0   \n","43727                            2.0                        165.0   \n","43728                            1.0                         66.0   \n","\n","       ToInternetUdpPort443Packet  ToInternetUdpPort443Byte  \\\n","0                             0.0                       0.0   \n","1                             0.0                       0.0   \n","2                             0.0                       0.0   \n","3                             0.0                       0.0   \n","4                             0.0                       0.0   \n","...                           ...                       ...   \n","43724                        26.0                   18572.0   \n","43725                         8.0                    4143.0   \n","43726                        17.0                    9789.0   \n","43727                         7.0                    3767.0   \n","43728                       210.0                   23305.0   \n","\n","       ToInternetTcpPort5228Packet  ToInternetTcpPort5228Byte  \n","0                              0.0                        0.0  \n","1                              0.0                        0.0  \n","2                              0.0                        0.0  \n","3                              0.0                        0.0  \n","4                              0.0                        0.0  \n","...                            ...                        ...  \n","43724                          1.0                       66.0  \n","43725                          3.0                      231.0  \n","43726                          1.0                       66.0  \n","43727                          3.0                      231.0  \n","43728                          1.0                       66.0  \n","\n","[570460 rows x 256 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","df=df.replace(np.nan, 0.0)\n","df"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1675499460007,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"sxjXg14hdxuw"},"outputs":[],"source":["def proportion(df, col):\n","    df = df[col].value_counts(normalize=True) * 100\n","    df = df.to_frame()\n","    df.reset_index(inplace=True)\n","    df.columns = [col, '%']\n","    return df\n","def proportion_2(df):\n","    df = df.value_counts(normalize=True) * 100\n","    df = df.to_frame()\n","    df.reset_index(inplace=True)\n","    return df"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1675499460008,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"7K2a8e-dfArU","outputId":"89b5b688-d7fa-4320-a7c4-165c060a0587"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.596817\n","1       1   0.403183\n"]}],"source":["print(proportion(df,'Attack'))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499460845,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"FECIarFkfDws","outputId":"5128a662-3b2f-40fe-b181-c7edacfff181"},"outputs":[{"name":"stdout","output_type":"stream","text":["    AttackType          %\n","0           45  99.596817\n","1           25   0.022789\n","2           24   0.021211\n","3           26   0.021036\n","4           30   0.021036\n","5           32   0.020860\n","6           31   0.019107\n","7            2   0.017530\n","8            1   0.017530\n","9            0   0.017004\n","10           3   0.012271\n","11           4   0.012271\n","12           5   0.012271\n","13          13   0.012271\n","14          12   0.012271\n","15          14   0.011920\n","16           7   0.010518\n","17           8   0.010518\n","18           6   0.010518\n","19          17   0.007012\n","20          16   0.007012\n","21          15   0.007012\n","22          11   0.007012\n","23          10   0.007012\n","24           9   0.007012\n","25          42   0.005434\n","26          33   0.005259\n","27          43   0.005259\n","28          41   0.005259\n","29          40   0.005259\n","30          39   0.005259\n","31          37   0.005259\n","32          38   0.005259\n","33          44   0.005259\n","34          35   0.005259\n","35          36   0.005084\n","36          34   0.005084\n","37          27   0.001753\n","38          23   0.001753\n","39          21   0.001753\n","40          20   0.001753\n","41          19   0.001753\n","42          29   0.001753\n","43          28   0.001753\n","44          22   0.001753\n","45          18   0.001227\n"]}],"source":["print(proportion(df,'AttackType'))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499462673,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"U-bREc4TFpc4","outputId":"67858b0f-653a-466c-9253-14437cce9af4"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.421571\n","1       1   0.578429\n","    AttackType          %\n","0           45  99.421571\n","1           32   0.028424\n","2           25   0.028424\n","3           26   0.028424\n","4           24   0.028424\n","5           30   0.028424\n","6           15   0.014212\n","7           11   0.014212\n","8           27   0.014212\n","9           28   0.014212\n","10          29   0.014212\n","11          17   0.014212\n","12          16   0.014212\n","13           9   0.014212\n","14          19   0.014212\n","15          20   0.014212\n","16          21   0.014212\n","17          22   0.014212\n","18          23   0.014212\n","19          10   0.014212\n","20          33   0.014212\n","21          35   0.014212\n","22          34   0.014212\n","23           1   0.014212\n","24           8   0.014212\n","25           7   0.014212\n","26           6   0.014212\n","27          12   0.014212\n","28          14   0.014212\n","29          13   0.014212\n","30           5   0.014212\n","31           4   0.014212\n","32           3   0.014212\n","33           0   0.014212\n","34           2   0.014212\n","35          31   0.014212\n","36          18   0.009948\n"]}],"source":["print(proportion(df_flow0,'Attack'))\n","print(proportion(df_flow0,'AttackType'))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499464803,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"mdvvEkTDFdLn","outputId":"8547ed24-5c5f-413b-a546-24a3da30ad1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.320801\n","1       1   0.679199\n","    AttackType          %\n","0           45  99.320801\n","1            3   0.022869\n","2           43   0.022869\n","3           42   0.022869\n","4           24   0.022869\n","5           26   0.022869\n","6           25   0.022869\n","7           41   0.022869\n","8           40   0.022869\n","9           39   0.022869\n","10          12   0.022869\n","11          13   0.022869\n","12          17   0.022869\n","13          16   0.022869\n","14          15   0.022869\n","15          32   0.022869\n","16          30   0.022869\n","17          37   0.022869\n","18          38   0.022869\n","19           0   0.022869\n","20           2   0.022869\n","21           1   0.022869\n","22           8   0.022869\n","23           7   0.022869\n","24           6   0.022869\n","25           5   0.022869\n","26           4   0.022869\n","27          44   0.022869\n","28          31   0.020582\n","29          36   0.020582\n","30          14   0.020582\n"]}],"source":["print(proportion(df_flow1,'Attack'))\n","print(proportion(df_flow1,'AttackType'))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499466196,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"SFsEuxknFtox","outputId":"ee9185c8-0202-490b-8f01-5d296d5877d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.796469\n","1       1   0.203531\n","   AttackType          %\n","0          45  99.796469\n","1           1   0.022869\n","2           2   0.022869\n","3           0   0.022869\n","4           9   0.022869\n","5          10   0.022869\n","6          11   0.022869\n","7          33   0.022869\n","8          35   0.022869\n","9          34   0.020582\n"]}],"source":["print(proportion(df_flow2,'Attack'))\n","print(proportion(df_flow2,'AttackType'))"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":676,"status":"ok","timestamp":1675499467378,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"HCvBNFo5FjK5","outputId":"a19d3bbc-3327-476c-cac0-f4103c6f4f90"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.619161\n","1       1   0.380839\n","    AttackType          %\n","0           45  99.619161\n","1           30   0.028421\n","2           25   0.028421\n","3           26   0.028421\n","4           24   0.028421\n","5           31   0.028421\n","6           32   0.027000\n","7           16   0.014210\n","8           15   0.014210\n","9            8   0.014210\n","10           7   0.014210\n","11           6   0.014210\n","12          17   0.014210\n","13          12   0.014210\n","14           1   0.014210\n","15          13   0.014210\n","16           5   0.014210\n","17           4   0.014210\n","18           3   0.014210\n","19           0   0.014210\n","20           2   0.014210\n","21          14   0.012789\n"]}],"source":["print(proportion(df_flow3,'Attack'))\n","print(proportion(df_flow3,'AttackType'))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1675499469326,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"vAKusTQXF4h4","outputId":"a0ff6f6f-5d9f-468c-b5e5-6220de2ec60c"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack         %\n","0       0  99.70579\n","1       1   0.29421\n","    AttackType          %\n","0           45  99.705790\n","1           25   0.028426\n","2           26   0.028426\n","3           24   0.028426\n","4           30   0.028426\n","5           31   0.028426\n","6           32   0.028426\n","7            1   0.014213\n","8            2   0.014213\n","9            3   0.014213\n","10           4   0.014213\n","11           5   0.014213\n","12          13   0.014213\n","13          14   0.014213\n","14          12   0.014213\n","15           0   0.009949\n"]}],"source":["print(proportion(df_flow4,'Attack'))\n","print(proportion(df_flow4,'AttackType'))"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675499471158,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"zE3guiIqF7pA","outputId":"ef5b9cc2-c56f-401f-beb5-56ded4d2e01a"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.931405\n","1       1   0.068595\n","   AttackType          %\n","0          45  99.931405\n","1           1   0.022865\n","2           2   0.022865\n","3           0   0.022865\n"]}],"source":["print(proportion(df_flow5,'Attack'))\n","print(proportion(df_flow5,'AttackType'))"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675499471993,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"GgSJXXLjF9E4","outputId":"94f4bff5-4adf-47a8-9e0d-5698f734036c"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.656986\n","1       1   0.343014\n","    AttackType          %\n","0           45  99.656986\n","1            1   0.022868\n","2            2   0.022868\n","3            0   0.022868\n","4            9   0.022868\n","5           10   0.022868\n","6           11   0.022868\n","7            6   0.022868\n","8            7   0.022868\n","9            8   0.022868\n","10          15   0.022868\n","11          16   0.022868\n","12          17   0.022868\n","13          33   0.022868\n","14          34   0.022868\n","15          35   0.022868\n"]}],"source":["print(proportion(df_flow6,'Attack'))\n","print(proportion(df_flow6,'AttackType'))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499475993,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"daE558PaF-gQ","outputId":"bf18bbfc-7765-408a-8fdc-315d84b1324b"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.658897\n","1       1   0.341103\n","    AttackType          %\n","0           45  99.658897\n","1           25   0.028425\n","2           32   0.028425\n","3           31   0.028425\n","4           30   0.028425\n","5           26   0.028425\n","6           24   0.028425\n","7            5   0.014213\n","8            4   0.014213\n","9            1   0.014213\n","10          13   0.014213\n","11          14   0.014213\n","12          12   0.014213\n","13           3   0.014213\n","14           0   0.014213\n","15           2   0.014213\n","16           6   0.014213\n","17           7   0.014213\n","18           8   0.014213\n"]}],"source":["print(proportion(df_flow7,'Attack'))\n","print(proportion(df_flow7,'AttackType'))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499476551,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"yzeKeOe2F_54","outputId":"140a4734-8e26-4f9c-fb36-221c98f8d819"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.488331\n","1       1   0.511669\n","    AttackType          %\n","0           45  99.488331\n","1           25   0.028426\n","2           31   0.028426\n","3           30   0.028426\n","4           24   0.028426\n","5           26   0.028426\n","6           32   0.028426\n","7            5   0.014213\n","8            4   0.014213\n","9           40   0.014213\n","10          39   0.014213\n","11          36   0.014213\n","12          37   0.014213\n","13          38   0.014213\n","14          11   0.014213\n","15          10   0.014213\n","16           9   0.014213\n","17          44   0.014213\n","18          43   0.014213\n","19          42   0.014213\n","20           8   0.014213\n","21           7   0.014213\n","22           6   0.014213\n","23           1   0.014213\n","24           2   0.014213\n","25           0   0.014213\n","26          12   0.014213\n","27          14   0.014213\n","28          13   0.014213\n","29           3   0.014213\n","30          41   0.014213\n"]}],"source":["print(proportion(df_flow8,'Attack'))\n","print(proportion(df_flow8,'AttackType'))"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675499479094,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"obuxmb0OGBq3","outputId":"f11e945b-6867-4674-f462-ced24f2d6bfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Attack          %\n","0       0  99.423723\n","1       1   0.576277\n","    AttackType          %\n","0           45  99.423723\n","1           25   0.045736\n","2           42   0.025155\n","3           24   0.025155\n","4           38   0.022868\n","5           43   0.022868\n","6           26   0.022868\n","7           32   0.022868\n","8           31   0.022868\n","9           30   0.022868\n","10          36   0.022868\n","11          37   0.022868\n","12          41   0.022868\n","13           1   0.022868\n","14          40   0.022868\n","15          39   0.022868\n","16          12   0.022868\n","17          14   0.022868\n","18          13   0.022868\n","19           5   0.022868\n","20           4   0.022868\n","21           3   0.022868\n","22           0   0.022868\n","23           2   0.022868\n","24          44   0.022868\n"]}],"source":["print(proportion(df_flow9,'Attack'))\n","print(proportion(df_flow9,'AttackType'))"]},{"cell_type":"markdown","metadata":{"id":"DOatPtMXyeid"},"source":["## dataset"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675499484409,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"5XqCK-bl_3Rn"},"outputs":[],"source":["y = df['Attack']\n","df_new = df.loc[df['Attack'] == 1]\n","y_attacktype = df_new['AttackType']\n","df = df.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":421,"status":"ok","timestamp":1675499484829,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"1fR6N19UMUuz"},"outputs":[],"source":["y_0 = df_flow0['Attack']\n","df_flow0_new = df_flow0.loc[df_flow0['Attack'] == 1]\n","y_0_attacktype = df_flow0_new['AttackType']\n","df_0 = df_flow0.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_1 = df_flow1['Attack']\n","df_flow1_new = df_flow1.loc[df_flow1['Attack'] == 1]\n","y_1_attacktype = df_flow1_new['AttackType']\n","df_1 = df_flow1.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_2 = df_flow2['Attack']\n","df_flow2_new = df_flow2.loc[df_flow2['Attack'] == 1]\n","y_2_attacktype = df_flow2_new['AttackType']\n","df_2 = df_flow2.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_3 = df_flow3['Attack']\n","df_flow3_new = df_flow3.loc[df_flow3['Attack'] == 1]\n","y_3_attacktype = df_flow3_new['AttackType']\n","df_3 = df_flow3.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_4 = df_flow4['Attack']\n","df_flow4_new = df_flow4.loc[df_flow4['Attack'] == 1]\n","y_4_attacktype = df_flow4_new['AttackType']\n","df_4 = df_flow4.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_5 = df_flow5['Attack']\n","df_flow5_new = df_flow5.loc[df_flow5['Attack'] == 1]\n","y_5_attacktype = df_flow5_new['AttackType']\n","df_5 = df_flow5.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_6 = df_flow6['Attack']\n","df_flow6_new = df_flow6.loc[df_flow6['Attack'] == 1]\n","y_6_attacktype = df_flow6_new['AttackType']\n","df_6 = df_flow6.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_7 = df_flow7['Attack']\n","df_flow7_new = df_flow7.loc[df_flow7['Attack'] == 1]\n","y_7_attacktype = df_flow7_new['AttackType']\n","df_7 = df_flow7.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_8 = df_flow8['Attack']\n","df_flow8_new = df_flow8.loc[df_flow8['Attack'] == 1]\n","y_8_attacktype = df_flow8_new['AttackType']\n","df_8 = df_flow8.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","\n","y_9 = df_flow9['Attack']\n","df_flow9_new = df_flow9.loc[df_flow9['Attack'] == 1]\n","y_9_attacktype = df_flow9_new['AttackType']\n","df_9 = df_flow9.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499486206,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"Oq8LkIqzDpPx"},"outputs":[],"source":["df_new = df_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_0_new = df_flow0_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_1_new = df_flow1_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_2_new = df_flow2_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_3_new = df_flow3_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_4_new = df_flow4_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_5_new = df_flow5_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_6_new = df_flow6_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_7_new = df_flow7_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_8_new = df_flow8_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)\n","df_9_new = df_flow9_new.drop(['Attack',' NoOfFlows','AttackType'], axis = 1)"]},{"cell_type":"markdown","metadata":{"id":"psBmivT3XgNb"},"source":["# Build Model"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499488521,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"i1twzFI8qOUw"},"outputs":[],"source":["import sklearn\n","import statistics\n","from sklearn import metrics\n","from sklearn.datasets import make_blobs\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import time"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499490281,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"GBuqfxsn2Fgb"},"outputs":[],"source":["def model(df, y, rf, grid, cv):\n","    X_train = X_test = y_train = y_test = []\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=100000)\n","    for train_index, test_index in sss.split(df, y):\n","      X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n","      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","    grid_search_rf = GridSearchCV(estimator=rf, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1_weighted',error_score=0)\n","    grid_result_rf = grid_search_rf.fit(X_train, y_train)\n","\n","    print(\"Best: %f using %s\" % (grid_result_rf.best_score_, grid_result_rf .best_params_))\n","    print(\"Time taken to run Random Forest = \", grid_result_rf.refit_time_, \"seconds\")\n","    print(grid_result_rf.best_estimator_)\n","    scores_train = cross_val_score(grid_result_rf.best_estimator_, X_train, y_train, cv=cv, scoring='f1_weighted')\n","    print(\"On all train set, mean of scores: %f, scores: %s\" % (scores_train.mean(), scores_train))\n","    predictions = grid_result_rf.predict(X_test)\n","    score_test = grid_result_rf.score(X_test, y_test)\n","    print(\"On test set, Accuracy: %f\" % score_test)\n","    \n","    report = classification_report(y_test, predictions)\n","    print(report)\n","    conf_matrix = metrics.confusion_matrix(y_test, predictions)\n","    fp = conf_matrix.sum(axis = 0) - np.diag(conf_matrix)\n","    fn = conf_matrix.sum(axis = 1) - np.diag(conf_matrix)\n","    tp = np.diag(conf_matrix)\n","    tn = conf_matrix[:].sum() - (fp + fn + tp)\n","    FPR = fp/(fp+tn)\n","    fpr = statistics.mean(FPR)\n","    print(\"FPR: %f\" % fpr)\n","    \n","\n","    means = grid_result_rf.cv_results_['mean_test_score']\n","    stds = grid_result_rf.cv_results_['std_test_score']\n","    params = grid_result_rf.cv_results_['params']\n","    for mean, stdev, param in zip(means, stds, params):\n","        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n","    "]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":841,"status":"ok","timestamp":1675499493459,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"VciClzCzwZb6"},"outputs":[],"source":["def client_server(df, y, model, grid, cv):\n","    X_train = X_test = y_train = y_test = []\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=100000)\n","    for train_index, test_index in sss.split(df, y):\n","      X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n","      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    print(\"y_train \",proportion_2(y_train))\n","    print(\"y_test \",proportion_2(y_test))\n","\n","    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1_weighted',error_score=0)\n","    grid_result = grid_search.fit(X_train, y_train)\n","    \n","    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","    scores_train = cross_val_score(grid_result.best_estimator_, X_train, y_train, cv=cv, scoring='f1_weighted')\n","    print(\"On all train set, mean of scores: %f, scores: %s\" % (scores_train.mean(), scores_train))\n","    predictions = grid_result.predict(X_test)\n","    score_test = grid_result.score(X_test, y_test)\n","    print(\"On test set, Accuracy: %f\" % score_test)\n","\n","    report = classification_report(y_test, predictions)\n","    print(report)\n","    conf_matrix = metrics.confusion_matrix(y_test, predictions)\n","    fp = conf_matrix.sum(axis = 0) - np.diag(conf_matrix)\n","    fn = conf_matrix.sum(axis = 1) - np.diag(conf_matrix)\n","    tp = np.diag(conf_matrix)\n","    tn = conf_matrix[:].sum() - (fp + fn + tp)\n","    FPR = fp/(fp+tn)\n","    fpr = statistics.mean(FPR)\n","    print(\"FPR: %f\" % fpr)\n","    \n","    print(\"================================================================================\")\n","    return score_test, fpr"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":708,"status":"ok","timestamp":1675499494791,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"zw3Y3VtyIdCz"},"outputs":[],"source":["def federated_learning(n, model, grid, cv,\n","                       df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                       df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9):\n","    \n","    print(\"0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\")\n","    best_0, fpr_0 = client_server(df_0, y_0, model, grid, cv)\n","    print(\"1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\")\n","    best_1, fpr_1 = client_server(df_1, y_1, model, grid, cv)\n","    print(\"2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\")\n","    best_2, fpr_2 = client_server(df_2, y_2, model, grid, cv)\n","    print(\"3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\")\n","    best_3, fpr_3 = client_server(df_3, y_3, model, grid, cv)\n","    print(\"4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\")\n","    best_4, fpr_4 = client_server(df_4, y_4, model, grid, cv)\n","    print(\"5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\")\n","    best_5, fpr_5 = client_server(df_5, y_5, model, grid, cv)\n","    print(\"6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\")\n","    best_6, fpr_6 = client_server(df_6, y_6, model, grid, cv)\n","    print(\"7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\")\n","    best_7, fpr_7 = client_server(df_7, y_7, model, grid, cv)\n","    print(\"8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\")\n","    best_8, fpr_8 = client_server(df_8, y_8, model, grid, cv)\n","    print(\"9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\")\n","    best_9, fpr_9 = client_server(df_9, y_9, model, grid, cv)\n","    mean_acc = np.mean([best_0, best_1, best_2, best_3, best_4, best_5, best_6, best_7, best_8, best_9])\n","    mean_fpr = np.mean([fpr_0, fpr_1, fpr_2, fpr_3, fpr_4, fpr_5, fpr_6, fpr_7, fpr_8, fpr_9])\n","    print(\"Federated Learning: Round: %d, Accuracy: %f, FPR: %f\" % (n, mean_acc, mean_fpr))"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675499496910,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"N--PlXmQ7uOk"},"outputs":[],"source":["def federated_learning_group(n, model_camera, grid_camera, cv_camera,\n","                       model_appliances, grid_appliances, cv_appliances,\n","                       model_energy, grid_energy, cv_energy,\n","                       model_controller, grid_controller, cv_controller,\n","                       df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                       df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9):\n","  \n","    print(\"0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\")\n","    best_0, fpr_0 = client_server(df_0, y_0, model_camera, grid_camera, cv_camera)\n","    print(\"1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\")\n","    best_1, fpr_1 = client_server(df_1, y_1, model_energy, grid_energy, cv_energy)\n","    print(\"2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\")\n","    best_2, fpr_2 = client_server(df_2, y_2, model_controller, grid_controller, cv_controller)\n","    print(\"3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\")\n","    best_3, fpr_3 = client_server(df_3, y_3, model_energy, grid_energy, cv_energy)\n","    print(\"4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\")\n","    best_4, fpr_4 = client_server(df_4, y_4, model_camera, grid_camera, cv_camera)\n","    print(\"5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\")\n","    best_5, fpr_5 = client_server(df_5, y_5, model_energy, grid_energy, cv_energy)\n","    print(\"6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\")\n","    best_6, fpr_6 = client_server(df_6, y_6, model_energy, grid_energy, cv_energy)\n","    print(\"7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\")\n","    best_7, fpr_7 = client_server(df_7, y_7, model_energy, grid_energy, cv_energy)\n","    print(\"8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\")\n","    best_8, fpr_8 = client_server(df_8, y_8, model_energy, grid_energy, cv_energy)\n","    print(\"9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\")\n","    best_9, fpr_9 = client_server(df_9, y_9, model_appliances, grid_appliances, cv_appliances)\n","\n","    camera_acc = np.mean([best_0, best_4])\n","    print(\"Camera group: Device 0 and Device 4, Accuracy: %f\" % camera_acc)\n","    appliances_acc = np.mean([best_9])\n","    print(\"Appliances group: Device 9, Accuracy: %f\" % appliances_acc)\n","    controller_acc = np.mean([best_2])\n","    print(\"Controller group: Device 2, Accuracy: %f\" % controller_acc)\n","    energy_acc = np.mean([best_1, best_3, best_5, best_6, best_7, best_8])\n","    print(\"Energy group: Device 1,3,5,6,7 and 8, Accuracy: %f\" % energy_acc)\n","\n","    mean_acc = np.mean([best_0, best_1, best_2, best_3, best_4, best_5, best_6, best_7, best_8, best_9])\n","    mean_fpr = np.mean([fpr_0, fpr_1, fpr_2, fpr_3, fpr_4, fpr_5, fpr_6, fpr_7, fpr_8, fpr_9])\n","    print(\"Federated Group: Round: %d, Accuracy: %f, FPR: %f\" % (n, mean_acc, mean_fpr))\n","    "]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1675499498723,"user":{"displayName":"Nikki Zhang","userId":"17298851517668756572"},"user_tz":-660},"id":"yq3zqVQQLvDg"},"outputs":[],"source":["cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=100000)"]},{"cell_type":"markdown","metadata":{"id":"RMuhkCTKYaa8"},"source":["### EL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjtkFuOjCkOq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"L-tVtSvGCkh3"},"source":["#### EL: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15190747,"status":"ok","timestamp":1643216784007,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"ypzB4WcQCkh4","outputId":"05e7d7c8-91cc-404c-87b4-ccdcb418aff1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best: 0.998490 using {'knn__n_neighbors': 1}\n","Time taken to run Random Forest =  1932.6440844535828 seconds\n","StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=1)),\n","                               ('cart', DecisionTreeClassifier())],\n","                   final_estimator=LogisticRegression())\n","On all train set, mean of scores: 0.998473, scores: [0.99819344 0.99838618 0.99878433 0.99860139 0.9984004 ]\n","On test set, Accuracy: 0.998473\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00    113632\n","           1       0.81      0.81      0.81       460\n","\n","    accuracy                           1.00    114092\n","   macro avg       0.91      0.90      0.90    114092\n","weighted avg       1.00      1.00      1.00    114092\n","\n","FPR: 0.096031\n","0.998490 (0.000162) with: {'knn__n_neighbors': 1}\n","Time taken to run EL =  15186.571796178818 seconds\n"]}],"source":["from sklearn.ensemble import StackingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","start_time_EL=time.time()\n","\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","rf_attackornot = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","grid = {'knn__n_neighbors': [1]}\n","\n","model(df, y, rf_attackornot, grid, cv)\n","elapsed_time_EL = time.time() - start_time_EL\n","print(\"Time taken to run EL = \", elapsed_time_EL, \"seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18754638,"status":"ok","timestamp":1643235539675,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"zXm8tf9UCkh4","outputId":"1fde6cc7-3c12-46ae-fbb6-d10ef680f582"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best: 0.998456 using {'knn__n_neighbors': 2}\n","Time taken to run Random Forest =  2516.6892161369324 seconds\n","StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=2)),\n","                               ('cart', DecisionTreeClassifier())],\n","                   final_estimator=LogisticRegression())\n","On all train set, mean of scores: 0.998446, scores: [0.99825409 0.99835749 0.99873758 0.99850974 0.99837302]\n","On test set, Accuracy: 0.998446\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00    113632\n","           1       0.81      0.80      0.81       460\n","\n","    accuracy                           1.00    114092\n","   macro avg       0.90      0.90      0.90    114092\n","weighted avg       1.00      1.00      1.00    114092\n","\n","FPR: 0.098209\n","0.998456 (0.000182) with: {'knn__n_neighbors': 2}\n","Time taken to run EL =  18754.608894109726 seconds\n"]}],"source":["start_time_EL1=time.time()\n","\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","rf_attackornot = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","grid = {'knn__n_neighbors': [2]}\n","\n","model(df, y, rf_attackornot, grid, cv)\n","elapsed_time_EL1 = time.time() - start_time_EL1\n","print(\"Time taken to run EL = \", elapsed_time_EL1, \"seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BFwVe3KKzI5q","outputId":"f2ed2f8b-ee3b-4f9c-9824-eb6eb11fc39b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best: 0.998440 using {'knn__n_neighbors': 3}\n","Time taken to run Random Forest =  2716.094496011734 seconds\n","StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=3)),\n","                               ('cart', DecisionTreeClassifier())],\n","                   final_estimator=LogisticRegression())\n"]}],"source":["start_time_EL2=time.time()\n","\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","rf_attackornot = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","grid = {'knn__n_neighbors': [3]}\n","\n","model(df, y, rf_attackornot, grid, cv)\n","elapsed_time_EL2 = time.time() - start_time_EL2\n","print(\"Time taken to run EL = \", elapsed_time_EL2, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"aMlKzYd4Cpfs"},"source":["#### FedAvg_EL: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"OnS2EvpNCpfw"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.998028 using {'knn__n_neighbors': 1}\n"]}],"source":["from sklearn.ensemble import StackingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","start_time_EL=time.time()\n","\n","n_neighbors = [1]\n","\n","# max_depth = [10, 20, 30, 40]\n","# min_samples_split = [0.1, 1.0]\n","# min_samples_leaf = [1, 2, 3]\n","\n","estimators = [('knn', KNeighborsClassifier(leaf_size = 1, p=1)), ('cart', DecisionTreeClassifier(max_depth = 10))]\n","model_EL1 = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","# grid_EL1 = {'knn__n_neighbors': n_neighbors,'cart__max_depth': max_depth}\n","grid_EL1 = {'knn__n_neighbors': n_neighbors}\n","federated_learning(1, model_EL1, grid_EL1, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_EL = time.time() - start_time_EL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9284,"status":"ok","timestamp":1643177283194,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"DgScArkZCpfw","outputId":"234e1979-9758-4590-e888-0787009132c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.989538 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.989538, scores: [1.         0.97948718 1.         0.98358974 0.98461538]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        82\n","   macro avg       1.00      1.00      1.00        82\n","weighted avg       1.00      1.00      1.00        82\n","\n","FPR: 0.000000\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n","FPR: 0.000000\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        18\n","   macro avg       1.00      1.00      1.00        18\n","weighted avg       1.00      1.00      1.00        18\n","\n","FPR: 0.000000\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n","FPR: 0.000000\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","FPR: 0.000000\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 0.964444\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      0.50      0.67         2\n","          34       0.67      1.00      0.80         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.97        30\n","   macro avg       0.98      0.97      0.96        30\n","weighted avg       0.98      0.97      0.96        30\n","\n","FPR: 0.002381\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        48\n","   macro avg       1.00      1.00      1.00        48\n","weighted avg       1.00      1.00      1.00        48\n","\n","FPR: 0.000000\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.983218 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 0.983218, scores: [0.98275862 1.         1.         0.98128655 0.95204678]\n","On test set, Accuracy: 0.985185\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       1.00      1.00      1.00         2\n","          37       0.67      1.00      0.80         2\n","          38       1.00      0.50      0.67         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.99        72\n","   macro avg       0.99      0.98      0.98        72\n","weighted avg       0.99      0.99      0.99        72\n","\n","FPR: 0.000476\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.945748 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 0.945748, scores: [0.91707317 0.95       0.97333333 0.97333333 0.915     ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         3\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        51\n","   macro avg       1.00      1.00      1.00        51\n","weighted avg       1.00      1.00      1.00        51\n","\n","FPR: 0.000000\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.994963, FPR: 0.000286\n","Time taken to run Federated Learning with EL as initial model =  370.67774238586424 seconds\n"]}],"source":["start_time_EL2=time.time()\n","\n","print(\"Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\")\n","n_neighbors = [2]\n","leaf_size = [1]\n","p=[1]\n","max_depth = [10]\n","min_samples_split = [0.4]\n","min_samples_leaf = [1]\n","\n","# penalty = 'l1', solver = 'liblinear'\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","model_EL2 = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","grid_EL2 = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","federated_learning(2, model_EL2, grid_EL2, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_RF2 = time.time() - start_time_EL\n","print(\"Time taken to run Federated Learning with EL as initial model = \", elapsed_time_RF2/10 , \"seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSq4Bug5Cpfw"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"c65ve_UyCuhP"},"source":["#### FedGroup_EL: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9361,"status":"ok","timestamp":1643177854693,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"CthS6rN4CuhP","outputId":"14ea2cbe-16b1-4157-d997-41f30d773a07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.989538 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.989538, scores: [1.         0.97948718 1.         0.98358974 0.98461538]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        82\n","   macro avg       1.00      1.00      1.00        82\n","weighted avg       1.00      1.00      1.00        82\n","\n","FPR: 0.000000\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 0.995745 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 0.995745, scores: [1.        1.        1.        0.9787234 1.       ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n","FPR: 0.000000\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        18\n","   macro avg       1.00      1.00      1.00        18\n","weighted avg       1.00      1.00      1.00        18\n","\n","FPR: 0.000000\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n","FPR: 0.000000\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","FPR: 0.000000\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 0.964444\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.97        30\n","   macro avg       0.98      0.97      0.96        30\n","weighted avg       0.98      0.97      0.96        30\n","\n","FPR: 0.002381\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        48\n","   macro avg       1.00      1.00      1.00        48\n","weighted avg       1.00      1.00      1.00        48\n","\n","FPR: 0.000000\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.979556 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 0.979556, scores: [0.95977011 1.         1.         1.         0.9380117 ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        72\n","   macro avg       1.00      1.00      1.00        72\n","weighted avg       1.00      1.00      1.00        72\n","\n","FPR: 0.000000\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.962293 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","On all train set, mean of scores: 0.962293, scores: [0.94146341 0.95       0.94666667 1.         0.97333333]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         3\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        51\n","   macro avg       1.00      1.00      1.00        51\n","weighted avg       1.00      1.00      1.00        51\n","\n","FPR: 0.000000\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 1.000000\n","Appliances group: Device 9, Accuracy: 1.000000\n","Controller group: Device 2, Accuracy: 1.000000\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.994074\n","Federated Group: Round: 2, Accuracy: 0.996444, FPR: 0.000238\n","Time taken to run Federated Learning with Random Forest as initial model =  341.4309114933014 seconds\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","\n","# penalty = 'l1', solver = 'liblinear'\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","model_EL2 = model_camera = model_appliances = model_energy = model_controller = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","cv_EL2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","\n","# 0, 4\n","n_neighbors = [2]\n","leaf_size = [1]\n","p=[1]\n","max_depth = [10]\n","min_samples_split = [0.1]\n","min_samples_leaf = [1]\n","grid_camera = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","# 9\n","n_neighbors = [3]\n","leaf_size = [1]\n","p=[2]\n","max_depth = [10]\n","min_samples_split = [1.0]\n","min_samples_leaf = [1]\n","grid_appliances = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","# 1, 3, 5, 6, 7, 8\n","n_neighbors = [3]\n","leaf_size = [1]\n","p=[1]\n","max_depth = [10]\n","min_samples_split = [0.4]\n","min_samples_leaf = [1]\n","grid_energy = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","# 2\n","n_neighbors = [1]\n","leaf_size = [1]\n","p=[1]\n","max_depth = [10]\n","min_samples_split = [0.1]\n","min_samples_leaf = [1]\n","grid_controller = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","start_time_RF3 = time.time()\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_RF3 = time.time() - start_time_RF3 + elapsed_time_EL\n","print(\"Time taken to run Federated Learning with Random Forest as initial model = \", elapsed_time_RF3/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"8N9fnfP6ZKIp"},"source":["#### EL: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1591007,"status":"ok","timestamp":1643171467067,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"jn0g_3LEYcCz","outputId":"3985dbb2-9f01-42c0-b219-d229204ef94b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best: 0.983884 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","Time taken to run Random Forest =  0.8509836196899414 seconds\n","StackingClassifier(estimators=[('knn',\n","                                KNeighborsClassifier(leaf_size=3, n_neighbors=3,\n","                                                     p=1)),\n","                               ('cart', DecisionTreeClassifier(max_depth=10))],\n","                   final_estimator=LogisticRegression())\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.982779, scores: [0.97522942 0.98342941 0.97985205 0.98900327 0.98638047]\n","On test set, Accuracy: 0.979801\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        20\n","           2       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        14\n","           4       1.00      1.00      1.00        14\n","           5       1.00      1.00      1.00        14\n","           6       1.00      1.00      1.00        12\n","           7       1.00      1.00      1.00        12\n","           8       1.00      1.00      1.00        12\n","           9       1.00      1.00      1.00         8\n","          10       1.00      1.00      1.00         8\n","          11       1.00      1.00      1.00         8\n","          12       1.00      0.93      0.96        14\n","          13       0.88      1.00      0.93        14\n","          14       1.00      0.86      0.92        14\n","          15       1.00      1.00      1.00         8\n","          16       1.00      1.00      1.00         8\n","          17       1.00      1.00      1.00         8\n","          18       1.00      1.00      1.00         1\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       0.67      1.00      0.80         2\n","          23       1.00      0.50      0.67         2\n","          24       1.00      0.92      0.96        24\n","          25       0.93      1.00      0.96        26\n","          26       0.96      1.00      0.98        24\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00        24\n","          31       1.00      1.00      1.00        22\n","          32       1.00      1.00      1.00        24\n","          33       1.00      1.00      1.00         6\n","          34       1.00      1.00      1.00         6\n","          35       1.00      1.00      1.00         6\n","          36       1.00      0.50      0.67         6\n","          37       0.67      1.00      0.80         6\n","          38       1.00      1.00      1.00         6\n","          39       1.00      1.00      1.00         6\n","          40       1.00      1.00      1.00         6\n","          41       1.00      1.00      1.00         6\n","          42       1.00      1.00      1.00         6\n","          43       1.00      1.00      1.00         6\n","          44       1.00      1.00      1.00         6\n","\n","    accuracy                           0.98       460\n","   macro avg       0.98      0.97      0.97       460\n","weighted avg       0.98      0.98      0.98       460\n","\n","FPR: 0.000448\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.971076 (0.010779) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978833 (0.005851) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.971984 (0.003996) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982813 (0.003764) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975126 (0.008246) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977395 (0.005477) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.967231 (0.002951) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974792 (0.013259) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.968544 (0.013667) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.972144 (0.010622) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978833 (0.005851) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.971410 (0.004103) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982246 (0.004565) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974558 (0.008534) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977395 (0.005477) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.968886 (0.003873) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973131 (0.015164) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.967425 (0.011976) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.972144 (0.010622) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978833 (0.005851) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.972522 (0.004231) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983884 (0.004186) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974020 (0.008906) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977435 (0.003881) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.967784 (0.004113) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974238 (0.013065) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.966340 (0.015354) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.971611 (0.009937) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978833 (0.005851) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.971948 (0.004403) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983351 (0.003999) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974588 (0.008497) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977435 (0.003881) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.967790 (0.004443) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.975335 (0.013258) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.968000 (0.013509) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.972144 (0.010622) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978295 (0.005501) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.971415 (0.004105) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983884 (0.004186) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975091 (0.007708) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977983 (0.003828) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.968866 (0.003614) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974796 (0.013090) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969080 (0.012905) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.971606 (0.010648) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978833 (0.005851) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.972517 (0.004488) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983345 (0.003628) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975126 (0.008246) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978501 (0.004232) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.968866 (0.003614) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.975344 (0.013541) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.968553 (0.013926) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.972144 (0.010622) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978833 (0.005851) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.971989 (0.003997) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982807 (0.003367) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975121 (0.007665) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979040 (0.003968) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.969961 (0.002441) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974796 (0.013090) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.968536 (0.012482) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.972144 (0.010622) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978295 (0.005501) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.972522 (0.004231) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982240 (0.004242) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974049 (0.007602) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978496 (0.004671) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.969409 (0.002890) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974805 (0.013254) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.968542 (0.012581) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.974924 (0.005264) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969137 (0.004449) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.965833 (0.011220) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978564 (0.003842) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.958958 (0.006578) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973487 (0.015248) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959577 (0.016595) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.971606 (0.010648) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978833 (0.005851) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.973055 (0.004637) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983884 (0.004186) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974588 (0.007360) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979040 (0.003968) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.969409 (0.002890) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.975344 (0.013541) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969096 (0.014059) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.971076 (0.010779) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978295 (0.005501) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.972517 (0.004488) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983884 (0.004186) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974588 (0.007360) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979040 (0.003968) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.969948 (0.003106) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.975887 (0.013517) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969096 (0.014059) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.971069 (0.011315) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978833 (0.005851) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.973055 (0.004637) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983345 (0.003628) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976233 (0.007741) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979040 (0.003968) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.970500 (0.002581) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.975344 (0.013541) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969096 (0.014059) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.970539 (0.011413) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978295 (0.005501) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.972517 (0.004488) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983345 (0.003628) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974558 (0.007403) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979040 (0.003968) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.969411 (0.002767) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.975887 (0.013517) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969096 (0.014059) with: {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977489 (0.006211) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976403 (0.010741) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980217 (0.004625) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.973160 (0.004573) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.977359 (0.004329) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976943 (0.002823) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.972015 (0.007536) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.970972 (0.005664) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.969723 (0.008458) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.973042 (0.005945) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978160 (0.003774) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.974781 (0.008743) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978958 (0.003665) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.974749 (0.004442) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.977458 (0.003430) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975332 (0.003377) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.974802 (0.004604) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.971548 (0.003747) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.968050 (0.012147) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969780 (0.005732) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.976397 (0.005525) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976411 (0.009379) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978497 (0.005027) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.971972 (0.006016) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980060 (0.003251) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975701 (0.002620) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.974537 (0.006174) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.973807 (0.003638) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.972556 (0.006151) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.972942 (0.004902) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.976454 (0.005982) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.974178 (0.007294) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980731 (0.003864) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.974131 (0.004561) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979573 (0.001266) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976804 (0.003690) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.975849 (0.007654) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.974181 (0.005185) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.970795 (0.007704) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.971978 (0.008060) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977560 (0.004730) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976503 (0.007877) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.979585 (0.002226) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976937 (0.004487) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981101 (0.002846) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976116 (0.002304) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977339 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.971904 (0.001989) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.972925 (0.003470) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.975659 (0.006416) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977550 (0.004703) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975425 (0.008982) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981337 (0.003218) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.977489 (0.004033) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980473 (0.002600) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975692 (0.001299) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977361 (0.004060) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976936 (0.004220) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973988 (0.002898) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.972485 (0.006678) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977560 (0.004730) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975397 (0.007749) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981337 (0.004525) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.977494 (0.004026) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980509 (0.002377) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977437 (0.000998) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977405 (0.003326) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976493 (0.003804) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973492 (0.002391) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.973997 (0.007080) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977011 (0.004462) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977055 (0.007280) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.979661 (0.002187) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976385 (0.003707) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979879 (0.002321) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977773 (0.001599) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.976804 (0.003437) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.974173 (0.001498) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974446 (0.005873) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.975200 (0.007452) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.979214 (0.005875) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975455 (0.008047) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980832 (0.004542) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978573 (0.003256) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981739 (0.004595) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.980005 (0.003731) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978004 (0.004683) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.978561 (0.004778) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.969527 (0.009135) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.970485 (0.010705) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978645 (0.005822) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976524 (0.007679) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.979676 (0.004382) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.977533 (0.004064) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981796 (0.003669) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977916 (0.004772) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977410 (0.004476) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976798 (0.002191) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971285 (0.009678) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.971799 (0.007493) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978665 (0.005820) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976476 (0.007905) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981749 (0.002926) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976918 (0.003348) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982334 (0.002817) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976200 (0.002488) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978056 (0.004018) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977357 (0.004763) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973372 (0.008543) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.971070 (0.010746) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978646 (0.005567) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975431 (0.009953) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.982424 (0.004267) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.979125 (0.005196) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981699 (0.002978) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977805 (0.005081) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979039 (0.004898) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976242 (0.005216) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974393 (0.009654) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.970114 (0.010180) with: {'cart__max_depth': 20, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.976167 (0.004339) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975528 (0.004859) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.979730 (0.005312) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.975257 (0.006026) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.976258 (0.001347) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974291 (0.002752) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973379 (0.006518) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.973858 (0.002954) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.966513 (0.007496) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.964955 (0.011367) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977172 (0.005693) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976148 (0.008596) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978732 (0.005020) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.972913 (0.007173) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979896 (0.003540) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975231 (0.001901) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977071 (0.006287) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.974647 (0.001204) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.968328 (0.006744) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.966746 (0.009333) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977229 (0.004324) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975794 (0.007339) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980356 (0.005573) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.973130 (0.007332) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.978888 (0.003013) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976032 (0.004581) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.974636 (0.007706) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.971034 (0.003661) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967217 (0.007783) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.965400 (0.009076) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.976036 (0.004443) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.974979 (0.008055) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978629 (0.005280) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.974093 (0.004442) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980419 (0.001476) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974170 (0.003853) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.972356 (0.007654) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.971864 (0.006068) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967773 (0.008881) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.964550 (0.006584) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977011 (0.004462) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975717 (0.006193) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980275 (0.003921) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978032 (0.003940) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982078 (0.001333) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976143 (0.002084) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978021 (0.003968) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.974959 (0.005355) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.969343 (0.008260) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.973184 (0.005990) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978198 (0.004789) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975700 (0.006209) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980204 (0.003545) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978565 (0.003313) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981562 (0.002910) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977349 (0.001171) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978563 (0.003417) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976032 (0.004127) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971236 (0.004657) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.972748 (0.005274) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977011 (0.004462) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976250 (0.005223) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980816 (0.004636) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976440 (0.002771) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980488 (0.002454) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977419 (0.000974) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.974712 (0.004074) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.975230 (0.003171) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.972351 (0.006376) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.972904 (0.006617) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978132 (0.004899) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976269 (0.004641) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980719 (0.002369) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976569 (0.003906) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979480 (0.001202) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976824 (0.002010) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977920 (0.004022) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977342 (0.006431) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.975145 (0.007316) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.971263 (0.005808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.979254 (0.005764) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977605 (0.008392) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980166 (0.003226) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.977499 (0.005058) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982782 (0.002258) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.979572 (0.003878) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.976812 (0.003820) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976985 (0.003817) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971663 (0.010009) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969828 (0.010681) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.979198 (0.005891) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977056 (0.007068) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980161 (0.004095) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978008 (0.004011) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982848 (0.002195) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977735 (0.001598) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977402 (0.004188) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.975805 (0.002199) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973207 (0.011455) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969950 (0.013110) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.979184 (0.005866) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977596 (0.005636) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980733 (0.004679) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976877 (0.003363) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981062 (0.003426) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976219 (0.001350) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978444 (0.004831) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977872 (0.002564) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973117 (0.010020) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.962831 (0.011797) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.979218 (0.005876) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977026 (0.006637) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981876 (0.004263) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978101 (0.003405) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981676 (0.002946) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.980074 (0.003364) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979039 (0.004898) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977888 (0.002549) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973131 (0.006821) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969396 (0.012703) with: {'cart__max_depth': 30, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.976439 (0.005404) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.974742 (0.009678) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978005 (0.003716) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976942 (0.004083) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.978794 (0.002705) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976811 (0.002274) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973960 (0.008798) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.972735 (0.003717) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.968688 (0.004996) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.965557 (0.009558) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.976267 (0.003534) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975835 (0.007602) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.977346 (0.005560) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.974721 (0.005617) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.976149 (0.006600) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976847 (0.002705) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.972828 (0.008703) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.972509 (0.005147) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.969559 (0.006134) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.967341 (0.007033) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.976692 (0.005055) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.971829 (0.003204) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978409 (0.006465) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.974000 (0.004452) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.977547 (0.001843) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975100 (0.004244) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973758 (0.004831) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.971643 (0.004002) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967243 (0.007094) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.966811 (0.006646) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977033 (0.004116) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975474 (0.005991) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.976747 (0.005472) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976978 (0.004985) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.978555 (0.003270) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974456 (0.002518) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.972154 (0.007601) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.972173 (0.007979) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.965408 (0.008744) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.967617 (0.009911) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978132 (0.004899) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.974008 (0.005488) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.979406 (0.005037) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976662 (0.005190) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980483 (0.001968) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.978469 (0.003111) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977425 (0.003371) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976252 (0.004373) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971010 (0.006403) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.970174 (0.006593) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977530 (0.003647) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976569 (0.007823) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.979003 (0.002747) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976382 (0.002754) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982164 (0.001479) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977052 (0.002638) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979038 (0.003901) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.975709 (0.003562) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974303 (0.004927) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.972054 (0.005419) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977046 (0.005593) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977035 (0.006631) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980628 (0.001928) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976393 (0.004169) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979939 (0.002148) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976051 (0.001724) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977561 (0.002354) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977491 (0.002734) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973493 (0.001502) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969381 (0.006271) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978185 (0.004507) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977043 (0.007292) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981338 (0.003105) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978546 (0.004150) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981713 (0.002346) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977081 (0.001031) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978054 (0.004075) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976053 (0.005825) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.969299 (0.007884) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.972050 (0.004897) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.979279 (0.004963) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977016 (0.006651) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981882 (0.003273) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978018 (0.004968) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982848 (0.002195) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977740 (0.002533) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978024 (0.003111) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.978936 (0.003859) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973242 (0.009487) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.968348 (0.008119) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978133 (0.005355) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977669 (0.006749) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981314 (0.004085) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978008 (0.004011) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.983411 (0.001767) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.978386 (0.001959) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.976928 (0.003298) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977972 (0.003534) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971138 (0.009419) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969012 (0.009646) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.979279 (0.004963) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977035 (0.006638) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980704 (0.003509) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.977456 (0.003338) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982782 (0.002258) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.978284 (0.001976) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978519 (0.003435) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976919 (0.003894) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971087 (0.012231) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.969343 (0.010470) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978097 (0.005452) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977007 (0.006649) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980724 (0.003525) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978038 (0.004642) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982883 (0.002591) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977347 (0.001243) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978482 (0.003410) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977299 (0.004776) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973347 (0.009621) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.967897 (0.012805) with: {'cart__max_depth': 40, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.975506 (0.004351) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976701 (0.007013) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978649 (0.004257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.973764 (0.005060) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979913 (0.002508) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976279 (0.002074) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973375 (0.006981) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.973801 (0.006001) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.966511 (0.011288) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.964341 (0.006602) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.975310 (0.006072) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976953 (0.008417) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980185 (0.004466) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.975010 (0.004824) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.978269 (0.002256) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975898 (0.002005) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.974038 (0.008648) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.973922 (0.004538) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967339 (0.010343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.965098 (0.008218) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.974516 (0.004428) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.975871 (0.006301) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.976232 (0.005407) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.974925 (0.004877) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.976844 (0.003782) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974761 (0.003127) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973446 (0.005453) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.974015 (0.006817) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.968770 (0.006485) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.967731 (0.008420) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.976107 (0.005859) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.974417 (0.006118) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978304 (0.004255) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.974659 (0.004596) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979881 (0.003013) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.974725 (0.003040) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.974687 (0.006340) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.973684 (0.005667) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.965932 (0.007151) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.961150 (0.009081) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975895 (0.006769) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978178 (0.003809) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.974562 (0.006179) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980292 (0.003944) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.975031 (0.005283) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981011 (0.003748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975498 (0.001461) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.977503 (0.002904) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.974076 (0.003858) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971942 (0.004906) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.972179 (0.005737) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978178 (0.003809) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976514 (0.007477) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981244 (0.003157) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976670 (0.004821) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981638 (0.001386) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.975600 (0.001956) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.976435 (0.002477) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977055 (0.004655) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.973715 (0.007039) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.974265 (0.007873) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978101 (0.006306) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976516 (0.007475) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.978769 (0.003647) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978669 (0.004310) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981535 (0.002191) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.978350 (0.001043) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.976618 (0.005495) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976772 (0.005689) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971505 (0.006119) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.973258 (0.006837) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977011 (0.004462) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.974567 (0.004842) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980824 (0.004552) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.975594 (0.004641) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981212 (0.003291) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.979102 (0.001477) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.974576 (0.002102) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976424 (0.004951) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.975929 (0.005685) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.973341 (0.006885) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 2, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969076 (0.006211) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.975399 (0.007413) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.969921 (0.005802) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.980070 (0.002748) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.967988 (0.010819) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978483 (0.003343) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.959959 (0.004338) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.974054 (0.014308) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.959519 (0.015257) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978706 (0.004286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.968378 (0.010196) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.971588 (0.005829) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.962599 (0.007363) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.979521 (0.002183) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.961929 (0.010405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.973107 (0.006233) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.951885 (0.014402) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.967996 (0.013405) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.947467 (0.013808) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978681 (0.004607) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977035 (0.006638) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981334 (0.004521) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978576 (0.004503) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982310 (0.002852) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.978921 (0.001447) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978404 (0.003358) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977443 (0.003240) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.972793 (0.011240) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.968861 (0.012995) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 1, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978638 (0.006831) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.976476 (0.007722) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980156 (0.003224) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978018 (0.004968) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982753 (0.003394) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.977717 (0.002383) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978542 (0.003286) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.978376 (0.003280) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.970183 (0.010415) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.972813 (0.007964) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.977517 (0.006369) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977614 (0.007239) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.980658 (0.003565) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.978652 (0.003978) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.981179 (0.003669) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.976632 (0.002079) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.979668 (0.002905) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.976871 (0.002803) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.971281 (0.008186) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.968255 (0.009957) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 3, 'knn__n_neighbors': 5, 'knn__p': 2}\n","0.978620 (0.005557) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 1}\n","0.977026 (0.006637) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 1, 'knn__p': 2}\n","0.981372 (0.004261) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 1}\n","0.976984 (0.003328) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 2, 'knn__p': 2}\n","0.982334 (0.002817) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 1}\n","0.979045 (0.003761) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 3, 'knn__p': 2}\n","0.978509 (0.002262) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 1}\n","0.977831 (0.003211) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 4, 'knn__p': 2}\n","0.970788 (0.009852) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 1}\n","0.965406 (0.010455) with: {'cart__max_depth': 50, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 4, 'knn__n_neighbors': 5, 'knn__p': 2}\n","Time taken to run EL =  1590.7009615898132 seconds\n"]}],"source":["from sklearn.ensemble import StackingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","start_time_EL=time.time()\n","\n","n_neighbors = [1, 2, 3, 4, 5]\n","leaf_size = list(range(1,5))\n","p=[1,2]\n","max_depth = [10, 20, 30, 40, 50]\n","min_samples_split = [0.1, 1.0, 2]\n","min_samples_leaf = [1, 2, 3]\n","\n","# penalty = 'l1', solver = 'liblinear'\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","rf_attackornot = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","grid = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","model(df_new, y_attacktype, rf_attackornot, grid, cv)\n","elapsed_time_EL = time.time() - start_time_EL\n","print(\"Time taken to run EL = \", elapsed_time_EL, \"seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YjzR3RhDb-Td"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"or9gm0gcb-oS"},"source":["#### FedAvg_EL: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3405142,"status":"ok","timestamp":1643176981392,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"aVtVClKzb-oT","outputId":"fc9669f4-2ca6-4706-abfc-f2ffb721244e"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.996718 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996718, scores: [1.         1.         1.         0.98358974 1.        ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        82\n","   macro avg       1.00      1.00      1.00        82\n","weighted avg       1.00      1.00      1.00        82\n","\n","FPR: 0.000000\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n","FPR: 0.000000\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        18\n","   macro avg       1.00      1.00      1.00        18\n","weighted avg       1.00      1.00      1.00        18\n","\n","FPR: 0.000000\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n","FPR: 0.000000\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","FPR: 0.000000\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 2, 'knn__n_neighbors': 1, 'knn__p': 1}\n","On all train set, mean of scores: 0.988889, scores: [1.         1.         0.94444444 1.         1.        ]\n","On test set, Accuracy: 0.931111\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      0.50      0.67         2\n","          34       0.50      0.50      0.50         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.93        30\n","   macro avg       0.94      0.93      0.93        30\n","weighted avg       0.94      0.93      0.93        30\n","\n","FPR: 0.004762\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        48\n","   macro avg       1.00      1.00      1.00        48\n","weighted avg       1.00      1.00      1.00        48\n","\n","FPR: 0.000000\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.996257 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 3, 'cart__min_samples_split': 2, 'knn__leaf_size': 2, 'knn__n_neighbors': 2, 'knn__p': 2}\n","On all train set, mean of scores: 0.988131, scores: [0.98275862 1.         1.         0.97660819 0.98128655]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        72\n","   macro avg       1.00      1.00      1.00        72\n","weighted avg       1.00      1.00      1.00        72\n","\n","FPR: 0.000000\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.962293 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","On all train set, mean of scores: 0.962293, scores: [0.94146341 0.95       0.94666667 1.         0.97333333]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         3\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        51\n","   macro avg       1.00      1.00      1.00        51\n","weighted avg       1.00      1.00      1.00        51\n","\n","FPR: 0.000000\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.993111, FPR: 0.000476\n"]}],"source":["from sklearn.ensemble import StackingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","start_time_EL=time.time()\n","\n","n_neighbors = [1, 2, 3, 4, 5]\n","leaf_size = list(range(1,5))\n","p=[1,2]\n","max_depth = [10, 20, 30, 40, 50]\n","min_samples_split = [0.1, 1.0, 2]\n","min_samples_leaf = [1, 2, 3]\n","\n","# penalty = 'l1', solver = 'liblinear'\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","model_EL1 = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","grid_EL1 = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","federated_learning(1, model_EL1, grid_EL1, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_EL = time.time() - start_time_EL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9284,"status":"ok","timestamp":1643177283194,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"RlF4E3pHb-oT","outputId":"234e1979-9758-4590-e888-0787009132c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.989538 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.989538, scores: [1.         0.97948718 1.         0.98358974 0.98461538]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        82\n","   macro avg       1.00      1.00      1.00        82\n","weighted avg       1.00      1.00      1.00        82\n","\n","FPR: 0.000000\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n","FPR: 0.000000\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        18\n","   macro avg       1.00      1.00      1.00        18\n","weighted avg       1.00      1.00      1.00        18\n","\n","FPR: 0.000000\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n","FPR: 0.000000\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","FPR: 0.000000\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 0.964444\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      0.50      0.67         2\n","          34       0.67      1.00      0.80         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.97        30\n","   macro avg       0.98      0.97      0.96        30\n","weighted avg       0.98      0.97      0.96        30\n","\n","FPR: 0.002381\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        48\n","   macro avg       1.00      1.00      1.00        48\n","weighted avg       1.00      1.00      1.00        48\n","\n","FPR: 0.000000\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.983218 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 0.983218, scores: [0.98275862 1.         1.         0.98128655 0.95204678]\n","On test set, Accuracy: 0.985185\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       1.00      1.00      1.00         2\n","          37       0.67      1.00      0.80         2\n","          38       1.00      0.50      0.67         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.99        72\n","   macro avg       0.99      0.98      0.98        72\n","weighted avg       0.99      0.99      0.99        72\n","\n","FPR: 0.000476\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.945748 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n","On all train set, mean of scores: 0.945748, scores: [0.91707317 0.95       0.97333333 0.97333333 0.915     ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         3\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        51\n","   macro avg       1.00      1.00      1.00        51\n","weighted avg       1.00      1.00      1.00        51\n","\n","FPR: 0.000000\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.994963, FPR: 0.000286\n","Time taken to run Federated Learning with EL as initial model =  370.67774238586424 seconds\n"]}],"source":["start_time_EL2=time.time()\n","\n","print(\"Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\")\n","n_neighbors = [2]\n","leaf_size = [1]\n","p=[1]\n","max_depth = [10]\n","min_samples_split = [0.4]\n","min_samples_leaf = [1]\n","\n","# penalty = 'l1', solver = 'liblinear'\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","model_EL2 = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","grid_EL2 = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","federated_learning(2, model_EL2, grid_EL2, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_RF2 = time.time() - start_time_EL\n","print(\"Time taken to run Federated Learning with EL as initial model = \", elapsed_time_RF2/10 , \"seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TRTw93_dPpy"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wKwZRTbxdQFr"},"source":["#### FedGroup_EL: attack types"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9361,"status":"ok","timestamp":1643177854693,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"__Evb29ndQFr","outputId":"14ea2cbe-16b1-4157-d997-41f30d773a07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.989538 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.989538, scores: [1.         0.97948718 1.         0.98358974 0.98461538]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        82\n","   macro avg       1.00      1.00      1.00        82\n","weighted avg       1.00      1.00      1.00        82\n","\n","FPR: 0.000000\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 0.995745 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 0.995745, scores: [1.        1.        1.        0.9787234 1.       ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n","FPR: 0.000000\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 1, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        18\n","   macro avg       1.00      1.00      1.00        18\n","weighted avg       1.00      1.00      1.00        18\n","\n","FPR: 0.000000\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n","FPR: 0.000000\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.1, 'knn__leaf_size': 1, 'knn__n_neighbors': 2, 'knn__p': 1}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","FPR: 0.000000\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 0.964444\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.97        30\n","   macro avg       0.98      0.97      0.96        30\n","weighted avg       0.98      0.97      0.96        30\n","\n","FPR: 0.002381\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 1.000000 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        48\n","   macro avg       1.00      1.00      1.00        48\n","weighted avg       1.00      1.00      1.00        48\n","\n","FPR: 0.000000\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.979556 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 0.4, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 1}\n","On all train set, mean of scores: 0.979556, scores: [0.95977011 1.         1.         1.         0.9380117 ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        72\n","   macro avg       1.00      1.00      1.00        72\n","weighted avg       1.00      1.00      1.00        72\n","\n","FPR: 0.000000\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.962293 using {'cart__max_depth': 10, 'cart__min_samples_leaf': 1, 'cart__min_samples_split': 1.0, 'knn__leaf_size': 1, 'knn__n_neighbors': 3, 'knn__p': 2}\n","On all train set, mean of scores: 0.962293, scores: [0.94146341 0.95       0.94666667 1.         0.97333333]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         3\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        51\n","   macro avg       1.00      1.00      1.00        51\n","weighted avg       1.00      1.00      1.00        51\n","\n","FPR: 0.000000\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 1.000000\n","Appliances group: Device 9, Accuracy: 1.000000\n","Controller group: Device 2, Accuracy: 1.000000\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.994074\n","Federated Group: Round: 2, Accuracy: 0.996444, FPR: 0.000238\n","Time taken to run Federated Learning with Random Forest as initial model =  341.4309114933014 seconds\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","\n","# penalty = 'l1', solver = 'liblinear'\n","estimators = [('knn', KNeighborsClassifier()), ('cart', DecisionTreeClassifier())]\n","model_EL2 = model_camera = model_appliances = model_energy = model_controller = StackingClassifier(estimators= estimators, final_estimator = LogisticRegression())\n","cv_EL2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","\n","# 0, 4\n","n_neighbors = [2]\n","leaf_size = [1]\n","p=[1]\n","max_depth = [10]\n","min_samples_split = [0.1]\n","min_samples_leaf = [1]\n","grid_camera = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","# 9\n","n_neighbors = [3]\n","leaf_size = [1]\n","p=[2]\n","max_depth = [10]\n","min_samples_split = [1.0]\n","min_samples_leaf = [1]\n","grid_appliances = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","# 1, 3, 5, 6, 7, 8\n","n_neighbors = [3]\n","leaf_size = [1]\n","p=[1]\n","max_depth = [10]\n","min_samples_split = [0.4]\n","min_samples_leaf = [1]\n","grid_energy = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","# 2\n","n_neighbors = [1]\n","leaf_size = [1]\n","p=[1]\n","max_depth = [10]\n","min_samples_split = [0.1]\n","min_samples_leaf = [1]\n","grid_controller = {'knn__n_neighbors': n_neighbors, 'knn__p': p, 'knn__leaf_size': leaf_size,\n","        'cart__max_depth': max_depth, 'cart__min_samples_split': min_samples_split, \n","        'cart__min_samples_leaf': min_samples_leaf}\n","\n","start_time_RF3 = time.time()\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_RF3 = time.time() - start_time_RF3 + elapsed_time_EL\n","print(\"Time taken to run Federated Learning with Random Forest as initial model = \", elapsed_time_RF3/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"q5TxwBguwlMI"},"source":["## Random Forest"]},{"cell_type":"markdown","metadata":{"id":"nP_Qv38nJiyE"},"source":["### Random Forest: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2occ5Q00yvD5"},"outputs":[],"source":["start_time_RFO=time.time()\n","n_estimators = [1, 2, 3, 4, 5, 6, 10, 50, 100]\n","criterion = ['gini', 'entropy']\n","max_features = ['sqrt', 'log2', 'auto']\n","class_weight = ['balanced','balanced_subsample', None]      \n","rf_attackornot =RandomForestClassifier()\n","grid = dict(n_estimators=n_estimators, criterion=criterion, max_features=max_features, class_weight=class_weight)\n","model(df, y, rf_attackornot, grid, cv)\n","elapsed_time_RFO = time.time() - start_time_RFO\n","print(\"Time taken to run Random Forest = \", elapsed_time_RFO, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"LdKbVn1ohVod"},"source":["### FL: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9900604,"status":"ok","timestamp":1642412066440,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"eKOunF0v6A4I","outputId":"efff4615-32b7-42ba-e1f4-f6b6b1c2c5ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.998198 using {'max_features': 'auto', 'n_estimators': 400}\n","On all train set, mean of scores: 0.998172, scores: [0.99831872 0.99829249 0.99824984 0.99769467 0.99830591]\n","On test set, Accuracy: 0.997868\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.81      0.81      0.81        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.91      0.91      0.91     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.093129\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.998055 using {'max_features': 'auto', 'n_estimators': 300}\n","On all train set, mean of scores: 0.997942, scores: [0.99771331 0.99766392 0.99763097 0.99841928 0.99828473]\n","On test set, Accuracy: 0.998110\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.82      0.92      0.86        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.91      0.96      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.043064\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999353 using {'max_features': 'sqrt', 'n_estimators': 100}\n","On all train set, mean of scores: 0.999326, scores: [0.99901678 0.99956387 0.99920775 0.9992976  0.9995455 ]\n","On test set, Accuracy: 0.999555\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.85      0.94      0.89        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.92      0.97      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.027950\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.999083 using {'max_features': 'auto', 'n_estimators': 200}\n","On all train set, mean of scores: 0.999048, scores: [0.99892164 0.99919584 0.9988386  0.99888864 0.99939529]\n","On test set, Accuracy: 0.998798\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.84      0.85      0.84        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.92      0.93      0.92     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.074395\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.998427 using {'max_features': 'auto', 'n_estimators': 200}\n","On all train set, mean of scores: 0.998313, scores: [0.99795513 0.99806509 0.99817925 0.99875422 0.99861303]\n","On test set, Accuracy: 0.998289\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.76      0.63      0.69        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.88      0.82      0.85     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.183212\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999882 using {'max_features': 'sqrt', 'n_estimators': 100}\n","On all train set, mean of scores: 0.999882, scores: [1.         0.99986359 1.         1.         0.99954744]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      1.00      1.00      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.998826 using {'max_features': 'auto', 'n_estimators': 300}\n","On all train set, mean of scores: 0.998767, scores: [0.99862558 0.99880485 0.99850606 0.99877523 0.99912378]\n","On test set, Accuracy: 0.999100\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.84      0.90      0.87        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.92      0.95      0.94      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.050287\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.999073 using {'max_features': 'sqrt', 'n_estimators': 200}\n","On all train set, mean of scores: 0.999036, scores: [0.99865876 0.99912281 0.99921532 0.99898853 0.99919519]\n","On test set, Accuracy: 0.998970\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.80      0.92      0.85        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.90      0.96      0.93     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.042059\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998143 using {'max_features': 'auto', 'n_estimators': 600}\n","On all train set, mean of scores: 0.998089, scores: [0.99854022 0.99832448 0.99817421 0.99795391 0.99745083]\n","On test set, Accuracy: 0.997970\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.89      0.71      0.79        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.95      0.85      0.89     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.146048\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.998620 using {'max_features': 'auto', 'n_estimators': 300}\n","On all train set, mean of scores: 0.998560, scores: [0.99913156 0.99841825 0.99914249 0.99805317 0.99805317]\n","On test set, Accuracy: 0.998383\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.88      0.84      0.86        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.92      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.080345\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.998704, FPR: 0.074049\n"]}],"source":["start_time_RF=time.time()\n","# n_estimators_RF1 = [1, 2, 3, 4, 5, 6, 10, 50, 100]\n","# criterion_RF1 = ['gini', 'entropy']\n","# max_features_RF1 = ['sqrt', 'log2', 'auto']\n","# class_weight_RF1 = ['balanced','balanced_subsample', None]\n","\n","n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)] #100\n","max_features = ['sqrt', 'auto']\n","\n","model_RF1 = RandomForestClassifier()\n","grid_RF1 = dict(n_estimators=n_estimators, max_features=max_features) \n","# grid_RF1 = dict(n_estimators=n_estimators_RF1, criterion=criterion_RF1, max_features=max_features_RF1, class_weight=class_weight_RF1)\n","federated_learning(1, model_RF1, grid_RF1, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_RF = time.time() - start_time_RF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":619459,"status":"ok","timestamp":1642412968462,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"Ox9M5BYe7T8w","outputId":"d9b74a18-fd9c-42f7-f810-151153c97068"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.998080 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.998121, scores: [0.99850689 0.99819545 0.99806055 0.9974298  0.998413  ]\n","On test set, Accuracy: 0.997868\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.81      0.81      0.81        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.91      0.91      0.91     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.093129\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.998056 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.997912, scores: [0.99771331 0.99766392 0.99747924 0.99841928 0.99828473]\n","On test set, Accuracy: 0.998215\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.83      0.92      0.87        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.92      0.96      0.94      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.043006\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999353 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.999288, scores: [0.99901678 0.99956387 0.99920775 0.9992721  0.99938068]\n","On test set, Accuracy: 0.999555\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.85      0.94      0.89        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.92      0.97      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.027950\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.999045 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.999012, scores: [0.99892164 0.99919584 0.9987418  0.99871766 0.9994844 ]\n","On test set, Accuracy: 0.998798\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.84      0.85      0.84        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.92      0.93      0.92     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.074395\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.998399 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.998405, scores: [0.99819438 0.99806509 0.998291   0.99886067 0.99861303]\n","On test set, Accuracy: 0.998227\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.74      0.63      0.68        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.87      0.82      0.84     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.183248\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999882 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.999882, scores: [1.         0.99986359 1.         1.         0.99954744]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      1.00      1.00      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.998759 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.998759, scores: [0.99875143 0.99863918 0.99850606 0.99877523 0.99912378]\n","On test set, Accuracy: 0.998995\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.82      0.90      0.86        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.91      0.95      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.050344\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.999072 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.999058, scores: [0.99857879 0.99912281 0.99938969 0.99900282 0.99919519]\n","On test set, Accuracy: 0.998970\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.80      0.92      0.85        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.90      0.96      0.93     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.042059\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998127 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.998110, scores: [0.99854022 0.99832448 0.99817421 0.99795391 0.99755769]\n","On test set, Accuracy: 0.997970\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.89      0.71      0.79        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.95      0.85      0.89     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.146048\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.998530 using {'max_features': 'auto', 'n_estimators': 270}\n","On all train set, mean of scores: 0.998442, scores: [0.99899328 0.99857082 0.99870584 0.99805317 0.99788826]\n","On test set, Accuracy: 0.998259\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.87      0.82      0.85        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.91      0.92      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.090345\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.998686, FPR: 0.075052\n","Time taken to run Federated Learning with Random Forest as initial model =  1080.2366291046142 seconds\n"]}],"source":["start_time_RF2=time.time()\n","n_estimators_RF2 = [270]\n","# criterion_RF2 = ['gini']\n","max_features_RF2 = ['auto']\n","# class_weight_RF2 = [None]\n","print(\"Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\")\n","model_RF2=RandomForestClassifier()\n","grid_RF2 = dict(n_estimators=n_estimators_RF2, max_features=max_features_RF2)\n","federated_learning(2, model_RF2, grid_RF2, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_RF2 = time.time() - start_time_RF\n","print(\"Time taken to run Federated Learning with Random Forest as initial model = \", elapsed_time_RF2/10 , \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"Oogy30QH71sC"},"source":["### FL Group: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633806,"status":"ok","timestamp":1642413603321,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"_AFsYx6p78y6","outputId":"7965e483-b60e-4647-bb61-a3e6dc3b5aa2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.998140 using {'max_features': 'auto', 'n_estimators': 300}\n","On all train set, mean of scores: 0.998166, scores: [0.99841318 0.99829249 0.99824984 0.99746393 0.998413  ]\n","On test set, Accuracy: 0.997868\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.81      0.81      0.81        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.91      0.91      0.91     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.093129\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.997946 using {'max_features': 'auto', 'n_estimators': 283}\n","On all train set, mean of scores: 0.997972, scores: [0.99771331 0.99766392 0.9977811  0.99841928 0.99828473]\n","On test set, Accuracy: 0.998110\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.82      0.92      0.86        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.91      0.96      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.043064\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999319 using {'max_features': 'sqrt', 'n_estimators': 100}\n","On all train set, mean of scores: 0.999348, scores: [0.99901678 0.99956387 0.99920775 0.9994063  0.9995455 ]\n","On test set, Accuracy: 0.999436\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.84      0.89      0.86        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.92      0.94      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.055727\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.999068 using {'max_features': 'auto', 'n_estimators': 283}\n","On all train set, mean of scores: 0.999067, scores: [0.99892164 0.99928082 0.9988386  0.99880924 0.9994844 ]\n","On test set, Accuracy: 0.998721\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.83      0.83      0.83        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.92      0.92      0.92     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.083654\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.998381 using {'max_features': 'auto', 'n_estimators': 300}\n","On all train set, mean of scores: 0.998405, scores: [0.99819438 0.99817925 0.99817925 0.99886067 0.99861303]\n","On test set, Accuracy: 0.998227\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.74      0.63      0.68        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.87      0.82      0.84     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.183248\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999882 using {'max_features': 'auto', 'n_estimators': 283}\n","On all train set, mean of scores: 0.999882, scores: [1.         0.99986359 1.         1.         0.99954744]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      1.00      1.00      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.998759 using {'max_features': 'auto', 'n_estimators': 283}\n","On all train set, mean of scores: 0.998767, scores: [0.99862558 0.99863918 0.99850606 0.99894159 0.99912378]\n","On test set, Accuracy: 0.998995\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.82      0.90      0.86        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.91      0.95      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.050344\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.999040 using {'max_features': 'auto', 'n_estimators': 283}\n","On all train set, mean of scores: 0.999056, scores: [0.99865876 0.99912281 0.99929825 0.99900282 0.99919519]\n","On test set, Accuracy: 0.998907\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.79      0.92      0.85        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.89      0.96      0.92     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.042095\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998052 using {'max_features': 'auto', 'n_estimators': 283}\n","On all train set, mean of scores: 0.998069, scores: [0.99854022 0.99832448 0.99807376 0.99795391 0.99745083]\n","On test set, Accuracy: 0.997970\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.89      0.71      0.79        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.95      0.85      0.89     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.146048\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.998560 using {'max_features': 'auto', 'n_estimators': 300}\n","On all train set, mean of scores: 0.998558, scores: [0.99914249 0.99857082 0.99914249 0.99821557 0.99772072]\n","On test set, Accuracy: 0.998383\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.88      0.84      0.86        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.92      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.080345\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 0.998048\n","Appliances group: Device 9, Accuracy: 0.998383\n","Controller group: Device 2, Accuracy: 0.999436\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.998784\n","Federated Group: Round: 2, Accuracy: 0.998662, FPR: 0.077765\n","Time taken to run Federated Learning group with Random Forest as initial model =  1053.3988390684128 seconds\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","model_RF2 = model_camera = model_appliances = model_energy = model_controller = RandomForestClassifier()\n","cv_RF2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","\n","# 0, 4\n","n_estimators_camera = [300]\n","# criterion_camera = ['entropy']\n","max_features_camera = ['auto']\n","# class_weight_camera = ['balanced']\n","grid_camera = dict(n_estimators=n_estimators_camera, \n","                   max_features=max_features_camera)\n","\n","# 9\n","n_estimators_appliances = [300]\n","# criterion_appliances = ['entropy']\n","max_features_appliances = ['auto']\n","# class_weight_appliances = [None]\n","grid_appliances = dict(n_estimators=n_estimators_appliances,\n","                       max_features=max_features_appliances)\n","\n","# 1, 3, 5, 6, 7, 8\n","n_estimators_energy = [283]\n","# criterion_energy = ['entropy']\n","max_features_energy = ['auto']\n","# class_weight_energy = [None]\n","grid_energy = dict(n_estimators=n_estimators_energy, \n","                   max_features=max_features_energy)\n","\n","# 2\n","n_estimators_controller = [100]\n","# criterion_controller = ['entropy']\n","max_features_controller = ['sqrt']\n","# class_weight_controller = ['balanced_subsample']\n","grid_controller = dict(n_estimators=n_estimators_controller,\n","                       max_features=max_features_controller)\n","\n","start_time_RF3 = time.time()\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_RF3 = time.time() - start_time_RF3 + elapsed_time_RF\n","print(\"Time taken to run Federated Learning group with Random Forest as initial model = \", elapsed_time_RF3/10 , \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"JFOW1oBH3DXk"},"source":["### Random Forest: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232718,"status":"ok","timestamp":1642401900174,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"5NBDljp33HSD","outputId":"df8926a6-cda5-4954-f81c-0b042be32c6d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.748377 using {'max_features': 'sqrt', 'n_estimators': 300}\n","Time taken to run Random Forest =  1.7236390113830566 seconds\n","RandomForestClassifier(max_features='sqrt', n_estimators=300)\n","On all train set, mean of scores: 0.743583, scores: [0.7307998  0.75135527 0.72945933 0.76739183 0.73890681]\n","On test set, Accuracy: 0.772265\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.84      0.89        19\n","           1       1.00      0.85      0.92        20\n","           2       0.90      0.90      0.90        20\n","           3       0.81      0.93      0.87        14\n","           4       0.93      0.93      0.93        14\n","           5       1.00      0.86      0.92        14\n","           6       0.73      0.67      0.70        12\n","           7       0.91      0.83      0.87        12\n","           8       0.91      0.83      0.87        12\n","           9       0.80      1.00      0.89         8\n","          10       0.67      0.75      0.71         8\n","          11       0.71      0.62      0.67         8\n","          12       1.00      0.86      0.92        14\n","          13       0.65      0.93      0.76        14\n","          14       0.92      0.79      0.85        14\n","          15       0.56      0.62      0.59         8\n","          16       0.75      0.75      0.75         8\n","          17       0.86      0.75      0.80         8\n","          18       1.00      1.00      1.00         1\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       0.50      1.00      0.67         2\n","          22       0.50      0.50      0.50         2\n","          23       1.00      0.50      0.67         2\n","          24       0.61      0.71      0.65        24\n","          25       0.65      0.65      0.65        26\n","          26       0.71      0.62      0.67        24\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       0.77      0.83      0.80        24\n","          31       0.76      0.73      0.74        22\n","          32       0.77      0.71      0.74        24\n","          33       0.80      0.67      0.73         6\n","          34       0.56      0.83      0.67         6\n","          35       0.40      0.33      0.36         6\n","          36       0.75      0.50      0.60         6\n","          37       0.50      0.83      0.62         6\n","          38       0.75      0.50      0.60         6\n","          39       0.45      0.83      0.59         6\n","          40       0.33      0.17      0.22         6\n","          41       0.50      0.50      0.50         6\n","          42       1.00      1.00      1.00         6\n","          43       1.00      1.00      1.00         6\n","          44       1.00      1.00      1.00         6\n","\n","    accuracy                           0.77       460\n","   macro avg       0.79      0.78      0.77       460\n","weighted avg       0.79      0.77      0.77       460\n","\n","FPR: 0.005245\n","0.739948 (0.012485) with: {'max_features': 'sqrt', 'n_estimators': 100}\n","0.735550 (0.019266) with: {'max_features': 'sqrt', 'n_estimators': 200}\n","0.748377 (0.013265) with: {'max_features': 'sqrt', 'n_estimators': 300}\n","0.745944 (0.015346) with: {'max_features': 'sqrt', 'n_estimators': 400}\n","0.740572 (0.016829) with: {'max_features': 'sqrt', 'n_estimators': 500}\n","0.743529 (0.015237) with: {'max_features': 'sqrt', 'n_estimators': 600}\n","0.743341 (0.021918) with: {'max_features': 'sqrt', 'n_estimators': 700}\n","0.744967 (0.016707) with: {'max_features': 'sqrt', 'n_estimators': 800}\n","0.744314 (0.019062) with: {'max_features': 'sqrt', 'n_estimators': 900}\n","0.745423 (0.014422) with: {'max_features': 'sqrt', 'n_estimators': 1000}\n","0.736975 (0.015456) with: {'max_features': 'auto', 'n_estimators': 100}\n","0.744825 (0.017265) with: {'max_features': 'auto', 'n_estimators': 200}\n","0.739511 (0.015065) with: {'max_features': 'auto', 'n_estimators': 300}\n","0.743799 (0.014806) with: {'max_features': 'auto', 'n_estimators': 400}\n","0.738425 (0.016217) with: {'max_features': 'auto', 'n_estimators': 500}\n","0.744725 (0.018202) with: {'max_features': 'auto', 'n_estimators': 600}\n","0.739229 (0.015382) with: {'max_features': 'auto', 'n_estimators': 700}\n","0.741976 (0.019323) with: {'max_features': 'auto', 'n_estimators': 800}\n","0.742205 (0.022886) with: {'max_features': 'auto', 'n_estimators': 900}\n","0.736186 (0.020350) with: {'max_features': 'auto', 'n_estimators': 1000}\n","Time taken to run Random Forest =  232.56668949127197 seconds\n"]}],"source":["start_time_RFO=time.time()\n","\n","n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)] #100\n","\n","max_features = ['sqrt', 'auto']\n","\n","# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","# max_depth.append(None)\n","\n","# min_samples_split = [2, 5, 10]\n","# min_samples_leaf = [1, 2, 4]\n","# bootstrap = [True, False]\n","\n","# criterion = ['gini', 'entropy']\n","# class_weight = ['balanced','balanced_subsample', None]      \n","# grid = dict(n_estimators=n_estimators, criterion=criterion, max_features=max_features, class_weight=class_weight)\n","\n","rf_attacktype = RandomForestClassifier()\n","grid = dict(n_estimators=n_estimators, max_features=max_features)  \n","\n","model(df_new, y_attacktype, rf_attacktype, grid, cv)\n","elapsed_time_RFO = time.time() - start_time_RFO\n","print(\"Time taken to run Random Forest = \", elapsed_time_RFO, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"LrNJR_MM0sKL"},"source":["### FL: attack types"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":786630,"status":"ok","timestamp":1642401427343,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"RzZS3ttGyySZ","outputId":"23ac0160-8484-4def-f0e2-c8dc9a85b025"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.746469 using {'max_features': 'sqrt', 'n_estimators': 500}\n","On all train set, mean of scores: 0.734190, scores: [0.68919414 0.75974359 0.76710623 0.74637363 0.7085348 ]\n","On test set, Accuracy: 0.813008\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      0.50      0.67         2\n","           5       0.67      1.00      0.80         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      0.50      0.67         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       0.67      1.00      0.80         2\n","          18       0.00      0.00      0.00         2\n","          19       1.00      0.50      0.67         2\n","          20       0.50      1.00      0.67         2\n","          21       1.00      0.50      0.67         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       0.50      1.00      0.67         4\n","          25       0.00      0.00      0.00         4\n","          26       0.60      0.75      0.67         4\n","          27       0.67      1.00      0.80         2\n","          28       1.00      0.50      0.67         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       0.67      1.00      0.80         2\n","          34       1.00      0.50      0.67         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.84        82\n","   macro avg       0.86      0.85      0.83        82\n","weighted avg       0.83      0.84      0.81        82\n","\n","FPR: 0.004567\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.814832 using {'max_features': 'sqrt', 'n_estimators': 300}\n","On all train set, mean of scores: 0.785266, scores: [0.82708333 0.76875    0.81631206 0.73191489 0.7822695 ]\n","On test set, Accuracy: 0.896667\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      0.50      0.67         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       0.67      1.00      0.80         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       0.67      1.00      0.80         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      0.50      0.67         2\n","          36       1.00      0.50      0.67         2\n","          37       0.50      0.50      0.50         2\n","          38       0.67      1.00      0.80         2\n","          39       1.00      1.00      1.00         2\n","          40       0.50      0.50      0.50         2\n","          41       0.50      0.50      0.50         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.90        60\n","   macro avg       0.92      0.90      0.90        60\n","weighted avg       0.92      0.90      0.90        60\n","\n","FPR: 0.003448\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 0.866984 using {'max_features': 'auto', 'n_estimators': 500}\n","On all train set, mean of scores: 0.828889, scores: [0.81111111 0.79761905 0.85714286 0.92857143 0.75      ]\n","On test set, Accuracy: 0.881481\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.67      1.00      0.80         2\n","           2       1.00      0.50      0.67         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       0.67      1.00      0.80         2\n","          34       1.00      0.50      0.67         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.89        18\n","   macro avg       0.93      0.89      0.88        18\n","weighted avg       0.93      0.89      0.88        18\n","\n","FPR: 0.013889\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 0.742417 using {'max_features': 'auto', 'n_estimators': 400}\n","On all train set, mean of scores: 0.730930, scores: [0.67054264 0.78211517 0.64972315 0.76173865 0.79053288]\n","On test set, Accuracy: 0.824397\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.67      1.00      0.80         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      0.50      0.67         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       0.50      0.50      0.50         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      0.75      0.86         4\n","          25       0.50      1.00      0.67         4\n","          26       1.00      0.25      0.40         4\n","          30       0.75      0.75      0.75         4\n","          31       0.80      1.00      0.89         4\n","          32       0.75      0.75      0.75         4\n","\n","    accuracy                           0.83        54\n","   macro avg       0.90      0.86      0.85        54\n","weighted avg       0.88      0.83      0.82        54\n","\n","FPR: 0.008498\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 0.756638 using {'max_features': 'auto', 'n_estimators': 300}\n","On all train set, mean of scores: 0.732107, scores: [0.66414141 0.70606061 0.77770563 0.8523088  0.66031746]\n","On test set, Accuracy: 0.772061\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      0.50      0.67         2\n","          14       0.67      1.00      0.80         2\n","          24       0.60      0.75      0.67         4\n","          25       0.57      1.00      0.73         4\n","          26       0.60      0.75      0.67         4\n","          30       0.80      1.00      0.89         4\n","          31       1.00      0.25      0.40         4\n","          32       1.00      0.75      0.86         4\n","\n","    accuracy                           0.79        42\n","   macro avg       0.88      0.80      0.80        42\n","weighted avg       0.85      0.79      0.77        42\n","\n","FPR: 0.015702\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 0.864667 using {'max_features': 'sqrt', 'n_estimators': 100}\n","On all train set, mean of scores: 0.864667, scores: [0.78666667 0.78666667 1.         1.         0.75      ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 0.789802 using {'max_features': 'sqrt', 'n_estimators': 500}\n","On all train set, mean of scores: 0.782222, scores: [0.78333333 0.75694444 0.59166667 0.89722222 0.88194444]\n","On test set, Accuracy: 0.824444\n","              precision    recall  f1-score   support\n","\n","           0       0.67      1.00      0.80         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      1.00      1.00         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      0.50      0.67         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       0.67      1.00      0.80         2\n","          11       1.00      0.50      0.67         2\n","          15       0.50      0.50      0.50         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.83        30\n","   macro avg       0.88      0.83      0.82        30\n","weighted avg       0.88      0.83      0.82        30\n","\n","FPR: 0.011905\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 0.639385 using {'max_features': 'auto', 'n_estimators': 600}\n","On all train set, mean of scores: 0.622358, scores: [0.6019536  0.649186   0.64398496 0.58903509 0.62763158]\n","On test set, Accuracy: 0.821230\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.50      0.67         2\n","           1       1.00      1.00      1.00         2\n","           2       0.67      1.00      0.80         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      0.50      0.67         2\n","          14       1.00      1.00      1.00         2\n","          24       0.80      1.00      0.89         4\n","          25       0.80      1.00      0.89         4\n","          26       0.80      1.00      0.89         4\n","          30       1.00      0.50      0.67         4\n","          31       0.75      0.75      0.75         4\n","          32       0.67      0.50      0.57         4\n","\n","    accuracy                           0.83        48\n","   macro avg       0.88      0.85      0.84        48\n","weighted avg       0.86      0.83      0.82        48\n","\n","FPR: 0.009936\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.754297 using {'max_features': 'auto', 'n_estimators': 100}\n","On all train set, mean of scores: 0.723992, scores: [0.64482759 0.72179803 0.74798851 0.732665   0.7726817 ]\n","On test set, Accuracy: 0.794769\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.00      0.00      0.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      0.50      0.67         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       0.50      1.00      0.67         2\n","          14       1.00      1.00      1.00         2\n","          24       0.60      0.75      0.67         4\n","          25       0.60      0.75      0.67         4\n","          26       0.50      0.50      0.50         4\n","          30       0.67      0.50      0.57         4\n","          31       0.57      1.00      0.73         4\n","          32       1.00      0.75      0.86         4\n","          36       0.50      0.50      0.50         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       0.67      1.00      0.80         2\n","          41       1.00      0.50      0.67         2\n","          42       1.00      0.50      0.67         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      0.50      0.67         2\n","\n","    accuracy                           0.81        72\n","   macro avg       0.85      0.82      0.82        72\n","weighted avg       0.82      0.81      0.79        72\n","\n","FPR: 0.006807\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.821992 using {'max_features': 'sqrt', 'n_estimators': 700}\n","On all train set, mean of scores: 0.814801, scores: [0.78102981 0.81190476 0.86857143 0.89666667 0.71583333]\n","On test set, Accuracy: 0.959477\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       0.75      1.00      0.86         3\n","          25       1.00      0.75      0.86         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.96        51\n","   macro avg       0.98      0.97      0.97        51\n","weighted avg       0.97      0.96      0.96        51\n","\n","FPR: 0.001718\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.858754, FPR: 0.007647\n"]}],"source":["start_time_RF=time.time()\n","# n_estimators_RF1 = [1, 2, 3, 4, 5, 10, 50, 100, 200, 300, 400, 500, 600]\n","# criterion_RF1 = ['gini', 'entropy']\n","# max_features_RF1 = ['sqrt', 'log2', 'auto']\n","# class_weight_RF1 = ['balanced','balanced_subsample', None]\n","\n","n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)] #100\n","\n","max_features = ['sqrt', 'auto']\n","\n","# max_depth = [int(x) for x in np.linspace(1, 5, num = 10)]\n","# max_depth.append(None)\n","\n","# min_samples_split = [2, 5, 10] #2\n","# min_samples_leaf = [1, 2, 4] #1\n","# bootstrap = [True, False]\n","\n","model_RF1=RandomForestClassifier()\n","# grid_RF1 = dict(n_estimators=n_estimators_RF1, criterion=criterion_RF1, max_features=max_features_RF1, class_weight=class_weight_RF1)\n","grid_RF1 = dict(n_estimators=n_estimators, max_features=max_features) \n","federated_learning(1, model_RF1, grid_RF1, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_RF = time.time() - start_time_RF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69112,"status":"ok","timestamp":1642401984118,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"qvOWcVjYxzO3","outputId":"034e4e12-ec96-47b2-d757-eecff1a187c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.722505 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.735297, scores: [0.68919414 0.75534799 0.77992674 0.71930403 0.73271062]\n","On test set, Accuracy: 0.800813\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      0.50      0.67         2\n","           5       0.67      1.00      0.80         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      0.50      0.67         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       0.67      1.00      0.80         2\n","          18       0.00      0.00      0.00         2\n","          19       1.00      0.50      0.67         2\n","          20       0.50      1.00      0.67         2\n","          21       1.00      0.50      0.67         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       0.50      1.00      0.67         4\n","          25       0.00      0.00      0.00         4\n","          26       0.60      0.75      0.67         4\n","          27       0.67      1.00      0.80         2\n","          28       1.00      0.50      0.67         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       0.50      0.50      0.50         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.83        82\n","   macro avg       0.85      0.84      0.82        82\n","weighted avg       0.82      0.83      0.80        82\n","\n","FPR: 0.004915\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.803871 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.799814, scores: [0.84166667 0.76875    0.81489362 0.79148936 0.7822695 ]\n","On test set, Accuracy: 0.896667\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      0.50      0.67         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       0.67      1.00      0.80         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       0.67      1.00      0.80         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      0.50      0.67         2\n","          36       1.00      0.50      0.67         2\n","          37       0.50      0.50      0.50         2\n","          38       0.67      1.00      0.80         2\n","          39       1.00      1.00      1.00         2\n","          40       0.50      0.50      0.50         2\n","          41       0.50      0.50      0.50         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.90        60\n","   macro avg       0.92      0.90      0.90        60\n","weighted avg       0.92      0.90      0.90        60\n","\n","FPR: 0.003448\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 0.846984 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.838413, scores: [0.81111111 0.79761905 0.78571429 0.92857143 0.86904762]\n","On test set, Accuracy: 0.822222\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.67      1.00      0.80         2\n","           2       1.00      0.50      0.67         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      0.50      0.67         2\n","          11       0.67      1.00      0.80         2\n","          33       0.67      1.00      0.80         2\n","          34       1.00      0.50      0.67         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.83        18\n","   macro avg       0.89      0.83      0.82        18\n","weighted avg       0.89      0.83      0.82        18\n","\n","FPR: 0.020833\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 0.739768 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.731100, scores: [0.67054264 0.78211517 0.68777811 0.72452935 0.79053288]\n","On test set, Accuracy: 0.843445\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.67      1.00      0.80         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      0.50      0.67         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       0.67      1.00      0.80         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      0.75      0.86         4\n","          25       0.50      1.00      0.67         4\n","          26       1.00      0.25      0.40         4\n","          30       1.00      0.75      0.86         4\n","          31       0.80      1.00      0.89         4\n","          32       0.75      0.75      0.75         4\n","\n","    accuracy                           0.85        54\n","   macro avg       0.92      0.88      0.87        54\n","weighted avg       0.90      0.85      0.84        54\n","\n","FPR: 0.007546\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 0.753348 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.735859, scores: [0.62777778 0.78744589 0.751443   0.8523088  0.66031746]\n","On test set, Accuracy: 0.729252\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      0.50      0.67         2\n","          14       0.50      1.00      0.67         2\n","          24       0.60      0.75      0.67         4\n","          25       0.50      0.75      0.60         4\n","          26       0.50      0.50      0.50         4\n","          30       0.67      1.00      0.80         4\n","          31       1.00      0.25      0.40         4\n","          32       1.00      0.75      0.86         4\n","\n","    accuracy                           0.74        42\n","   macro avg       0.85      0.77      0.77        42\n","weighted avg       0.81      0.74      0.73        42\n","\n","FPR: 0.019123\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 0.864667 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.864667, scores: [0.78666667 0.78666667 1.         1.         0.75      ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 0.767500 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.768690, scores: [0.7531746  0.75694444 0.58888889 0.89722222 0.84722222]\n","On test set, Accuracy: 0.862222\n","              precision    recall  f1-score   support\n","\n","           0       0.67      1.00      0.80         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      1.00      1.00         2\n","           6       0.50      1.00      0.67         2\n","           7       1.00      0.50      0.67         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      0.50      0.67         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.87        30\n","   macro avg       0.92      0.87      0.86        30\n","weighted avg       0.92      0.87      0.86        30\n","\n","FPR: 0.009524\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 0.612551 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.624371, scores: [0.61239316 0.649186   0.67255639 0.57850877 0.60921053]\n","On test set, Accuracy: 0.805291\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       0.67      1.00      0.80         2\n","           3       0.67      1.00      0.80         2\n","           4       0.67      1.00      0.80         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      0.50      0.67         2\n","          14       1.00      0.50      0.67         2\n","          24       0.80      1.00      0.89         4\n","          25       0.80      1.00      0.89         4\n","          26       1.00      0.75      0.86         4\n","          30       0.67      0.50      0.57         4\n","          31       1.00      0.75      0.86         4\n","          32       0.60      0.75      0.67         4\n","\n","    accuracy                           0.81        48\n","   macro avg       0.86      0.82      0.81        48\n","weighted avg       0.85      0.81      0.81        48\n","\n","FPR: 0.011144\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.740237 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.728150, scores: [0.63140021 0.76559934 0.78563218 0.72915622 0.72896129]\n","On test set, Accuracy: 0.808995\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.00      0.00      0.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      0.50      0.67         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       0.50      1.00      0.67         2\n","          14       1.00      1.00      1.00         2\n","          24       0.50      0.75      0.60         4\n","          25       0.75      0.75      0.75         4\n","          26       0.50      0.50      0.50         4\n","          30       0.67      0.50      0.57         4\n","          31       0.67      1.00      0.80         4\n","          32       1.00      0.75      0.86         4\n","          36       0.50      0.50      0.50         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       0.67      1.00      0.80         2\n","          41       1.00      0.50      0.67         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      0.50      0.67         2\n","\n","    accuracy                           0.82        72\n","   macro avg       0.86      0.84      0.83        72\n","weighted avg       0.83      0.82      0.81        72\n","\n","FPR: 0.006317\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.804265 using {'max_features': 'sqrt', 'n_estimators': 400}\n","On all train set, mean of scores: 0.809685, scores: [0.78753388 0.8102381  0.86857143 0.92333333 0.65875   ]\n","On test set, Accuracy: 0.959477\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       0.75      1.00      0.86         3\n","          25       1.00      0.75      0.86         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       0.67      1.00      0.80         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.96        51\n","   macro avg       0.98      0.97      0.97        51\n","weighted avg       0.97      0.96      0.96        51\n","\n","FPR: 0.001718\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.852838, FPR: 0.008457\n","Time taken to run Federated Learning with Random Forest as initial model =  85.5209261417389 seconds\n"]}],"source":["start_time_RF2=time.time()\n","n_estimators_RF2 = [400]\n","# criterion_RF2 = ['gini']\n","max_features_RF2 = ['sqrt']\n","# class_weight_RF2 = [None]\n","print(\"Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\")\n","model_RF2=RandomForestClassifier()\n","grid_RF2 = dict(n_estimators=n_estimators_RF2, max_features=max_features_RF2)\n","federated_learning(2, model_RF2, grid_RF2, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_RF2 = time.time() - start_time_RF2 + elapsed_time_RF\n","print(\"Time taken to run Federated Learning with Random Forest as initial model = \", elapsed_time_RF2/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"-85PlWJI8QoG"},"source":["### FL Group: attack types"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69130,"status":"ok","timestamp":1642401665965,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"xpGQCI_e8gTe","outputId":"6301ad67-f51d-45c8-e66b-cf0b86073e49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.736476 using {'max_features': 'auto', 'n_estimators': 400}\n","On all train set, mean of scores: 0.742352, scores: [0.66765568 0.7818315  0.77992674 0.74714286 0.73520147]\n","On test set, Accuracy: 0.800813\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      0.50      0.67         2\n","           5       0.67      1.00      0.80         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      0.50      0.67         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       0.67      1.00      0.80         2\n","          18       0.00      0.00      0.00         2\n","          19       1.00      0.50      0.67         2\n","          20       0.50      1.00      0.67         2\n","          21       1.00      0.50      0.67         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       0.50      1.00      0.67         4\n","          25       0.00      0.00      0.00         4\n","          26       0.60      0.75      0.67         4\n","          27       0.67      1.00      0.80         2\n","          28       1.00      0.50      0.67         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       0.50      0.50      0.50         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.83        82\n","   macro avg       0.85      0.84      0.82        82\n","weighted avg       0.82      0.83      0.80        82\n","\n","FPR: 0.004915\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.793913 using {'max_features': 'auto', 'n_estimators': 333}\n","On all train set, mean of scores: 0.795157, scores: [0.85138889 0.75347222 0.81631206 0.77234043 0.7822695 ]\n","On test set, Accuracy: 0.883333\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      0.50      0.67         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       0.67      1.00      0.80         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      0.50      0.67         2\n","          36       1.00      0.50      0.67         2\n","          37       0.33      0.50      0.40         2\n","          38       0.50      0.50      0.50         2\n","          39       1.00      1.00      1.00         2\n","          40       0.50      0.50      0.50         2\n","          41       0.50      0.50      0.50         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.88        60\n","   macro avg       0.91      0.88      0.88        60\n","weighted avg       0.91      0.88      0.88        60\n","\n","FPR: 0.004023\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 0.814603 using {'max_features': 'auto', 'n_estimators': 500}\n","On all train set, mean of scores: 0.826508, scores: [0.81111111 0.85714286 0.78571429 0.92857143 0.75      ]\n","On test set, Accuracy: 0.881481\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.67      1.00      0.80         2\n","           2       1.00      0.50      0.67         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       0.67      1.00      0.80         2\n","          34       1.00      0.50      0.67         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.89        18\n","   macro avg       0.93      0.89      0.88        18\n","weighted avg       0.93      0.89      0.88        18\n","\n","FPR: 0.013889\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 0.722684 using {'max_features': 'auto', 'n_estimators': 333}\n","On all train set, mean of scores: 0.717570, scores: [0.68604651 0.75885936 0.6551495  0.72452935 0.76326531]\n","On test set, Accuracy: 0.850404\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.67      1.00      0.80         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      0.50      0.67         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       0.50      0.50      0.50         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      0.75      0.86         4\n","          25       0.57      1.00      0.73         4\n","          26       1.00      0.50      0.67         4\n","          30       0.60      0.75      0.67         4\n","          31       0.80      1.00      0.89         4\n","          32       1.00      0.75      0.86         4\n","\n","    accuracy                           0.85        54\n","   macro avg       0.91      0.87      0.87        54\n","weighted avg       0.89      0.85      0.85        54\n","\n","FPR: 0.007546\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 0.739596 using {'max_features': 'auto', 'n_estimators': 400}\n","On all train set, mean of scores: 0.727864, scores: [0.66414141 0.70606061 0.72619048 0.8523088  0.69062049]\n","On test set, Accuracy: 0.773648\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      0.50      0.67         2\n","          14       0.50      1.00      0.67         2\n","          24       0.75      0.75      0.75         4\n","          25       0.57      1.00      0.73         4\n","          26       0.60      0.75      0.67         4\n","          30       0.80      1.00      0.89         4\n","          31       1.00      0.25      0.40         4\n","          32       1.00      0.75      0.86         4\n","\n","    accuracy                           0.79        42\n","   macro avg       0.88      0.80      0.80        42\n","weighted avg       0.85      0.79      0.77        42\n","\n","FPR: 0.015614\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 0.864667 using {'max_features': 'auto', 'n_estimators': 333}\n","On all train set, mean of scores: 0.864667, scores: [0.78666667 0.78666667 1.         1.         0.75      ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 0.795278 using {'max_features': 'auto', 'n_estimators': 333}\n","On all train set, mean of scores: 0.803889, scores: [0.78333333 0.82361111 0.58888889 0.94166667 0.88194444]\n","On test set, Accuracy: 0.831111\n","              precision    recall  f1-score   support\n","\n","           0       0.67      1.00      0.80         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      1.00      1.00         2\n","           6       0.33      0.50      0.40         2\n","           7       1.00      0.50      0.67         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      0.50      0.67         2\n","          15       0.67      1.00      0.80         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.83        30\n","   macro avg       0.89      0.83      0.83        30\n","weighted avg       0.89      0.83      0.83        30\n","\n","FPR: 0.011905\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 0.585509 using {'max_features': 'auto', 'n_estimators': 333}\n","On all train set, mean of scores: 0.592013, scores: [0.65683761 0.62496947 0.57781955 0.5495614  0.55087719]\n","On test set, Accuracy: 0.846429\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      0.50      0.67         2\n","          14       1.00      1.00      1.00         2\n","          24       0.80      1.00      0.89         4\n","          25       0.80      1.00      0.89         4\n","          26       0.80      1.00      0.89         4\n","          30       1.00      0.50      0.67         4\n","          31       1.00      0.75      0.86         4\n","          32       0.50      0.50      0.50         4\n","\n","    accuracy                           0.85        48\n","   macro avg       0.90      0.88      0.87        48\n","weighted avg       0.88      0.85      0.85        48\n","\n","FPR: 0.008729\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.746405 using {'max_features': 'auto', 'n_estimators': 333}\n","On all train set, mean of scores: 0.731468, scores: [0.62914614 0.74720854 0.80287356 0.76390977 0.71420217]\n","On test set, Accuracy: 0.795723\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.00      0.00      0.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      0.50      0.67         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       0.50      1.00      0.67         2\n","          14       1.00      1.00      1.00         2\n","          24       0.60      0.75      0.67         4\n","          25       0.50      0.50      0.50         4\n","          26       0.40      0.50      0.44         4\n","          30       0.67      0.50      0.57         4\n","          31       0.67      1.00      0.80         4\n","          32       1.00      0.75      0.86         4\n","          36       0.50      0.50      0.50         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       0.67      1.00      0.80         2\n","          41       1.00      0.50      0.67         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      0.50      0.67         2\n","\n","    accuracy                           0.81        72\n","   macro avg       0.85      0.83      0.83        72\n","weighted avg       0.81      0.81      0.80        72\n","\n","FPR: 0.006807\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.810885 using {'max_features': 'sqrt', 'n_estimators': 700}\n","On all train set, mean of scores: 0.802325, scores: [0.78102981 0.81190476 0.8352381  0.92333333 0.66011905]\n","On test set, Accuracy: 0.959477\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       0.75      1.00      0.86         3\n","          25       1.00      0.75      0.86         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.96        51\n","   macro avg       0.98      0.97      0.97        51\n","weighted avg       0.97      0.96      0.96        51\n","\n","FPR: 0.001718\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 0.787231\n","Appliances group: Device 9, Accuracy: 0.959477\n","Controller group: Device 2, Accuracy: 0.881481\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.867833\n","Federated Group: Round: 2, Accuracy: 0.862242, FPR: 0.007514\n","Time taken to run Federated Learning with Random Forest as initial model =  85.50389273166657 seconds\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","model_RF2 = model_camera = model_appliances = model_energy = model_controller = RandomForestClassifier()\n","cv_RF2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","\n","# 0, 4\n","n_estimators_camera = [400]\n","# criterion_camera = ['gini']\n","max_features_camera = ['auto']\n","# class_weight_camera = [None]\n","grid_camera = dict(n_estimators=n_estimators_camera, \n","                   max_features=max_features_camera)\n","\n","# 9\n","n_estimators_appliances = [700]\n","# criterion_appliances = ['gini']\n","max_features_appliances = ['sqrt']\n","# class_weight_appliances = [None]\n","grid_appliances = dict(n_estimators=n_estimators_appliances,\n","                       max_features=max_features_appliances)\n","\n","# 1, 3, 5, 6, 7, 8\n","n_estimators_energy = [333]\n","# criterion_energy = ['entropy']\n","max_features_energy = ['auto']\n","# class_weight_energy = ['balanced_subsample']\n","grid_energy = dict(n_estimators=n_estimators_energy,\n","                       max_features=max_features_energy)\n","\n","# 2\n","n_estimators_controller = [500]\n","# criterion_controller = ['gini']\n","max_features_controller = ['auto']\n","# class_weight_controller = ['balanced']\n","grid_controller = dict(n_estimators=n_estimators_controller,\n","                       max_features=max_features_controller)\n","\n","start_time_RF3 = time.time()\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_RF3 = time.time() - start_time_RF3 + elapsed_time_RF\n","print(\"Time taken to run Federated Learning with Random Forest as initial model = \", elapsed_time_RF3/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"21GZNf_h1MWK"},"source":["## KNN"]},{"cell_type":"markdown","metadata":{"id":"FPAcLbYG1ZVX"},"source":["### KNN: Attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ScNpkkSV2yZJ"},"outputs":[],"source":["start_time_KNNO=time.time()\n","from sklearn.neighbors import KNeighborsClassifier\n","# n_neighbors = list(range(1,5))\n","# leaf_size = list(range(1,3))\n","# p=[1,2]\n","n_neighbors = [1, 2, 3, 4, 5, 10, 20, 25, 30]\n","weights = ['uniform', 'distance']\n","algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n","knn = KNeighborsClassifier()\n","grid = dict(n_neighbors=n_neighbors, weights = weights, algorithm = algorithm)  \n","# grid = dict(n_neighbors=n_neighbors, leaf_size = leaf_size, p = p)\n","model(df, y, knn, grid, cv)\n","elapsed_time_KNNO = time.time() - start_time_KNNO\n","print(\"Time taken to run KNN = \", elapsed_time_KNNO, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"LiCiXNbA35tm"},"source":["### FL: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6167432,"status":"ok","timestamp":1642432945690,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"jCgosM-C5SZM","outputId":"314813a4-d237-4f90-bdb5-57480d01686c"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998621 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998621, scores: [0.9988317  0.99847223 0.99869214 0.99827466 0.99883192]\n","On test set, Accuracy: 0.999221\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.93      0.94      0.93        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.96      0.97      0.97     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.031079\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.998327 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998327, scores: [0.99818772 0.99824794 0.99801956 0.99887966 0.99830211]\n","On test set, Accuracy: 0.998661\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.86      0.95      0.90        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.97      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.025942\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999686 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 2}\n","On all train set, mean of scores: 0.999686, scores: [0.99972367 0.99957814 0.99970315 0.99970315 0.99972363]\n","On test set, Accuracy: 0.999163\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.87      0.72      0.79        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.86      0.89      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.139003\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.999186 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999186, scores: [0.99919603 0.99929769 0.99909024 0.99904974 0.9992975 ]\n","On test set, Accuracy: 0.999063\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.90      0.85      0.88        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.95      0.93      0.94     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.074252\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.999471 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 2}\n","On all train set, mean of scores: 0.999471, scores: [0.99973545 0.99938279 0.99947481 0.99928933 0.99947481]\n","On test set, Accuracy: 0.999298\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.86      0.90      0.88        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.93      0.95      0.94     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.048994\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999916 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999916, scores: [1.         0.99986359 1.         1.         0.99971416]\n","On test set, Accuracy: 0.999748\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      0.67      0.80         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      0.83      0.90      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.166667\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.999201 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 2}\n","On all train set, mean of scores: 0.999201, scores: [0.99902889 0.99927783 0.99914249 0.99929267 0.99926156]\n","On test set, Accuracy: 0.999665\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.91      1.00      0.95        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.95      1.00      0.98      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.000172\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.999361 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999361, scores: [0.99919526 0.9993742  0.99948    0.99928933 0.999467  ]\n","On test set, Accuracy: 0.999147\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.88      0.88      0.88        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.94      0.94      0.94     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.062714\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998898 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998898, scores: [0.99885974 0.99911166 0.99885016 0.99884017 0.99882991]\n","On test set, Accuracy: 0.999279\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.96      0.90      0.93        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.98      0.95      0.96     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.048718\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.998888 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998888, scores: [0.99915289 0.99915264 0.99916231 0.9985332  0.99843732]\n","On test set, Accuracy: 0.998857\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.90      0.90      0.90        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.95      0.95      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.050287\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.999210, FPR: 0.064783\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","start_time_KNN=time.time()\n","n_neighbors_KNN1 = list(range(1,5))\n","leaf_size = list(range(1,3))\n","p=[1,2]     \n","model_KNN1=KNeighborsClassifier()\n","grid_KNN1 = dict(n_neighbors = n_neighbors_KNN1, leaf_size = leaf_size, p = p)\n","federated_learning(1, model_KNN1, grid_KNN1, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_KNN = time.time() - start_time_KNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2021494,"status":"ok","timestamp":1642453893159,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"yVbKxzFkZte_","outputId":"6b844890-001d-45c2-dab4-ada642d40faf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.998621 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998621, scores: [0.9988317  0.99847223 0.99869214 0.99827466 0.99883192]\n","On test set, Accuracy: 0.999221\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.93      0.94      0.93        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.96      0.97      0.97     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.031079\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.998327 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998327, scores: [0.99818772 0.99824794 0.99801956 0.99887966 0.99830211]\n","On test set, Accuracy: 0.998661\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.86      0.95      0.90        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.97      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.025942\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999662 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999662, scores: [0.99972367 0.99971416 0.99970315 0.99970315 0.9994639 ]\n","On test set, Accuracy: 0.999314\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.83      0.83      0.83        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.92      0.92      0.92      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.083505\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.999186 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999186, scores: [0.99919603 0.99929769 0.99909024 0.99904974 0.9992975 ]\n","On test set, Accuracy: 0.999063\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.90      0.85      0.88        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.95      0.93      0.94     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.074252\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.999416 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999416, scores: [0.99955908 0.999467   0.999467   0.99927826 0.99930957]\n","On test set, Accuracy: 0.999506\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.90      0.93      0.92        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.95      0.96      0.96     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.036728\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999916 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999916, scores: [1.         0.99986359 1.         1.         0.99971416]\n","On test set, Accuracy: 0.999748\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      0.67      0.80         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      0.83      0.90      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.166667\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.999113 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999113, scores: [0.99875143 0.99942833 0.99929267 0.99883188 0.99926156]\n","On test set, Accuracy: 0.999665\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.91      1.00      0.95        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.95      1.00      0.98      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.000172\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.999361 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999361, scores: [0.99919526 0.9993742  0.99948    0.99928933 0.999467  ]\n","On test set, Accuracy: 0.999147\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.88      0.88      0.88        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.94      0.94      0.94     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.062714\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998898 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998898, scores: [0.99885974 0.99911166 0.99885016 0.99884017 0.99882991]\n","On test set, Accuracy: 0.999279\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.96      0.90      0.93        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.98      0.95      0.96     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.048718\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.998888 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998888, scores: [0.99915289 0.99915264 0.99916231 0.9985332  0.99843732]\n","On test set, Accuracy: 0.998857\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.90      0.90      0.90        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.95      0.95      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.050287\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.999246, FPR: 0.058006\n","Time taken to run Federated Learning with KNN as initial model =  2711.490216422081 seconds\n"]}],"source":["start_time_KNN2=time.time()\n","n_neighbors_KNN2 = [3] \n","leaf_size = [1]\n","p=[1]   \n","model_KNN2=KNeighborsClassifier()\n","grid_KNN2 = dict(n_neighbors = n_neighbors_KNN2, leaf_size = leaf_size, p = p) \n","print(\"Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\")\n","federated_learning(2, model_KNN2, grid_KNN2, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_KNN2 = time.time() - start_time_KNN\n","print(\"Time taken to run Federated Learning with KNN as initial model = \", elapsed_time_KNN2/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"0yh7fEWx-d5A"},"source":["### FL Group: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1930166,"status":"ok","timestamp":1642455824306,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"9EB4TFNk-SBx","outputId":"0503c83c-cc48-4263-fd1b-7738554392e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.998621 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998621, scores: [0.9988317  0.99847223 0.99869214 0.99827466 0.99883192]\n","On test set, Accuracy: 0.999221\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.93      0.94      0.93        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.96      0.97      0.97     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.031079\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.998327 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998327, scores: [0.99818772 0.99824794 0.99801956 0.99887966 0.99830211]\n","On test set, Accuracy: 0.998661\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.86      0.95      0.90        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.97      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.025942\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999686 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 2}\n","On all train set, mean of scores: 0.999686, scores: [0.99972367 0.99957814 0.99970315 0.99970315 0.99972363]\n","On test set, Accuracy: 0.999163\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.87      0.72      0.79        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.86      0.89      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.139003\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.999186 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999186, scores: [0.99919603 0.99929769 0.99909024 0.99904974 0.9992975 ]\n","On test set, Accuracy: 0.999063\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.90      0.85      0.88        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.95      0.93      0.94     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.074252\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.999416 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999416, scores: [0.99955908 0.999467   0.999467   0.99927826 0.99930957]\n","On test set, Accuracy: 0.999506\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.90      0.93      0.92        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.95      0.96      0.96     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.036728\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999916 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999916, scores: [1.         0.99986359 1.         1.         0.99971416]\n","On test set, Accuracy: 0.999748\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      0.67      0.80         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      0.83      0.90      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.166667\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.999113 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999113, scores: [0.99875143 0.99942833 0.99929267 0.99883188 0.99926156]\n","On test set, Accuracy: 0.999665\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.91      1.00      0.95        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.95      1.00      0.98      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.000172\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.999361 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.999361, scores: [0.99919526 0.9993742  0.99948    0.99928933 0.999467  ]\n","On test set, Accuracy: 0.999147\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.88      0.88      0.88        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.94      0.94      0.94     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.062714\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998898 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998898, scores: [0.99885974 0.99911166 0.99885016 0.99884017 0.99882991]\n","On test set, Accuracy: 0.999279\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.96      0.90      0.93        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.98      0.95      0.96     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.048718\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.998888 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","On all train set, mean of scores: 0.998888, scores: [0.99915289 0.99915264 0.99916231 0.9985332  0.99843732]\n","On test set, Accuracy: 0.998857\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.90      0.90      0.90        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.95      0.95      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.050287\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 0.999363\n","Appliances group: Device 9, Accuracy: 0.998857\n","Controller group: Device 2, Accuracy: 0.999163\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.999261\n","Federated Group: Round: 2, Accuracy: 0.999231, FPR: 0.063556\n","Time taken to run Federated Learning with KNN as initial model =  809.716430068016 seconds\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","model_KNN2 = model_camera = model_appliances = model_energy = model_controller = KNeighborsClassifier()\n","cv_KNN2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","# 0, 4\n","n_neighbors_camera = [3]\n","leaf_size = [1]\n","p=[1]\n","grid_camera = dict(n_neighbors = n_neighbors_camera, leaf_size = leaf_size, p = p)\n","\n","# 9\n","n_neighbors_appliances = [3]\n","leaf_size = [1]\n","p=[1]\n","grid_appliances = dict(n_neighbors = n_neighbors_appliances, leaf_size = leaf_size, p = p)\n","\n","# 1, 3, 5, 6, 7, 8\n","n_neighbors_energy = [3]\n","leaf_size = [1]\n","p=[1]\n","grid_energy = dict(n_neighbors = n_neighbors_energy, leaf_size = leaf_size, p = p)\n","\n","# 2\n","n_neighbors_controller = [1]\n","leaf_size = [1]\n","p=[2]\n","grid_controller = dict(n_neighbors = n_neighbors_controller, leaf_size = leaf_size, p = p)\n","\n","start_time_KNN3 = time.time()\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_KNN3 = time.time() - start_time_KNN3 + elapsed_time_KNN\n","print(\"Time taken to run Federated Learning with KNN as initial model = \", elapsed_time_KNN3/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"rE1Z2w6P20oF"},"source":["### KNN: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112712,"status":"ok","timestamp":1643169195902,"user":{"displayName":"Nikki Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"VUVoWiPv32IK","outputId":"ea1a4fcf-5278-49d5-b5cd-63bb85dc3772"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best: 0.979521 using {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","Time taken to run Random Forest =  0.004422903060913086 seconds\n","KNeighborsClassifier(leaf_size=1, n_neighbors=3, p=1)\n","On all train set, mean of scores: 0.979521, scores: [0.97522942 0.98068567 0.97985205 0.98080556 0.98103192]\n","On test set, Accuracy: 0.982042\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        20\n","           2       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        14\n","           4       1.00      1.00      1.00        14\n","           5       1.00      1.00      1.00        14\n","           6       1.00      1.00      1.00        12\n","           7       1.00      1.00      1.00        12\n","           8       1.00      1.00      1.00        12\n","           9       1.00      1.00      1.00         8\n","          10       1.00      1.00      1.00         8\n","          11       1.00      1.00      1.00         8\n","          12       1.00      0.93      0.96        14\n","          13       0.88      1.00      0.93        14\n","          14       1.00      0.93      0.96        14\n","          15       1.00      1.00      1.00         8\n","          16       1.00      1.00      1.00         8\n","          17       1.00      1.00      1.00         8\n","          18       1.00      1.00      1.00         1\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       0.67      1.00      0.80         2\n","          23       1.00      0.50      0.67         2\n","          24       1.00      0.92      0.96        24\n","          25       0.96      1.00      0.98        26\n","          26       0.96      1.00      0.98        24\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00        24\n","          31       1.00      1.00      1.00        22\n","          32       1.00      1.00      1.00        24\n","          33       1.00      1.00      1.00         6\n","          34       1.00      1.00      1.00         6\n","          35       1.00      1.00      1.00         6\n","          36       1.00      0.50      0.67         6\n","          37       0.67      1.00      0.80         6\n","          38       1.00      1.00      1.00         6\n","          39       1.00      1.00      1.00         6\n","          40       1.00      1.00      1.00         6\n","          41       1.00      1.00      1.00         6\n","          42       1.00      1.00      1.00         6\n","          43       1.00      1.00      1.00         6\n","          44       1.00      1.00      1.00         6\n","\n","    accuracy                           0.98       460\n","   macro avg       0.98      0.97      0.97       460\n","weighted avg       0.99      0.98      0.98       460\n","\n","FPR: 0.000397\n","0.978706 (0.004286) with: {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 1, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 1, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 1, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 1, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 1, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 1, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 1, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 1, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 1, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 1, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 1, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 1, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 1, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 1, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 1, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 2, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 2, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 2, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 2, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 2, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 2, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 2, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 2, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 2, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 2, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 2, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 2, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 2, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 2, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 2, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 2, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 2, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 2, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 3, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 3, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 3, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 3, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 3, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 3, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 3, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 3, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 3, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 3, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 3, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 3, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 3, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 3, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 3, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 3, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 3, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 3, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 4, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 4, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 4, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 4, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 4, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 4, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 4, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 4, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 4, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 4, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 4, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 4, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 4, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 4, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 4, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 4, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 4, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 4, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 5, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 5, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 5, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 5, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 5, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 5, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 5, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 5, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 5, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 5, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 5, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 5, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 5, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 5, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 5, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 5, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 5, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 5, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 6, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 6, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 6, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 6, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 6, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 6, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 6, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 6, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 6, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 6, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 6, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 6, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 6, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 6, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 6, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 6, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 6, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 6, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 7, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 7, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 7, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 7, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 7, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 7, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 7, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 7, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 7, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 7, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 7, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 7, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 7, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 7, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 7, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 7, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 7, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 7, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 8, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 8, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 8, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 8, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 8, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 8, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 8, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 8, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 8, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 8, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 8, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 8, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 8, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 8, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 8, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 8, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 8, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 8, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 9, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 9, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 9, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 9, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 9, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 9, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 9, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 9, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 9, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 9, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 9, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 9, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 9, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 9, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 9, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 9, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 9, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 9, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 10, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 10, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 10, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 10, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 10, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 10, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 10, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 10, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 10, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 10, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 10, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 10, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 10, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 10, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 10, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 10, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 10, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 10, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 11, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 11, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 11, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 11, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 11, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 11, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 11, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 11, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 11, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 11, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 11, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 11, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 11, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 11, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 11, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 11, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 11, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 11, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 12, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 12, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 12, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 12, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 12, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 12, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 12, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 12, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 12, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 12, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 12, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 12, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 12, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 12, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 12, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 12, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 12, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 12, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 13, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 13, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 13, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 13, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 13, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 13, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 13, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 13, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 13, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 13, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 13, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 13, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 13, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 13, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 13, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 13, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 13, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 13, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 14, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 14, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 14, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 14, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 14, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 14, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 14, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 14, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 14, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 14, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 14, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 14, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 14, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 14, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 14, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 14, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 14, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 14, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 15, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 15, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 15, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 15, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 15, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 15, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 15, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 15, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 15, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 15, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 15, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 15, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 15, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 15, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 15, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 15, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 15, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 15, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 16, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 16, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 16, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 16, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 16, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 16, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 16, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 16, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 16, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 16, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 16, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 16, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 16, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 16, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 16, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 16, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 16, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 16, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 17, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 17, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 17, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 17, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 17, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 17, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 17, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 17, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 17, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 17, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 17, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 17, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 17, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 17, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 17, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 17, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 17, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 17, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 18, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 18, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 18, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 18, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 18, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 18, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 18, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 18, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 18, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 18, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 18, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 18, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 18, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 18, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 18, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 18, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 18, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 18, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 19, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 19, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 19, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 19, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 19, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 19, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 19, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 19, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 19, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 19, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 19, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 19, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 19, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 19, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 19, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 19, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 19, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 19, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 20, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 20, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 20, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 20, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 20, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 20, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 20, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 20, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 20, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 20, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 20, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 20, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 20, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 20, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 20, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 20, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 20, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 20, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 21, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 21, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 21, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 21, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 21, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 21, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 21, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 21, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 21, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 21, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 21, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 21, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 21, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 21, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 21, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 21, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 21, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 21, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 22, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 22, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 22, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 22, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 22, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 22, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 22, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 22, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 22, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 22, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 22, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 22, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 22, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 22, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 22, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 22, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 22, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 22, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 23, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 23, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 23, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 23, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 23, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 23, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 23, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 23, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 23, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 23, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 23, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 23, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 23, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 23, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 23, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 23, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 23, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 23, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 24, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 24, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 24, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 24, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 24, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 24, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 24, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 24, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 24, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 24, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 24, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 24, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 24, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 24, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 24, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 24, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 24, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 24, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 25, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 25, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 25, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 25, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 25, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 25, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 25, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 25, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 25, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 25, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 25, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 25, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 25, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 25, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 25, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 25, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 25, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 25, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 26, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 26, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 26, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 26, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 26, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 26, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 26, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 26, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 26, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 26, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 26, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 26, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 26, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 26, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 26, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 26, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 26, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 26, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 27, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 27, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 27, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 27, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 27, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 27, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 27, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 27, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 27, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 27, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 27, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 27, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 27, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 27, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 27, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 27, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 27, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 27, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 28, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 28, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 28, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 28, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 28, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 28, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 28, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 28, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 28, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 28, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 28, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 28, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 28, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 28, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 28, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 28, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 28, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 28, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 29, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 29, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 29, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 29, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 29, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 29, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 29, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 29, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 29, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 29, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 29, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 29, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 29, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 29, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 29, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 29, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 29, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 29, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 30, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 30, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 30, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 30, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 30, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 30, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 30, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 30, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 30, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 30, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 30, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 30, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 30, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 30, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 30, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 30, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 30, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 30, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 31, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 31, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 31, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 31, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 31, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 31, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 31, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 31, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 31, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 31, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 31, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 31, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 31, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 31, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 31, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 31, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 31, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 31, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 32, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 32, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 32, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 32, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 32, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 32, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 32, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 32, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 32, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 32, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 32, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 32, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 32, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 32, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 32, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 32, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 32, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 32, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 33, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 33, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 33, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 33, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 33, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 33, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 33, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 33, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 33, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 33, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 33, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 33, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 33, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 33, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 33, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 33, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 33, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 33, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 34, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 34, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 34, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 34, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 34, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 34, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 34, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 34, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 34, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 34, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 34, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 34, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 34, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 34, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 34, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 34, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 34, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 34, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 35, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 35, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 35, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 35, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 35, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 35, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 35, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 35, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 35, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 35, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 35, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 35, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 35, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 35, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 35, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 35, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 35, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 35, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 36, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 36, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 36, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 36, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 36, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 36, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 36, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 36, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 36, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 36, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 36, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 36, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 36, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 36, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 36, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 36, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 36, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 36, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 37, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 37, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 37, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 37, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 37, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 37, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 37, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 37, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 37, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 37, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 37, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 37, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 37, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 37, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 37, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 37, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 37, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 37, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 38, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 38, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 38, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 38, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 38, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 38, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 38, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 38, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 38, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 38, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 38, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 38, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 38, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 38, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 38, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 38, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 38, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 38, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 39, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 39, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 39, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 39, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 39, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 39, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 39, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 39, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 39, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 39, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 39, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 39, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 39, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 39, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 39, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 39, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 39, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 39, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 40, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 40, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 40, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 40, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 40, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 40, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 40, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 40, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 40, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 40, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 40, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 40, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 40, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 40, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 40, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 40, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 40, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 40, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 41, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 41, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 41, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 41, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 41, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 41, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 41, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 41, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 41, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 41, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 41, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 41, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 41, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 41, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 41, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 41, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 41, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 41, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 42, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 42, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 42, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 42, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 42, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 42, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 42, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 42, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 42, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 42, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 42, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 42, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 42, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 42, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 42, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 42, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 42, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 42, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 43, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 43, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 43, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 43, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 43, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 43, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 43, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 43, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 43, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 43, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 43, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 43, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 43, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 43, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 43, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 43, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 43, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 43, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 44, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 44, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 44, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 44, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 44, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 44, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 44, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 44, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 44, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 44, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 44, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 44, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 44, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 44, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 44, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 44, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 44, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 44, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 45, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 45, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 45, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 45, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 45, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 45, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 45, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 45, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 45, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 45, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 45, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 45, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 45, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 45, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 45, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 45, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 45, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 45, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 46, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 46, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 46, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 46, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 46, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 46, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 46, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 46, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 46, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 46, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 46, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 46, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 46, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 46, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 46, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 46, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 46, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 46, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 47, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 47, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 47, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 47, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 47, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 47, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 47, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 47, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 47, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 47, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 47, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 47, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 47, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 47, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 47, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 47, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 47, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 47, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 48, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 48, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 48, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 48, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 48, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 48, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 48, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 48, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 48, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 48, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 48, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 48, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 48, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 48, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 48, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 48, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 48, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 48, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 49, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 49, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 49, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 49, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 49, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 49, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 49, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 49, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 49, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 49, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 49, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 49, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 49, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 49, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 49, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 49, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 49, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 49, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 50, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 50, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 50, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 50, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 50, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 50, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 50, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 50, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 50, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 50, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 50, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 50, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 50, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 50, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 50, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 50, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 50, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 50, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 51, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 51, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 51, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 51, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 51, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 51, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 51, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 51, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 51, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 51, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 51, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 51, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 51, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 51, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 51, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 51, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 51, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 51, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 52, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 52, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 52, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 52, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 52, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 52, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 52, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 52, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 52, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 52, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 52, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 52, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 52, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 52, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 52, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 52, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 52, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 52, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 53, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 53, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 53, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 53, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 53, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 53, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 53, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 53, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 53, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 53, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 53, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 53, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 53, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 53, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 53, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 53, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 53, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 53, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 54, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 54, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 54, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 54, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 54, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 54, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 54, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 54, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 54, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 54, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 54, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 54, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 54, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 54, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 54, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 54, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 54, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 54, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 55, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 55, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 55, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 55, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 55, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 55, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 55, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 55, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 55, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 55, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 55, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 55, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 55, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 55, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 55, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 55, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 55, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 55, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 56, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 56, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 56, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 56, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 56, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 56, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 56, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 56, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 56, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 56, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 56, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 56, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 56, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 56, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 56, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 56, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 56, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 56, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 57, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 57, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 57, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 57, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 57, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 57, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 57, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 57, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 57, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 57, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 57, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 57, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 57, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 57, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 57, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 57, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 57, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 57, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 58, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 58, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 58, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 58, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 58, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 58, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 58, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 58, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 58, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 58, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 58, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 58, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 58, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 58, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 58, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 58, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 58, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 58, 'n_neighbors': 9, 'p': 2}\n","0.978706 (0.004286) with: {'leaf_size': 59, 'n_neighbors': 1, 'p': 1}\n","0.968378 (0.010196) with: {'leaf_size': 59, 'n_neighbors': 1, 'p': 2}\n","0.969878 (0.003960) with: {'leaf_size': 59, 'n_neighbors': 2, 'p': 1}\n","0.956476 (0.004192) with: {'leaf_size': 59, 'n_neighbors': 2, 'p': 2}\n","0.979521 (0.002183) with: {'leaf_size': 59, 'n_neighbors': 3, 'p': 1}\n","0.962545 (0.010430) with: {'leaf_size': 59, 'n_neighbors': 3, 'p': 2}\n","0.968523 (0.005175) with: {'leaf_size': 59, 'n_neighbors': 4, 'p': 1}\n","0.952071 (0.004291) with: {'leaf_size': 59, 'n_neighbors': 4, 'p': 2}\n","0.969919 (0.014645) with: {'leaf_size': 59, 'n_neighbors': 5, 'p': 1}\n","0.948231 (0.014487) with: {'leaf_size': 59, 'n_neighbors': 5, 'p': 2}\n","0.949988 (0.018866) with: {'leaf_size': 59, 'n_neighbors': 6, 'p': 1}\n","0.934579 (0.018279) with: {'leaf_size': 59, 'n_neighbors': 6, 'p': 2}\n","0.944799 (0.027836) with: {'leaf_size': 59, 'n_neighbors': 7, 'p': 1}\n","0.926543 (0.025339) with: {'leaf_size': 59, 'n_neighbors': 7, 'p': 2}\n","0.904663 (0.024176) with: {'leaf_size': 59, 'n_neighbors': 8, 'p': 1}\n","0.887893 (0.027957) with: {'leaf_size': 59, 'n_neighbors': 8, 'p': 2}\n","0.868581 (0.031102) with: {'leaf_size': 59, 'n_neighbors': 9, 'p': 1}\n","0.853919 (0.040924) with: {'leaf_size': 59, 'n_neighbors': 9, 'p': 2}\n","Time taken to run KNN =  112.59424495697021 seconds\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","start_time_KNNO=time.time()\n","# n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35, 40, 45]\n","n_neighbors = list(range(1,10))\n","leaf_size = list(range(1,60))\n","p=[1,2]\n","# weights = ['uniform', 'distance']\n","# algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n","knn = KNeighborsClassifier()\n","# grid = dict(n_neighbors=n_neighbors, weights=weights, algorithm = algorithm)\n","grid = dict(n_neighbors=n_neighbors, leaf_size = leaf_size, p = p)\n","model(df_new, y_attacktype, knn, grid, cv)\n","elapsed_time_KNNO = time.time() - start_time_KNNO\n","print(\"Time taken to run KNN = \", elapsed_time_KNNO, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"Dv5OzRaY6qST"},"source":["### FL: attack types"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219898,"status":"ok","timestamp":1642334027872,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"gMw1o0aa6t5N","outputId":"d96d4ea2-ff37-4b4a-f771-139a2292c2cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 7, 'p': 2}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        82\n","   macro avg       1.00      1.00      1.00        82\n","weighted avg       1.00      1.00      1.00        82\n","\n","FPR: 0.000000\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n","FPR: 0.000000\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        18\n","   macro avg       1.00      1.00      1.00        18\n","weighted avg       1.00      1.00      1.00        18\n","\n","FPR: 0.000000\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n","FPR: 0.000000\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","FPR: 0.000000\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 0.931111\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      0.50      0.67         2\n","          34       0.50      0.50      0.50         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.93        30\n","   macro avg       0.94      0.93      0.93        30\n","weighted avg       0.94      0.93      0.93        30\n","\n","FPR: 0.004762\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        48\n","   macro avg       1.00      1.00      1.00        48\n","weighted avg       1.00      1.00      1.00        48\n","\n","FPR: 0.000000\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.992809 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 0.992809, scores: [0.98275862 1.         1.         1.         0.98128655]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        72\n","   macro avg       1.00      1.00      1.00        72\n","weighted avg       1.00      1.00      1.00        72\n","\n","FPR: 0.000000\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.967626 using {'leaf_size': 1, 'n_neighbors': 9, 'p': 1}\n","On all train set, mean of scores: 0.967626, scores: [0.94146341 0.95       1.         0.97333333 0.97333333]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         3\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        51\n","   macro avg       1.00      1.00      1.00        51\n","weighted avg       1.00      1.00      1.00        51\n","\n","FPR: 0.000000\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.993111, FPR: 0.000476\n"]}],"source":["start_time_KNN=time.time()\n","# n_neighbors_KNN1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35, 40, 45]\n","# weights_KNN1 = ['uniform', 'distance']\n","# algorithm_KNN1 = ['auto', 'ball_tree', 'kd_tree', 'brute']\n","n_neighbors = list(range(1,10))\n","leaf_size = list(range(1,60))\n","p=[1,2]\n","# weights = ['uniform', 'distance']\n","# algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n","# grid = dict(n_neighbors=n_neighbors, weights=weights, algorithm = algorithm)\n","model_KNN1=KNeighborsClassifier()\n","# grid_KNN1 = dict(n_neighbors = n_neighbors_KNN1, weights=weights_KNN1, algorithm = algorithm_KNN1)\n","# grid_KNN1 = dict(n_neighbors = n_neighbors_KNN1)\n","grid_KNN1 = dict(n_neighbors=n_neighbors, leaf_size = leaf_size, p = p)\n","federated_learning(1, model_KNN1, grid_KNN1, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_KNN = time.time() - start_time_KNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1373,"status":"ok","timestamp":1642334197439,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"5u6ifsXGnAjg","outputId":"23dab8a6-ee2e-49c9-fa34-d50cb0b6d963"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.993641 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 0.993641, scores: [1.         1.         1.         0.98358974 0.98461538]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        82\n","   macro avg       1.00      1.00      1.00        82\n","weighted avg       1.00      1.00      1.00        82\n","\n","FPR: 0.000000\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n","FPR: 0.000000\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 0.984762 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 0.984762, scores: [1.         1.         1.         0.92380952 1.        ]\n","On test set, Accuracy: 0.940741\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       0.67      1.00      0.80         2\n","          34       1.00      0.50      0.67         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.94        18\n","   macro avg       0.96      0.94      0.94        18\n","weighted avg       0.96      0.94      0.94        18\n","\n","FPR: 0.006944\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n","FPR: 0.000000\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","FPR: 0.000000\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 0.991111 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 0.991111, scores: [1.         1.         0.95555556 1.         1.        ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        30\n","   macro avg       1.00      1.00      1.00        30\n","weighted avg       1.00      1.00      1.00        30\n","\n","FPR: 0.000000\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        48\n","   macro avg       1.00      1.00      1.00        48\n","weighted avg       1.00      1.00      1.00        48\n","\n","FPR: 0.000000\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.979790 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 0.979790, scores: [0.95977011 1.         1.         0.98128655 0.95789474]\n","On test set, Accuracy: 0.985185\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       1.00      1.00      1.00         2\n","          37       0.67      1.00      0.80         2\n","          38       1.00      0.50      0.67         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.99        72\n","   macro avg       0.99      0.98      0.98        72\n","weighted avg       0.99      0.99      0.99        72\n","\n","FPR: 0.000476\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.952415 using {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n","On all train set, mean of scores: 0.952415, scores: [0.91707317 0.95       0.97333333 0.97333333 0.94833333]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         3\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        51\n","   macro avg       1.00      1.00      1.00        51\n","weighted avg       1.00      1.00      1.00        51\n","\n","FPR: 0.000000\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.992593, FPR: 0.000742\n","Time taken to run Federated Learning with KNN as initial model =  22.093693685531616 seconds\n"]}],"source":["start_time_KNN2=time.time()\n","n_neighbors_KNN2 = [2]\n","leaf_size = [1]\n","p=[1]\n","# weights_KNN2 = ['uniform']\n","# algorithm_KNN2 = ['auto']        \n","model_KNN2 = KNeighborsClassifier()\n","# grid_KNN2 = dict(n_neighbors = n_neighbors_KNN2, weights=weights_KNN2, algorithm = algorithm_KNN2)\n","grid_KNN2 = dict(n_neighbors = n_neighbors_KNN2, leaf_size = leaf_size, p = p)\n","print(\"Centralized learning model aggregate the mean of the parameters from locally trained models and start the second round\")\n","federated_learning(2, model_KNN2, grid_KNN2, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_KNN2 = time.time() - start_time_KNN2 + elapsed_time_KNN\n","print(\"Time taken to run Federated Learning with KNN as initial model = \", elapsed_time_KNN2/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"S3TRF4Ut-6OG"},"source":["### FL Group: attack types"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1679,"status":"ok","timestamp":1642334341057,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"9jWYuBGF-9X8","outputId":"98c6aff2-4adc-4044-9cbb-7aae24764d94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.993641 using {'leaf_size': 1, 'n_neighbors': 4, 'p': 1}\n","On all train set, mean of scores: 0.993641, scores: [1.         1.         1.         0.98358974 0.98461538]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        82\n","   macro avg       1.00      1.00      1.00        82\n","weighted avg       1.00      1.00      1.00        82\n","\n","FPR: 0.000000\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        60\n","   macro avg       1.00      1.00      1.00        60\n","weighted avg       1.00      1.00      1.00        60\n","\n","FPR: 0.000000\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        18\n","   macro avg       1.00      1.00      1.00        18\n","weighted avg       1.00      1.00      1.00        18\n","\n","FPR: 0.000000\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n","FPR: 0.000000\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 4, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        42\n","   macro avg       1.00      1.00      1.00        42\n","weighted avg       1.00      1.00      1.00        42\n","\n","FPR: 0.000000\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 0.931111\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      0.50      0.67         2\n","          34       0.50      0.50      0.50         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.93        30\n","   macro avg       0.94      0.93      0.93        30\n","weighted avg       0.94      0.93      0.93        30\n","\n","FPR: 0.004762\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 1.000000 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 1.000000, scores: [1. 1. 1. 1. 1.]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           1.00        48\n","   macro avg       1.00      1.00      1.00        48\n","weighted avg       1.00      1.00      1.00        48\n","\n","FPR: 0.000000\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.992809 using {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n","On all train set, mean of scores: 0.992809, scores: [0.98275862 1.         1.         1.         0.98128655]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        72\n","   macro avg       1.00      1.00      1.00        72\n","weighted avg       1.00      1.00      1.00        72\n","\n","FPR: 0.000000\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.967626 using {'leaf_size': 1, 'n_neighbors': 9, 'p': 1}\n","On all train set, mean of scores: 0.967626, scores: [0.94146341 0.95       1.         0.97333333 0.97333333]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         3\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        51\n","   macro avg       1.00      1.00      1.00        51\n","weighted avg       1.00      1.00      1.00        51\n","\n","FPR: 0.000000\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 1.000000\n","Appliances group: Device 9, Accuracy: 1.000000\n","Controller group: Device 2, Accuracy: 1.000000\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.988519\n","Federated Group: Round: 2, Accuracy: 0.993111, FPR: 0.000476\n","Time taken to run Federated Learning with KNN as initial model =  22.09772343635559 seconds\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","model_KNN2 = model_camera = model_appliances = model_energy = model_controller = KNeighborsClassifier()\n","cv_KNN2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","# 0, 4\n","n_neighbors_camera = [4]\n","leaf_size = [1]\n","p=[1]\n","# weights_camera = ['uniform']\n","# algorithm_camera = ['auto']  \n","# grid_camera = dict(n_neighbors = n_neighbors_camera, weights = weights_camera, algorithm = algorithm_camera)\n","grid_camera = dict(n_neighbors = n_neighbors_camera, leaf_size = leaf_size, p = p)\n","# 9\n","n_neighbors_appliances = [9]\n","leaf_size = [1]\n","p=[1]\n","# weights_appliances = ['uniform']\n","# algorithm_appliances = ['auto']  \n","# grid_appliances = dict(n_neighbors = n_neighbors_appliances, weights = weights_appliances, algorithm = algorithm_appliances)\n","grid_appliances = dict(n_neighbors = n_neighbors_appliances, leaf_size = leaf_size, p = p)\n","# 1, 3, 5, 6, 7, 8\n","n_neighbors_energy = [1]\n","leaf_size = [1]\n","p=[1]\n","# weights_energy = ['uniform']\n","# algorithm_energy = ['auto']  \n","# grid_energy = dict(n_neighbors = n_neighbors_energy, weights = weights_energy, algorithm = algorithm_energy)\n","grid_energy = dict(n_neighbors = n_neighbors_energy, leaf_size = leaf_size, p = p)\n","# 2\n","n_neighbors_controller = [1]\n","leaf_size = [1]\n","p=[1]\n","# weights_controller = ['uniform']\n","# algorithm_controller = ['auto']  \n","# grid_controller = dict(n_neighbors = n_neighbors_controller, weights = weights_controller, algorithm = algorithm_controller)\n","grid_controller = dict(n_neighbors = n_neighbors_controller, leaf_size = leaf_size, p = p)\n","start_time_KNN3 = time.time() \n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_KNN3 = time.time() - start_time_KNN3 + elapsed_time_KNN\n","print(\"Time taken to run Federated Learning with KNN as initial model = \", elapsed_time_KNN3/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"tmQlpebD3iKx"},"source":["## Decision Tree"]},{"cell_type":"markdown","metadata":{"id":"IIuty5wa3m2j"},"source":["### Decision Tree: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":6991,"status":"error","timestamp":1642758365875,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"7NLakog73l6P","outputId":"0ffe1118-2feb-403f-9bc4-cffd6a231868"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-95ab372da3c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# grid = dict(criterion = criterion, splitter = splitter, max_depth = max_depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0melapsed_time_DTO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time_DTO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken to run Decision Tree = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed_time_DTO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-8af2e0601a1d>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(df, y, rf, grid, cv)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgrid_search_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_weighted'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgrid_result_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result_rf\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","start_time_DTO=time.time()\n","# criterion = ['gini', 'entropy']\n","# splitter = ['best', 'random']\n","# max_depth= [5,10,15,20,30,40,50,100,150]\n","\n","max_depth = [5, 10, 15, 20, 30, 40, 50, 100, 150]\n","min_samples_split = [0.1, 1.0, 2, 3, 4, 5, 6, 7]\n","min_samples_leaf = list(range(1,5))\n","\n","dt = DecisionTreeClassifier()\n","# grid = dict(criterion = criterion, splitter = splitter, max_depth = max_depth)\n","grid = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n","model(df, y, dt, grid, cv)\n","elapsed_time_DTO = time.time() - start_time_DTO\n","print(\"Time taken to run Decision Tree = \", elapsed_time_DTO, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"A5Bh23yY3w1o"},"source":["### FL: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1524798,"status":"ok","timestamp":1642387620388,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"OBcIhIOH3zcR","outputId":"ad5e01f9-7fb6-4290-db18-faeb9fa2c9ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.998310 using {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998254, scores: [0.99827875 0.99844723 0.99859987 0.99772479 0.99822062]\n","On test set, Accuracy: 0.998654\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.88      0.89      0.88        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.94      0.94      0.94     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.055913\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.997699 using {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.997667, scores: [0.99771331 0.99729845 0.99685535 0.9984671  0.99799886]\n","On test set, Accuracy: 0.996999\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.74      0.83      0.78        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.87      0.91      0.89      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.085724\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999689 using {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","On all train set, mean of scores: 0.999689, scores: [0.99944734 0.99957814 0.99985442 0.99956326 1.        ]\n","On test set, Accuracy: 0.999450\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.81      0.94      0.87        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.90      0.97      0.94      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.028007\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.999099 using {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.999061, scores: [0.99875666 0.99947327 0.9987418  0.99877062 0.99956337]\n","On test set, Accuracy: 0.998465\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.78      0.83      0.80        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.89      0.92      0.90     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.083797\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.999220 using {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","On all train set, mean of scores: 0.999145, scores: [0.99946705 0.99888084 0.99927826 0.99908309 0.99901534]\n","On test set, Accuracy: 0.999017\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.81      0.85      0.83        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.91      0.93      0.92     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.073456\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999882 using {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.999831, scores: [1.         0.99986359 1.         0.99974273 0.99954744]\n","On test set, Accuracy: 0.999880\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      0.92      0.95      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.083333\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.999091 using {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","On all train set, mean of scores: 0.999024, scores: [0.99917535 0.99880485 0.99942833 0.99846904 0.99924388]\n","On test set, Accuracy: 0.999325\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.88      0.93      0.90        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.97      0.95      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.033563\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.999201 using {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.999185, scores: [0.99909978 0.99920561 0.99921532 0.99902915 0.99937403]\n","On test set, Accuracy: 0.999180\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.82      0.96      0.88        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.91      0.98      0.94     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.021190\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998341 using {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","On all train set, mean of scores: 0.998249, scores: [0.99825294 0.99856604 0.99815829 0.99825823 0.99801094]\n","On test set, Accuracy: 0.997920\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.87      0.72      0.79        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.93      0.86      0.89     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.139175\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.998414 using {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","On all train set, mean of scores: 0.998224, scores: [0.99873684 0.99858773 0.99826366 0.99758658 0.99794648]\n","On test set, Accuracy: 0.998310\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.83      0.88      0.85        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.91      0.94      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.060517\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.998720, FPR: 0.066467\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","start_time_DT=time.time()\n","# criterion_DT1 = ['gini', 'entropy']\n","# splitter_DT1 = ['best', 'random']\n","# max_depth_DT1 = [5,10,15,20,30,40,50,100,150]\n","\n","max_depth = [5, 10, 15, 20, 30, 40, 50, 100, 150, 200]\n","min_samples_split = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2, 3, 4, 5, 6, 7]\n","min_samples_leaf = list(range(1,5))\n","\n","model_DT1 = DecisionTreeClassifier()\n","grid_DT1 = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n","# grid_DT1 = dict(criterion = criterion_DT1, splitter = splitter_DT1, max_depth = max_depth_DT1)\n","federated_learning(1, model_DT1, grid_DT1, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_DT = time.time() - start_time_DT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16534,"status":"ok","timestamp":1642388121405,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"iaK7qJXR-i2x","outputId":"f9fa5aa5-51f0-44e0-bc38-542fb0b67b8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.997822 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.997860, scores: [0.99844723 0.9978441  0.99801499 0.99729317 0.99770074]\n","On test set, Accuracy: 0.998184\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.88      0.80      0.84        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.94      0.90      0.92     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.099087\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.997357 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.997278, scores: [0.99701408 0.99682257 0.99682139 0.99830248 0.9974271 ]\n","On test set, Accuracy: 0.997129\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.79      0.78      0.79        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.90      0.89      0.89      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.110860\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999414 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.999473, scores: [0.99944734 0.99942833 0.9995455  0.9992425  0.99970315]\n","On test set, Accuracy: 0.999294\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.88      0.78      0.82        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.89      0.91      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.111226\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.998819 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998854, scores: [0.99885208 0.99919584 0.99862676 0.99832212 0.99927219]\n","On test set, Accuracy: 0.998295\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.78      0.78      0.78        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.89      0.89      0.89     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.111539\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.999023 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.999101, scores: [0.99918217 0.99906737 0.99888084 0.99916782 0.99920645]\n","On test set, Accuracy: 0.998688\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.81      0.73      0.77        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.91      0.87      0.88     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.134396\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999825 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.999825, scores: [1.         0.99986359 0.99984917 0.99986502 0.99954744]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      1.00      1.00      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.998789 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998856, scores: [0.99891993 0.99863918 0.998671   0.99880485 0.99924388]\n","On test set, Accuracy: 0.998979\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.84      0.87      0.85        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.92      0.93      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.066953\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.998868 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998887, scores: [0.99864033 0.9991954  0.99911174 0.99841346 0.99907371]\n","On test set, Accuracy: 0.999081\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.86      0.88      0.87        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.93      0.94      0.93     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.062750\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998145 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998243, scores: [0.99822349 0.99874528 0.99830473 0.99792984 0.99801094]\n","On test set, Accuracy: 0.997802\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.89      0.68      0.77        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.94      0.84      0.89     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.159937\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.997864 using {'max_depth': 39, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998021, scores: [0.99828498 0.99843731 0.99826366 0.99720119 0.99791816]\n","On test set, Accuracy: 0.997817\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.82      0.80      0.81        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.91      0.90      0.90      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.100517\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.998527, FPR: 0.095726\n","Time taken to run Federated Learning with Decision Tree as initial model =  154.0514803647995 seconds\n"]}],"source":["start_time_DT2=time.time()\n","# criterion_DT2 = ['entropy']\n","# splitter_DT2 = ['best']\n","# max_depth_DT2 = [37]\n","max_depth = [39]\n","min_samples_split = [5]\n","min_samples_leaf = [2]\n","model_DT2 = DecisionTreeClassifier()\n","# grid_DT2 = dict(criterion = criterion_DT2, splitter = splitter_DT2, max_depth = max_depth_DT2)\n","grid_DT2 = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)   \n","federated_learning(2, model_DT2, grid_DT2, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_DT2 = time.time() - start_time_DT2 + elapsed_time_DT\n","print(\"Time taken to run Federated Learning with Decision Tree as initial model = \", elapsed_time_DT2/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"gQ6BzoLFCvZh"},"source":["### FL Group: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15599,"status":"ok","timestamp":1642388324778,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"SMrEygWZCzCw","outputId":"7c98d54b-0f78-49c9-b09a-e5a1042ec27d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n","Best: 0.998024 using {'max_depth': 45, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","On all train set, mean of scores: 0.998031, scores: [0.99845993 0.99844723 0.99801499 0.99753161 0.99770074]\n","On test set, Accuracy: 0.998184\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.88      0.80      0.84        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.94      0.90      0.92     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.099087\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.997155 using {'max_depth': 47, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.997168, scores: [0.99669569 0.99695063 0.99649373 0.99830248 0.99739992]\n","On test set, Accuracy: 0.997359\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.81      0.80      0.80        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.90      0.90      0.90      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.102328\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n","Best: 0.999689 using {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","On all train set, mean of scores: 0.999689, scores: [0.99944734 0.99957814 0.99985442 0.99956326 1.        ]\n","On test set, Accuracy: 0.999450\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.81      0.94      0.87        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.90      0.97      0.94      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.028007\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n","Best: 0.998835 using {'max_depth': 47, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998835, scores: [0.99885208 0.99919584 0.99862676 0.99832212 0.99917606]\n","On test set, Accuracy: 0.998295\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.78      0.78      0.78        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.89      0.89      0.89     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.111539\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.999100 using {'max_depth': 45, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","On all train set, mean of scores: 0.999120, scores: [0.99946705 0.99896501 0.99888084 0.99908309 0.99920645]\n","On test set, Accuracy: 0.998834\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.84      0.76      0.79        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.92      0.88      0.90     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.122165\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","Best: 0.999855 using {'max_depth': 47, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.999795, scores: [0.99984917 0.99986359 0.99984917 0.99986502 0.99954744]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      1.00      1.00         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      1.00      1.00      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","Best: 0.998754 using {'max_depth': 47, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998754, scores: [0.99891993 0.99863918 0.998671   0.99829409 0.99924388]\n","On test set, Accuracy: 0.999442\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.88      0.97      0.92        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.98      0.96      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.016896\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.998801 using {'max_depth': 47, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998863, scores: [0.99864033 0.99910009 0.99911174 0.9983887  0.99907371]\n","On test set, Accuracy: 0.999015\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.84      0.88      0.86        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.92      0.94      0.93     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.062785\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.998098 using {'max_depth': 47, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","On all train set, mean of scores: 0.998187, scores: [0.99822349 0.99855295 0.99830473 0.99830486 0.99754774]\n","On test set, Accuracy: 0.997717\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.89      0.67      0.76        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.94      0.83      0.88     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.166881\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n","Best: 0.998267 using {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","On all train set, mean of scores: 0.998236, scores: [0.99888371 0.99858773 0.99810698 0.99791816 0.99768382]\n","On test set, Accuracy: 0.998310\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.83      0.88      0.85        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.91      0.94      0.93      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.060517\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 0.998509\n","Appliances group: Device 9, Accuracy: 0.998310\n","Controller group: Device 2, Accuracy: 0.999450\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.998638\n","Federated Group: Round: 2, Accuracy: 0.998661, FPR: 0.077021\n","Time taken to run Federated Learning with Decision Tree as initial model =  153.95429277420044 seconds\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","model_DT2 = model_camera = model_appliances = model_energy = model_controller = DecisionTreeClassifier()\n","cv_DT2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","# 0, 4\n","# criterion_camera = ['entropy']\n","# splitter_camera = ['best']\n","# max_depth_camera = [33]\n","max_depth = [45]\n","min_samples_split = [6]\n","min_samples_leaf = [2]\n","grid_camera = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf) \n","# grid_camera = dict(criterion = criterion_camera, splitter = splitter_camera, max_depth = max_depth_camera)\n","\n","# 9\n","# criterion_appliances = ['entropy']\n","# splitter_appliances = ['best']\n","# max_depth_appliance = [150]\n","# grid_appliances = dict(criterion = criterion_appliances, splitter = splitter_appliances, max_depth = max_depth_appliance)\n","max_depth = [10]\n","min_samples_split = [7]\n","min_samples_leaf = [4]\n","grid_appliances = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf) \n","\n","# 1, 3, 5, 6, 7, 8\n","# criterion_energy = ['gini']\n","# splitter_energy = ['best']\n","# max_depth_energy = [20]\n","# grid_energy = dict(criterion = criterion_energy, splitter = splitter_energy, max_depth = max_depth_energy)\n","max_depth = [47]\n","min_samples_split = [5]\n","min_samples_leaf = [2]\n","grid_energy = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf) \n","\n","# 2\n","# criterion_controller = ['entropy']\n","# splitter_controller = ['best']\n","# max_depth_controller = [30]\n","# grid_controller = dict(criterion = criterion_controller, splitter = splitter_controller, max_depth = max_depth_controller)\n","max_depth = [10]\n","min_samples_split = [0.1]\n","min_samples_leaf = [1]\n","grid_controller = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf) \n","\n","start_time_DT3 = time.time()\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_DT3 = time.time() - start_time_DT3 + elapsed_time_DT\n","print(\"Time taken to run Federated Learning with Decision Tree as initial model = \", elapsed_time_DT3/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"mEeo5Z-_3ri8"},"source":["### Decision Tree: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35295,"status":"ok","timestamp":1642377115400,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"bOilzecr3wVz","outputId":"38a405c2-dc4a-4fb1-9b03-e342a4e324a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best: 0.885398 using {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","Time taken to run Random Forest =  0.032326459884643555 seconds\n","DecisionTreeClassifier(max_depth=30, min_samples_split=3)\n","On all train set, mean of scores: 0.887537, scores: [0.89282521 0.90845238 0.85312902 0.89576803 0.88751018]\n","On test set, Accuracy: 0.884082\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.84      0.89        19\n","           1       1.00      0.80      0.89        20\n","           2       0.75      0.90      0.82        20\n","           3       0.74      1.00      0.85        14\n","           4       0.92      0.79      0.85        14\n","           5       1.00      0.86      0.92        14\n","           6       0.92      1.00      0.96        12\n","           7       1.00      0.92      0.96        12\n","           8       0.91      0.83      0.87        12\n","           9       1.00      1.00      1.00         8\n","          10       0.89      1.00      0.94         8\n","          11       1.00      1.00      1.00         8\n","          12       0.80      0.86      0.83        14\n","          13       0.81      0.93      0.87        14\n","          14       0.73      0.79      0.76        14\n","          15       1.00      0.88      0.93         8\n","          16       0.88      0.88      0.88         8\n","          17       0.75      0.75      0.75         8\n","          18       1.00      1.00      1.00         1\n","          19       1.00      1.00      1.00         2\n","          20       1.00      1.00      1.00         2\n","          21       1.00      1.00      1.00         2\n","          22       0.67      1.00      0.80         2\n","          23       1.00      0.50      0.67         2\n","          24       0.95      0.83      0.89        24\n","          25       0.76      0.96      0.85        26\n","          26       1.00      0.92      0.96        24\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       0.92      0.96      0.94        24\n","          31       0.92      1.00      0.96        22\n","          32       0.95      0.88      0.91        24\n","          33       1.00      0.67      0.80         6\n","          34       0.75      1.00      0.86         6\n","          35       1.00      0.67      0.80         6\n","          36       1.00      0.50      0.67         6\n","          37       0.67      1.00      0.80         6\n","          38       0.75      1.00      0.86         6\n","          39       0.67      0.67      0.67         6\n","          40       1.00      0.50      0.67         6\n","          41       1.00      0.67      0.80         6\n","          42       1.00      1.00      1.00         6\n","          43       1.00      1.00      1.00         6\n","          44       1.00      1.00      1.00         6\n","\n","    accuracy                           0.88       460\n","   macro avg       0.91      0.88      0.89       460\n","weighted avg       0.90      0.88      0.88       460\n","\n","FPR: 0.002651\n","0.121199 (0.008145) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.072076 (0.021604) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.230214 (0.040064) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.228132 (0.037593) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.229634 (0.040850) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.228141 (0.036952) with: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.121199 (0.008145) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.072076 (0.021604) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.230200 (0.041724) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.229250 (0.040265) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.231343 (0.041835) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.121199 (0.008145) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.072076 (0.021604) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.230214 (0.040064) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.230214 (0.040064) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.121199 (0.008145) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.078473 (0.016184) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.072076 (0.021604) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.229263 (0.038612) with: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.188309 (0.008357) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.492273 (0.052782) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.493241 (0.053140) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.493338 (0.050966) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.494730 (0.054726) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.494155 (0.055604) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.493234 (0.052622) with: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.188309 (0.008357) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.497308 (0.053048) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.497475 (0.051302) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.494456 (0.051749) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.495559 (0.051913) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.495751 (0.050745) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.492159 (0.053541) with: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.188309 (0.008357) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.492594 (0.049380) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.491662 (0.053832) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.492235 (0.050615) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.491098 (0.053077) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.494447 (0.048937) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.491760 (0.051992) with: {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.188309 (0.008357) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.491407 (0.053113) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.492158 (0.052394) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.491412 (0.052719) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.493075 (0.050523) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.492141 (0.052370) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.492663 (0.053181) with: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.758491 (0.030885) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.757151 (0.028188) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.750058 (0.030141) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.756972 (0.028552) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.749905 (0.029904) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.753391 (0.034970) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.752498 (0.025343) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.756619 (0.027930) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.751197 (0.027604) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.753091 (0.025197) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.751503 (0.024042) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.752570 (0.029037) with: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.747899 (0.025752) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.748448 (0.026123) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.748340 (0.027440) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.749272 (0.027708) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.748858 (0.025433) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.750572 (0.025822) with: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.744053 (0.025884) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.743304 (0.025840) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.746068 (0.029234) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.745306 (0.027958) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.747084 (0.027221) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.747714 (0.027948) with: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.860542 (0.020043) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.858974 (0.014920) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.857842 (0.015197) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.857493 (0.017495) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.852221 (0.019826) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.856947 (0.019965) with: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.849367 (0.015491) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.851290 (0.013398) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.850939 (0.014835) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.850317 (0.011016) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.849736 (0.014694) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.854210 (0.017187) with: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.848376 (0.014083) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.848325 (0.013111) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.843890 (0.012630) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.843245 (0.015211) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.847130 (0.015588) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.845970 (0.013664) with: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.840001 (0.018719) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.839308 (0.019849) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.837604 (0.019262) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.839343 (0.016444) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.840835 (0.016428) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.835520 (0.020190) with: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.877914 (0.020548) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.885398 (0.017052) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.882155 (0.019469) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.881832 (0.015506) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.879068 (0.019229) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.874379 (0.015622) with: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.869457 (0.009667) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.870389 (0.013939) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.873432 (0.008361) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.870098 (0.013353) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.873557 (0.013594) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.876478 (0.017493) with: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.869197 (0.012424) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.870906 (0.016158) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.871529 (0.018763) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.867419 (0.015421) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.874130 (0.011916) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.868975 (0.015590) with: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.861919 (0.019325) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.862477 (0.015851) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.861599 (0.014328) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.857320 (0.022707) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.862385 (0.017876) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.862756 (0.016929) with: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.878436 (0.020344) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.882802 (0.013604) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.878508 (0.016983) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.878855 (0.022844) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.876854 (0.015212) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.876788 (0.014030) with: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.868902 (0.012338) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.874455 (0.011845) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.867130 (0.018342) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.872032 (0.012230) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.869573 (0.010266) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.875378 (0.016764) with: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.866791 (0.018758) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.867747 (0.016372) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.869948 (0.016285) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.869449 (0.013335) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.868469 (0.016473) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.867022 (0.018319) with: {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.861387 (0.018198) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.860966 (0.022168) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.860947 (0.017656) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.862863 (0.015625) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.861989 (0.019063) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.859320 (0.020049) with: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.883746 (0.022451) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.880321 (0.017117) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.879237 (0.019488) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.881335 (0.016650) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.878727 (0.013883) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.879235 (0.014526) with: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.873045 (0.015312) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.868167 (0.010943) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.870598 (0.015370) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.872179 (0.013449) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.870752 (0.013325) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.875090 (0.015226) with: {'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.869150 (0.018082) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.868602 (0.014704) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.867356 (0.016562) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.868295 (0.016348) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.869136 (0.012391) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.869313 (0.016924) with: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.863241 (0.017812) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.860610 (0.016982) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.859578 (0.017634) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.861227 (0.017866) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.861903 (0.016797) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.859813 (0.018236) with: {'max_depth': 50, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.884968 (0.019467) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.883784 (0.018468) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.880016 (0.018900) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.876317 (0.020038) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.878836 (0.020239) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.875239 (0.013459) with: {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.871639 (0.009281) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.871772 (0.010450) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.868009 (0.015067) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.867387 (0.016782) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.870850 (0.014000) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.875280 (0.018382) with: {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.866993 (0.014130) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.867522 (0.016758) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.869613 (0.013190) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.867656 (0.012536) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.869123 (0.016291) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.866114 (0.015156) with: {'max_depth': 100, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.860569 (0.017400) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.861147 (0.017409) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.860815 (0.015087) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.860748 (0.019065) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.858868 (0.019189) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.860468 (0.017911) with: {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.878845 (0.018897) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.877868 (0.020131) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.882814 (0.019347) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.874951 (0.021551) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.877086 (0.015625) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.877773 (0.015213) with: {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.869498 (0.013489) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.871128 (0.015181) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.872777 (0.013111) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.870680 (0.011953) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.874528 (0.014442) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.874341 (0.016482) with: {'max_depth': 150, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.870740 (0.014788) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.868921 (0.014847) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.870589 (0.014916) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.871814 (0.015085) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.867407 (0.014854) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.868928 (0.016088) with: {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.862686 (0.017214) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.862190 (0.017700) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.860821 (0.017263) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.864300 (0.017541) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.861637 (0.016012) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.862364 (0.016540) with: {'max_depth': 150, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 1.0}\n","0.880407 (0.019283) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.877646 (0.018907) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","0.880345 (0.014198) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 4}\n","0.878371 (0.014816) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 5}\n","0.877752 (0.014698) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 6}\n","0.877419 (0.017157) with: {'max_depth': 200, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 1.0}\n","0.871427 (0.012472) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","0.869416 (0.012076) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","0.869900 (0.012759) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","0.875149 (0.014501) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 5}\n","0.871344 (0.017318) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 6}\n","0.874276 (0.012515) with: {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 1.0}\n","0.867376 (0.015683) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","0.866889 (0.016866) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 3}\n","0.869929 (0.013133) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 4}\n","0.869833 (0.014737) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 5}\n","0.868022 (0.015378) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","0.868387 (0.015530) with: {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 7}\n","0.214002 (0.011119) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.1}\n","0.131962 (0.017037) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n","0.095704 (0.029462) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.3}\n","0.094582 (0.030342) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.4}\n","0.094582 (0.030342) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.5}\n","0.074961 (0.025652) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.6}\n","0.065459 (0.022464) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.7}\n","0.054233 (0.024121) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.8}\n","0.046724 (0.023543) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 0.9}\n","0.029713 (0.002776) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 1.0}\n","0.862031 (0.017466) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","0.863519 (0.016428) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","0.858107 (0.018088) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 4}\n","0.857266 (0.018286) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 5}\n","0.858649 (0.016499) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 6}\n","0.861099 (0.017930) with: {'max_depth': 200, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","Time taken to run Decision Tree =  35.00631260871887 seconds\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","start_time_DTO=time.time()\n","# criterion = ['gini', 'entropy']\n","# splitter = ['best', 'random']\n","# max_features = ['auto', 'sqrt', 'log2', None]\n","\n","max_depth = [5, 10, 15, 20, 30, 40, 50, 100, 150, 200]\n","min_samples_split = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2, 3, 4, 5, 6, 7]\n","min_samples_leaf = list(range(1,5))\n","\n","dt = DecisionTreeClassifier()\n","# grid = dict(criterion = criterion, splitter = splitter, max_features = max_features)\n","grid = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n","model(df_new, y_attacktype, dt, grid, cv)\n","elapsed_time_DTO = time.time() - start_time_DTO\n","print(\"Time taken to run Decision Tree = \", elapsed_time_DTO, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"F5oTOMz_3z5S"},"source":["### FL: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108417,"status":"ok","timestamp":1642377264523,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"KNdozEQU37Up","outputId":"08ec5710-7126-41cf-a748-73fd4db471b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.912459 using {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","On all train set, mean of scores: 0.898647, scores: [0.89641026 0.92205128 0.87990232 0.92615385 0.86871795]\n","On test set, Accuracy: 0.960976\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      0.50      0.67         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       0.67      1.00      0.80         2\n","          21       1.00      0.50      0.67         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       0.67      1.00      0.80         2\n","          28       1.00      0.50      0.67         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.96        82\n","   macro avg       0.97      0.96      0.96        82\n","weighted avg       0.98      0.96      0.96        82\n","\n","FPR: 0.001042\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 0.950816 using {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","On all train set, mean of scores: 0.927931, scores: [0.93611111 1.         0.94751773 0.86382979 0.89219858]\n","On test set, Accuracy: 0.964444\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       0.67      1.00      0.80         2\n","          31       0.67      1.00      0.80         2\n","          32       1.00      0.50      0.67         2\n","          36       1.00      0.50      0.67         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.97        60\n","   macro avg       0.98      0.97      0.96        60\n","weighted avg       0.98      0.97      0.96        60\n","\n","FPR: 0.001149\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 0.970476 using {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.955238, scores: [1.         0.85238095 1.         0.92380952 1.        ]\n","On test set, Accuracy: 0.940741\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      0.50      0.67         2\n","           9       0.67      1.00      0.80         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.94        18\n","   macro avg       0.96      0.94      0.94        18\n","weighted avg       0.96      0.94      0.94        18\n","\n","FPR: 0.006944\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 0.939842 using {'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","On all train set, mean of scores: 0.916896, scores: [0.82735327 0.97674419 0.8620155  1.         0.91836735]\n","On test set, Accuracy: 0.961434\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      0.50      0.67         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       0.67      1.00      0.80         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      0.75      0.86         4\n","          31       1.00      1.00      1.00         4\n","          32       0.80      1.00      0.89         4\n","\n","    accuracy                           0.96        54\n","   macro avg       0.97      0.96      0.96        54\n","weighted avg       0.97      0.96      0.96        54\n","\n","FPR: 0.001868\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 0.927431 using {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.904060, scores: [0.86544012 0.86176046 0.88535354 0.96969697 0.93804714]\n","On test set, Accuracy: 0.878609\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       0.50      1.00      0.67         2\n","           5       1.00      1.00      1.00         2\n","          12       0.67      1.00      0.80         2\n","          13       1.00      0.50      0.67         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      0.75      0.86         4\n","          25       1.00      1.00      1.00         4\n","          26       0.80      1.00      0.89         4\n","          30       1.00      0.75      0.86         4\n","          31       0.80      1.00      0.89         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           0.88        42\n","   macro avg       0.92      0.87      0.86        42\n","weighted avg       0.92      0.88      0.88        42\n","\n","FPR: 0.008509\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 1.000000 using {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.3}\n","On all train set, mean of scores: 0.917333, scores: [0.8        0.78666667 1.         1.         1.        ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 0.951667 using {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 7}\n","On all train set, mean of scores: 0.923889, scores: [0.95833333 0.94444444 0.76111111 1.         0.95555556]\n","On test set, Accuracy: 0.928889\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      0.50      0.67         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.93        30\n","   macro avg       0.96      0.93      0.93        30\n","weighted avg       0.96      0.93      0.93        30\n","\n","FPR: 0.004762\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 0.952165 using {'max_depth': 100, 'min_samples_leaf': 4, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.920827, scores: [0.85500611 0.97435897 0.94411028 0.93433584 0.89632414]\n","On test set, Accuracy: 0.979762\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       0.67      1.00      0.80         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      0.75      0.86         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           0.98        48\n","   macro avg       0.98      0.99      0.98        48\n","weighted avg       0.99      0.98      0.98        48\n","\n","FPR: 0.001208\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.879132 using {'max_depth': 200, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","On all train set, mean of scores: 0.849508, scores: [0.84798851 0.84433498 0.82323481 0.83646617 0.89551657]\n","On test set, Accuracy: 0.863448\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      0.50      0.67         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      0.50      0.67         2\n","           9       0.50      1.00      0.67         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      0.75      0.86         4\n","          25       1.00      1.00      1.00         4\n","          26       0.80      1.00      0.89         4\n","          30       1.00      0.50      0.67         4\n","          31       0.80      1.00      0.89         4\n","          32       1.00      0.75      0.86         4\n","          36       0.25      0.50      0.33         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       0.67      1.00      0.80         2\n","          40       0.67      1.00      0.80         2\n","          41       0.50      0.50      0.50         2\n","          42       1.00      0.50      0.67         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      0.50      0.67         2\n","\n","    accuracy                           0.86        72\n","   macro avg       0.91      0.87      0.86        72\n","weighted avg       0.91      0.86      0.86        72\n","\n","FPR: 0.004790\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.915157 using {'max_depth': 40, 'min_samples_leaf': 3, 'min_samples_split': 2}\n","On all train set, mean of scores: 0.897507, scores: [0.82086721 0.975      0.94833333 1.         0.74333333]\n","On test set, Accuracy: 0.959477\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       0.67      1.00      0.80         2\n","           5       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       0.75      1.00      0.86         3\n","          25       1.00      0.75      0.86         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.96        51\n","   macro avg       0.98      0.97      0.97        51\n","weighted avg       0.97      0.96      0.96        51\n","\n","FPR: 0.001718\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.943778, FPR: 0.003199\n"]}],"source":["start_time_DT=time.time()\n","# criterion_DT1 = ['gini', 'entropy']\n","# splitter_DT1 = ['best', 'random']\n","# max_features_DT1 = ['auto', 'sqrt', 'log2', None]\n","max_depth = [5, 10, 15, 20, 30, 40, 50, 100, 150, 200]\n","min_samples_split = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2, 3, 4, 5, 6, 7]\n","min_samples_leaf = list(range(1,5))\n","model_DT1 = DecisionTreeClassifier()\n","# grid_DT1 = dict(criterion = criterion_DT1, splitter = splitter_DT1, max_features = max_features_DT1)\n","grid_DT1 = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)   \n","federated_learning(1, model_DT1, grid_DT1, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_DT = time.time() - start_time_DT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1387,"status":"ok","timestamp":1642377457763,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"53DeZeJ35qDB","outputId":"cb397347-02a1-42bd-86ec-def027052c90"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.885343 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.888479, scores: [0.90739927 0.9047619  0.89553114 0.84649573 0.88820513]\n","On test set, Accuracy: 0.960976\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      0.50      0.67         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       0.67      1.00      0.80         2\n","          21       1.00      0.50      0.67         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       0.67      1.00      0.80         2\n","          28       1.00      0.50      0.67         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.96        82\n","   macro avg       0.97      0.96      0.96        82\n","weighted avg       0.98      0.96      0.96        82\n","\n","FPR: 0.001042\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 0.917624 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.937334, scores: [0.93611111 1.         0.97021277 0.91489362 0.86545086]\n","On test set, Accuracy: 0.965556\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       0.67      1.00      0.80         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      0.50      0.67         2\n","          36       0.50      0.50      0.50         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.97        60\n","   macro avg       0.97      0.97      0.97        60\n","weighted avg       0.97      0.97      0.97        60\n","\n","FPR: 0.001149\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 0.956254 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.970476, scores: [1.         0.92857143 1.         0.92380952 1.        ]\n","On test set, Accuracy: 0.940741\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      0.50      0.67         2\n","           9       0.67      1.00      0.80         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.94        18\n","   macro avg       0.96      0.94      0.94        18\n","weighted avg       0.96      0.94      0.94        18\n","\n","FPR: 0.006944\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 0.919554 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.903740, scores: [0.82735327 0.97674419 0.87596899 0.92026578 0.91836735]\n","On test set, Accuracy: 0.961434\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      0.50      0.67         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       0.67      1.00      0.80         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      0.75      0.86         4\n","          31       1.00      1.00      1.00         4\n","          32       0.80      1.00      0.89         4\n","\n","    accuracy                           0.96        54\n","   macro avg       0.97      0.96      0.96        54\n","weighted avg       0.97      0.96      0.96        54\n","\n","FPR: 0.001868\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 0.875921 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.873093, scores: [0.76782107 0.86176046 0.88535354 0.90319865 0.94733045]\n","On test set, Accuracy: 0.855178\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       0.50      1.00      0.67         2\n","           5       1.00      1.00      1.00         2\n","          12       0.67      1.00      0.80         2\n","          13       1.00      0.50      0.67         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      0.75      0.86         4\n","          25       1.00      1.00      1.00         4\n","          26       0.80      1.00      0.89         4\n","          30       0.75      0.75      0.75         4\n","          31       0.75      0.75      0.75         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           0.86        42\n","   macro avg       0.90      0.85      0.85        42\n","weighted avg       0.89      0.86      0.86        42\n","\n","FPR: 0.010263\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 0.914667 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.914667, scores: [0.78666667 0.78666667 1.         1.         1.        ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 0.935000 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.923889, scores: [0.95833333 0.94444444 0.71666667 1.         1.        ]\n","On test set, Accuracy: 0.928889\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      0.50      0.67         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.93        30\n","   macro avg       0.96      0.93      0.93        30\n","weighted avg       0.96      0.93      0.93        30\n","\n","FPR: 0.004762\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 0.914859 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.916713, scores: [0.85573871 0.97435897 0.92280702 0.93433584 0.89632414]\n","On test set, Accuracy: 0.977778\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           0.98        48\n","   macro avg       0.98      0.97      0.97        48\n","weighted avg       0.99      0.98      0.98        48\n","\n","FPR: 0.001208\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.855905 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.847388, scores: [0.82151067 0.84893268 0.82077176 0.87477026 0.87095517]\n","On test set, Accuracy: 0.881658\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      0.50      0.67         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      0.50      0.67         2\n","           9       0.67      1.00      0.80         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      0.75      0.86         4\n","          25       1.00      1.00      1.00         4\n","          26       0.80      1.00      0.89         4\n","          30       1.00      0.75      0.86         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","          36       0.25      0.50      0.33         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       0.67      1.00      0.80         2\n","          42       1.00      0.50      0.67         2\n","          43       0.67      1.00      0.80         2\n","          44       0.00      0.00      0.00         2\n","\n","    accuracy                           0.89        72\n","   macro avg       0.89      0.88      0.87        72\n","weighted avg       0.90      0.89      0.88        72\n","\n","FPR: 0.003824\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.888499 using {'max_depth': 81, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.880499, scores: [0.85582656 0.975      0.87166667 0.94666667 0.75333333]\n","On test set, Accuracy: 0.917320\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       0.60      1.00      0.75         3\n","          25       1.00      0.50      0.67         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       0.67      1.00      0.80         2\n","          43       1.00      0.50      0.67         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.92        51\n","   macro avg       0.96      0.94      0.93        51\n","weighted avg       0.95      0.92      0.92        51\n","\n","FPR: 0.003437\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.938953, FPR: 0.003450\n","Time taken to run Federated Learning with Decision Tree as initial model =  10.933495163917542 seconds\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["start_time_DT2=time.time()\n","# criterion_DT2 = ['gini']\n","# splitter_DT2 = ['best']\n","# max_features_DT2 = [None]\n","max_depth = [81]\n","min_samples_split = [3]\n","min_samples_leaf = [2]\n","model_DT2 = DecisionTreeClassifier()\n","# grid_DT2 = dict(criterion = criterion_DT2, splitter = splitter_DT2, max_features = max_features_DT2)\n","grid_DT2 = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n","federated_learning(2, model_DT2, grid_DT2, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_DT2 = time.time() - start_time_DT2 + elapsed_time_DT\n","print(\"Time taken to run Federated Learning with Decision Tree as initial model = \", elapsed_time_DT2/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"PhzF14ghD40e"},"source":["### FL Group: attack types"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1378,"status":"ok","timestamp":1642377547803,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"P9LcDFlqD87o","outputId":"07f40cde-2966-4f1d-e373-691f4d9275de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n","Best: 0.894730 using {'max_depth': 65, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.890891, scores: [0.92102564 0.92205128 0.89206349 0.84649573 0.87282051]\n","On test set, Accuracy: 0.973984\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      0.50      0.67         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          18       1.00      1.00      1.00         2\n","          19       1.00      1.00      1.00         2\n","          20       0.67      1.00      0.80         2\n","          21       1.00      0.50      0.67         2\n","          22       1.00      1.00      1.00         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          27       1.00      1.00      1.00         2\n","          28       1.00      1.00      1.00         2\n","          29       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         4\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           0.98        82\n","   macro avg       0.98      0.97      0.97        82\n","weighted avg       0.98      0.98      0.97        82\n","\n","FPR: 0.000694\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n","Best: 0.923055 using {'max_depth': 106, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","On all train set, mean of scores: 0.918327, scores: [0.93611111 1.         0.94751773 0.86382979 0.84417427]\n","On test set, Accuracy: 0.982222\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         2\n","          25       1.00      1.00      1.00         2\n","          26       1.00      1.00      1.00         2\n","          30       0.67      1.00      0.80         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      0.50      0.67         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.98        60\n","   macro avg       0.99      0.98      0.98        60\n","weighted avg       0.99      0.98      0.98        60\n","\n","FPR: 0.000575\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n","Best: 0.956254 using {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.956254, scores: [0.92888889 0.92857143 1.         0.92380952 1.        ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      1.00      1.00         2\n","          35       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00        18\n","   macro avg       1.00      1.00      1.00        18\n","weighted avg       1.00      1.00      1.00        18\n","\n","FPR: 0.000000\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n","Best: 0.924102 using {'max_depth': 106, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","On all train set, mean of scores: 0.928288, scores: [0.85127353 0.97674419 0.87918051 1.         0.93424036]\n","On test set, Accuracy: 0.961434\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      0.50      0.67         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       0.67      1.00      0.80         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      0.75      0.86         4\n","          31       1.00      1.00      1.00         4\n","          32       0.80      1.00      0.89         4\n","\n","    accuracy                           0.96        54\n","   macro avg       0.97      0.96      0.96        54\n","weighted avg       0.97      0.96      0.96        54\n","\n","FPR: 0.001868\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n","Best: 0.869591 using {'max_depth': 65, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.881578, scores: [0.76782107 0.9041847  0.88535354 0.90319865 0.94733045]\n","On test set, Accuracy: 0.855178\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      1.00      1.00         2\n","           4       0.50      1.00      0.67         2\n","           5       1.00      1.00      1.00         2\n","          12       0.67      1.00      0.80         2\n","          13       1.00      0.50      0.67         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      0.75      0.86         4\n","          25       1.00      1.00      1.00         4\n","          26       0.80      1.00      0.89         4\n","          30       0.75      0.75      0.75         4\n","          31       0.75      0.75      0.75         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           0.86        42\n","   macro avg       0.90      0.85      0.85        42\n","weighted avg       0.89      0.86      0.86        42\n","\n","FPR: 0.010263\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","Best: 0.914667 using {'max_depth': 106, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","On all train set, mean of scores: 0.914667, scores: [0.78666667 0.78666667 1.         1.         1.        ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","Best: 0.916111 using {'max_depth': 106, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","On all train set, mean of scores: 0.926667, scores: [0.95555556 1.         0.67777778 1.         1.        ]\n","On test set, Accuracy: 0.928889\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      0.50      0.67         2\n","          15       1.00      1.00      1.00         2\n","          16       1.00      1.00      1.00         2\n","          17       1.00      1.00      1.00         2\n","          33       1.00      1.00      1.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.93        30\n","   macro avg       0.96      0.93      0.93        30\n","weighted avg       0.96      0.93      0.93        30\n","\n","FPR: 0.004762\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","Best: 0.916563 using {'max_depth': 106, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","On all train set, mean of scores: 0.904597, scores: [0.79590965 0.97435897 0.92205514 0.93433584 0.89632414]\n","On test set, Accuracy: 0.977778\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       1.00      1.00      1.00         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      1.00      1.00         4\n","          31       1.00      1.00      1.00         4\n","          32       1.00      1.00      1.00         4\n","\n","    accuracy                           0.98        48\n","   macro avg       0.98      0.97      0.97        48\n","weighted avg       0.99      0.98      0.98        48\n","\n","FPR: 0.001208\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","Best: 0.858313 using {'max_depth': 106, 'min_samples_leaf': 2, 'min_samples_split': 4}\n","On all train set, mean of scores: 0.845096, scores: [0.82151067 0.8546798  0.81818555 0.86015038 0.87095517]\n","On test set, Accuracy: 0.889065\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","           6       0.50      0.50      0.50         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      0.50      0.67         2\n","           9       0.67      1.00      0.80         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       1.00      1.00      1.00         4\n","          25       1.00      1.00      1.00         4\n","          26       1.00      1.00      1.00         4\n","          30       1.00      0.75      0.86         4\n","          31       0.80      1.00      0.89         4\n","          32       1.00      0.75      0.86         4\n","          36       0.33      0.50      0.40         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       0.67      1.00      0.80         2\n","          41       0.50      0.50      0.50         2\n","          42       1.00      0.50      0.67         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      0.50      0.67         2\n","\n","    accuracy                           0.89        72\n","   macro avg       0.90      0.88      0.88        72\n","weighted avg       0.91      0.89      0.89        72\n","\n","FPR: 0.003824\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n","Best: 0.880499 using {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 3}\n","On all train set, mean of scores: 0.881507, scores: [0.82086721 0.94833333 0.92166667 0.94666667 0.77      ]\n","On test set, Accuracy: 0.917320\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       1.00      1.00      1.00         2\n","          24       0.60      1.00      0.75         3\n","          25       1.00      0.50      0.67         4\n","          26       1.00      1.00      1.00         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       1.00      1.00      1.00         2\n","          36       1.00      1.00      1.00         2\n","          37       1.00      1.00      1.00         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      1.00      1.00         2\n","          40       1.00      1.00      1.00         2\n","          41       1.00      1.00      1.00         2\n","          42       0.67      1.00      0.80         2\n","          43       1.00      0.50      0.67         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.92        51\n","   macro avg       0.96      0.94      0.93        51\n","weighted avg       0.95      0.92      0.92        51\n","\n","FPR: 0.003437\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 0.914581\n","Appliances group: Device 9, Accuracy: 0.917320\n","Controller group: Device 2, Accuracy: 1.000000\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.956565\n","Federated Group: Round: 2, Accuracy: 0.948587, FPR: 0.002663\n","Time taken to run Federated Learning with Decision Tree as initial model =  10.931342673301696 seconds\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","model_DT2 = model_camera = model_appliances = model_energy = model_controller = DecisionTreeClassifier()\n","cv_DT2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","\n","# 0, 4\n","# criterion_camera = ['entropy']\n","# splitter_camera = ['best']\n","# max_features_camera = [None]\n","max_depth = [65]\n","min_samples_split = [3]\n","min_samples_leaf = [2]\n","grid_camera = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n","# grid_camera = dict(criterion = criterion_camera, splitter = splitter_camera, max_features = max_features_camera)\n","\n","# 9\n","# criterion_appliances = ['entropy']\n","# splitter_appliances = ['best']\n","# max_features_appliances = [None]\n","# grid_appliances = dict(criterion = criterion_appliances, splitter = splitter_appliances, max_features = max_features_appliances)\n","max_depth = [40]\n","min_samples_split = [3]\n","min_samples_leaf = [2]\n","grid_appliances = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n","\n","# 1, 3, 5, 6, 7, 8\n","# criterion_energy = ['gini']\n","# splitter_energy = ['best']\n","# max_features_energy = [None]\n","# grid_energy = dict(criterion = criterion_energy, splitter = splitter_energy, max_features = max_features_energy)\n","max_depth = [106]\n","min_samples_split = [4]\n","min_samples_leaf = [2]\n","grid_energy = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n","\n","# 2\n","# criterion_controller = ['entropy']\n","# splitter_controller = ['best']\n","# max_features_controller = [None]\n","# grid_controller = dict(criterion = criterion_controller, splitter = splitter_controller, max_features = max_features_controller)\n","max_depth = [10]\n","min_samples_split = [3]\n","min_samples_leaf = [1]\n","grid_controller = dict(max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n","\n","\n","start_time_DT3 = time.time()\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_DT3 = time.time() - start_time_DT3 + elapsed_time_DT\n","print(\"Time taken to run Federated Learning with Decision Tree as initial model = \", elapsed_time_DT3/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"6vYlY-vX32ZF"},"source":["## Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"C3JuA-hg36LV"},"source":["### Logistic Regression: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"huy9cLgB3_YE"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","start_time_LRO=time.time()\n","penalty = ['l1']\n","solver = ['liblinear']\n","C = [0.01, 0.1, 1, 10, 100]\n","# multi_class = ['auto', 'ovr', 'multinomial']\n","lg = LogisticRegression()\n","grid = dict(penalty = penalty, solver = solver, C = C) \n","model(df, y, lg, grid, cv)\n","elapsed_time_LRO = time.time() - start_time_LRO\n","print(\"Time taken to run Logistic Regression = \", elapsed_time_LRO, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"yxuSy5XE9ZC8"},"source":["### FL: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20325878,"status":"ok","timestamp":1642503241795,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"oWmNy5zv9bcX","outputId":"56c7aaf6-27c6-4e80-bd18-2b1a83f3b2f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.996143 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996143, scores: [0.99650021 0.99592662 0.99579047 0.996698   0.99580177]\n","On test set, Accuracy: 0.996362\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.84      0.53      0.65        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.92      0.77      0.82     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.234854\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n","Best: 0.995844 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.995844, scores: [0.99604479 0.9947504  0.99598636 0.99546347 0.99697604]\n","On test set, Accuracy: 0.997441\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.84      0.78      0.81        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.92      0.89      0.90      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.110688\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998931 using {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998931, scores: [0.99839884 0.99956387 0.99883292 0.99883292 0.9990256 ]\n","On test set, Accuracy: 0.998924\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.80      0.67      0.73        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.90      0.83      0.86      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.166839\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.997947 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.997947, scores: [0.99750708 0.99797112 0.9976618  0.99810717 0.99848574]\n","On test set, Accuracy: 0.996753\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.73      0.41      0.52        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.87      0.70      0.76     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.296582\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.997942 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.997958, scores: [0.99782448 0.99781159 0.99793969 0.99818624 0.99802639]\n","On test set, Accuracy: 0.997918\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.90      0.44      0.59        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.95      0.72      0.79     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.280559\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.999851 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.999851, scores: [1.         0.99986359 1.         0.99971416 0.99967845]\n","On test set, Accuracy: 0.999880\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      0.92      0.95      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.083333\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998057 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998057, scores: [0.99837566 0.99733317 0.99820727 0.99838328 0.99798363]\n","On test set, Accuracy: 0.997788\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.88      0.50      0.64        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.75      0.82      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.250115\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998905 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998905, scores: [0.99905965 0.99910009 0.99883779 0.99862073 0.99890448]\n","On test set, Accuracy: 0.998863\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.83      0.83      0.83        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.92      0.92      0.92     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.083619\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.996711 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996711, scores: [0.99736784 0.99736266 0.99677982 0.99590612 0.99613868]\n","On test set, Accuracy: 0.995495\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.86      0.33      0.48        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.93      0.67      0.74     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.333476\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.996908 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996908, scores: [0.99785694 0.99671738 0.99671738 0.99678552 0.99646407]\n","On test set, Accuracy: 0.997175\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.86      0.64      0.74        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.82      0.87      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.180287\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.997660, FPR: 0.202035\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}],"source":["start_time_LR=time.time()\n","from sklearn.linear_model import LogisticRegression\n","penalty_LR1 = ['l1']\n","solver_LR1 = ['liblinear']\n","C = [0.01, 0.1, 1, 10, 100]\n","# multi_class_LR1 = ['auto', 'ovr']\n","model_LR1 = LogisticRegression()\n","grid_LR1 = dict(penalty = penalty_LR1, solver = solver_LR1, C = C)  \n","federated_learning(1, model_LR1, grid_LR1, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_LR = time.time() - start_time_LR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8796651,"status":"ok","timestamp":1642512040665,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"aHoAu1AckPD2","outputId":"5b70f084-4c9a-4c44-d690-a34df41a13ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.996020 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996072, scores: [0.99650021 0.99592662 0.99579047 0.9964669  0.99567507]\n","On test set, Accuracy: 0.996075\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.83      0.49      0.62        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.92      0.75      0.81     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.253372\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.995777 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.995813, scores: [0.99604479 0.9947504  0.99570659 0.99558952 0.99697604]\n","On test set, Accuracy: 0.997652\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.87      0.78      0.82        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.89      0.91      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.110572\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998877 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998855, scores: [0.99828498 0.99942833 0.99883292 0.9987008  0.9990256 ]\n","On test set, Accuracy: 0.998924\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.80      0.67      0.73        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.90      0.83      0.86      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.166839\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998006 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998006, scores: [0.99750708 0.99797112 0.9976618  0.99840216 0.99848574]\n","On test set, Accuracy: 0.996753\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.73      0.41      0.52        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.87      0.70      0.76     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.296582\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n","Best: 0.997897 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.997897, scores: [0.99774589 0.99765704 0.99790625 0.99830506 0.9978716 ]\n","On test set, Accuracy: 0.997918\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.90      0.44      0.59        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.95      0.72      0.79     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.280559\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.999851 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.999851, scores: [1.         0.99986359 1.         0.99971416 0.99967845]\n","On test set, Accuracy: 0.999880\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      0.92      0.95      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.083333\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998057 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998057, scores: [0.99837566 0.99733317 0.99820727 0.99838328 0.99798363]\n","On test set, Accuracy: 0.997788\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.88      0.50      0.64        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.75      0.82      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.250115\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","Best: 0.998885 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998885, scores: [0.99905965 0.99890538 0.99892011 0.99862073 0.99891964]\n","On test set, Accuracy: 0.998940\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.84      0.85      0.85        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.92      0.93      0.92     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.073202\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n","Best: 0.996688 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996687, scores: [0.9973967  0.9974153  0.9963773  0.99598374 0.9962635 ]\n","On test set, Accuracy: 0.995435\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.83      0.33      0.48        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.91      0.67      0.74     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.333512\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.996610 using {'C': 1.34, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996636, scores: [0.99751252 0.99658765 0.99634669 0.99665355 0.99607819]\n","On test set, Accuracy: 0.997175\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.86      0.64      0.74        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.82      0.87      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.180287\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.997654, FPR: 0.202837\n","Time taken to run Federated Learning with Logistic Regression as initial model =  2912.2638642549514 seconds\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}],"source":["start_time_LR2=time.time()\n","penalty_LR2 = ['l1']\n","solver_LR2 = ['liblinear']\n","C = [1.34]\n","# multi_class_LR2 = ['auto']\n","model_LR2 = LogisticRegression()\n","grid_LR2 = dict(penalty = penalty_LR2, solver = solver_LR2, C = C)  \n","federated_learning(2, model_LR2, grid_LR2, cv,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_LR2 = time.time() - start_time_LR2 + elapsed_time_LR\n","print(\"Time taken to run Federated Learning with Logistic Regression as initial model = \", elapsed_time_LR2/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"fo1i8C26EZP7"},"source":["### FL Group: attack or not"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9663568,"status":"ok","timestamp":1642521705221,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"LguXgBFwEyAL","outputId":"dac6f627-1f19-4e6d-b756-3c0269a5adef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train     index     Attack\n","0      0  99.420856\n","1      1   0.579144\n","y_test     index    Attack\n","0      0  99.42443\n","1      1   0.57557\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.996118 using {'C': 0.055, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996118, scores: [0.99650021 0.99592662 0.99579047 0.996698   0.99567507]\n","On test set, Accuracy: 0.996267\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     13992\n","           1       0.84      0.52      0.64        81\n","\n","    accuracy                           1.00     14073\n","   macro avg       0.92      0.76      0.82     14073\n","weighted avg       1.00      1.00      1.00     14073\n","\n","FPR: 0.241027\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train     index    Attack\n","0      0  99.31965\n","1      1   0.68035\n","y_test     index     Attack\n","0      0  99.325406\n","1      1   0.674594\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.995921 using {'C': 0.55, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.995920, scores: [0.99604479 0.99500155 0.9961118  0.99546347 0.99697604]\n","On test set, Accuracy: 0.997652\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8687\n","           1       0.87      0.78      0.82        59\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.89      0.91      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.110572\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index     Attack\n","0      0  99.797038\n","1      1   0.202962\n","y_test     index     Attack\n","0      0  99.794192\n","1      1   0.205808\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998894 using {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998890, scores: [0.99839884 0.99956387 0.99883292 0.99862811 0.9990256 ]\n","On test set, Accuracy: 0.999028\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8728\n","           1       0.86      0.67      0.75        18\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.83      0.87      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.166781\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train     index     Attack\n","0      0  99.619866\n","1      1   0.380134\n","y_test     index     Attack\n","0      0  99.616341\n","1      1   0.383659\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.997947 using {'C': 0.55, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.997947, scores: [0.99750708 0.99797112 0.9976618  0.99810717 0.99848574]\n","On test set, Accuracy: 0.996650\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14021\n","           1       0.72      0.39      0.51        54\n","\n","    accuracy                           1.00     14075\n","   macro avg       0.86      0.69      0.75     14075\n","weighted avg       1.00      1.00      1.00     14075\n","\n","FPR: 0.305841\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train     index     Attack\n","0      0  99.705078\n","1      1   0.294922\n","y_test     index     Attack\n","0      0  99.708641\n","1      1   0.291359\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.997904 using {'C': 0.055, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.997904, scores: [0.99782448 0.99765704 0.99770684 0.99830506 0.99802639]\n","On test set, Accuracy: 0.997918\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14031\n","           1       0.90      0.44      0.59        41\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.95      0.72      0.79     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.280559\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n","y_test     index     Attack\n","0      0  99.931405\n","1      1   0.068595\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.999851 using {'C': 0.55, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.999851, scores: [1.         0.99986359 1.         0.99971416 0.99967845]\n","On test set, Accuracy: 0.999880\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8741\n","           1       1.00      0.83      0.91         6\n","\n","    accuracy                           1.00      8747\n","   macro avg       1.00      0.92      0.95      8747\n","weighted avg       1.00      1.00      1.00      8747\n","\n","FPR: 0.083333\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n","y_test     index     Attack\n","0      0  99.656986\n","1      1   0.343014\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998057 using {'C': 0.55, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998057, scores: [0.99837566 0.99733317 0.99820727 0.99838328 0.99798363]\n","On test set, Accuracy: 0.997788\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8716\n","           1       0.88      0.50      0.64        30\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.94      0.75      0.82      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.250115\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n","y_test     index     Attack\n","0      0  99.658897\n","1      1   0.341103\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.998901 using {'C': 0.55, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.998901, scores: [0.99905965 0.99900344 0.99892011 0.99851794 0.99900282]\n","On test set, Accuracy: 0.998940\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14024\n","           1       0.84      0.85      0.85        48\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.92      0.93      0.92     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.073202\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train     index     Attack\n","0      0  99.488327\n","1      1   0.511673\n","y_test     index     Attack\n","0      0  99.488346\n","1      1   0.511654\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.996737 using {'C': 0.55, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996737, scores: [0.99747936 0.9974153  0.99662001 0.99590612 0.9962635 ]\n","On test set, Accuracy: 0.995607\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14000\n","           1       0.86      0.35      0.50        72\n","\n","    accuracy                           1.00     14072\n","   macro avg       0.93      0.67      0.75     14072\n","weighted avg       1.00      1.00      1.00     14072\n","\n","FPR: 0.326532\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train     index     Attack\n","0      0  99.422577\n","1      1   0.577423\n","y_test     index    Attack\n","0      0  99.42831\n","1      1   0.57169\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.996908 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.996935, scores: [0.99785694 0.99671738 0.99684883 0.99678552 0.99646407]\n","On test set, Accuracy: 0.997175\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8696\n","           1       0.86      0.64      0.74        50\n","\n","    accuracy                           1.00      8746\n","   macro avg       0.93      0.82      0.87      8746\n","weighted avg       1.00      1.00      1.00      8746\n","\n","FPR: 0.180287\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 0.997093\n","Appliances group: Device 9, Accuracy: 0.997175\n","Controller group: Device 2, Accuracy: 0.999028\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.997753\n","Federated Group: Round: 2, Accuracy: 0.997691, FPR: 0.201825\n","Time taken to run Federated Learning with Logistic Regression as initial model =  2998.8491686344146 seconds\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}],"source":["print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","model_LR2 = model_camera = model_appliances = model_energy = model_controller = LogisticRegression()\n","cv_LR2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","\n","# 0, 4\n","penalty_camera = ['l1']\n","solver_camera = ['liblinear']\n","C = [0.055]\n","# multi_class_camera = ['auto']\n","# grid_camera = dict(penalty = penalty_camera, solver = solver_camera, multi_class = multi_class_camera)\n","grid_camera = dict(penalty = penalty_camera, solver = solver_camera, C = C)\n","# 9\n","penalty_appliances = ['l1']\n","solver_appliances = ['liblinear']\n","C = [0.01]\n","# multi_class_appliances = ['ovr']\n","# grid_appliances = dict(penalty = penalty_appliances, solver = solver_appliances, multi_class = multi_class_appliances)\n","grid_appliances = dict(penalty = penalty_appliances, solver = solver_appliances, C = C)\n","# 1, 3, 5, 6, 7, 8\n","penalty_energy = ['l1']\n","solver_energy = ['liblinear']\n","C = [0.55]\n","# multi_class_energy = ['auto']\n","# grid_energy = dict(penalty = penalty_energy, solver = solver_energy, multi_class = multi_class_energy)\n","grid_energy = dict(penalty = penalty_energy, solver = solver_energy, C = C)\n","# 2\n","penalty_controller = ['l1']\n","solver_controller = ['liblinear']\n","C = [10]\n","# multi_class_controller = ['auto']\n","# grid_controller = dict(penalty = penalty_controller, solver = solver_controller, multi_class = multi_class_controller)\n","grid_controller = dict(penalty = penalty_controller, solver = solver_controller, C = C)\n","start_time_LR3 = time.time()\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0, y_0, df_1, y_1, df_2, y_2, df_3, y_3, df_4, y_4,\n","                   df_5, y_5, df_6, y_6, df_7, y_7, df_8, y_8, df_9, y_9)\n","elapsed_time_LR3 = time.time() - start_time_LR3 + elapsed_time_LR\n","print(\"Time taken to run Federated Learning with Logistic Regression as initial model = \", elapsed_time_LR3/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"HpJ2SbIO3_uF"},"source":["### Logistic Regression: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5442951,"status":"ok","timestamp":1642419109406,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"yP-TIFEc9Yoo","outputId":"6c220126-ea75-448a-c322-b822cdc21a80"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.397257 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n","Time taken to run Random Forest =  339.0084857940674 seconds\n","LogisticRegression(C=1, penalty='l1', solver='liblinear')\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.398432, scores: [0.37644176 0.41087898 0.39489176 0.40801693 0.40192866]\n","On test set, Accuracy: 0.389001\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.74      0.70        19\n","           1       0.43      0.65      0.52        20\n","           2       0.64      0.45      0.53        20\n","           3       0.38      0.57      0.46        14\n","           4       0.38      0.43      0.40        14\n","           5       0.50      0.50      0.50        14\n","           6       0.40      0.50      0.44        12\n","           7       0.25      0.25      0.25        12\n","           8       0.48      0.83      0.61        12\n","           9       1.00      0.75      0.86         8\n","          10       0.38      0.38      0.38         8\n","          11       0.55      0.75      0.63         8\n","          12       0.45      0.36      0.40        14\n","          13       0.33      0.21      0.26        14\n","          14       0.36      0.36      0.36        14\n","          15       0.14      0.12      0.13         8\n","          16       0.50      0.50      0.50         8\n","          17       0.67      0.50      0.57         8\n","          18       0.00      0.00      0.00         1\n","          19       0.67      1.00      0.80         2\n","          20       0.50      0.50      0.50         2\n","          21       0.33      0.50      0.40         2\n","          22       0.50      1.00      0.67         2\n","          23       1.00      0.50      0.67         2\n","          24       0.29      0.29      0.29        24\n","          25       0.33      0.27      0.30        26\n","          26       0.08      0.04      0.05        24\n","          27       1.00      0.50      0.67         2\n","          28       0.67      1.00      0.80         2\n","          29       1.00      1.00      1.00         2\n","          30       0.18      0.25      0.21        24\n","          31       0.33      0.14      0.19        22\n","          32       0.05      0.04      0.04        24\n","          33       0.67      0.67      0.67         6\n","          34       0.44      0.67      0.53         6\n","          35       0.50      0.17      0.25         6\n","          36       1.00      0.33      0.50         6\n","          37       0.45      0.83      0.59         6\n","          38       1.00      0.50      0.67         6\n","          39       0.00      0.00      0.00         6\n","          40       0.00      0.00      0.00         6\n","          41       0.22      0.33      0.27         6\n","          42       0.43      0.50      0.46         6\n","          43       0.67      1.00      0.80         6\n","          44       0.86      1.00      0.92         6\n","\n","    accuracy                           0.40       460\n","   macro avg       0.48      0.49      0.46       460\n","weighted avg       0.40      0.40      0.39       460\n","\n","FPR: 0.013722\n","0.356792 (0.013896) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n","0.006050 (0.000223) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n","0.372393 (0.013127) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n","0.006050 (0.000223) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n","0.397257 (0.013658) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n","0.006050 (0.000223) with: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n","0.391940 (0.018872) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n","0.006050 (0.000223) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n","0.386964 (0.008383) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n","0.006050 (0.000223) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n","Time taken to run Logistic Regression =  5442.615127801895 seconds\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","start_time_LRO=time.time()\n","penalty = ['l1', 'l2']\n","solver = ['liblinear']\n","# multi_class = ['auto', 'ovr', 'multinomial']\n","C = [ 0.01, 0.1, 1, 10, 100]\n","# max_iter = list(range(100,500,10))\n","lg = LogisticRegression()\n","grid = dict(penalty = penalty, solver = solver, C = C)  \n","model(df_new, y_attacktype, lg, grid, cv)\n","elapsed_time_LRO = time.time() - start_time_LRO\n","print(\"Time taken to run Logistic Regression = \", elapsed_time_LRO, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"3qxK5d3H9bte"},"source":["### FL: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1284461,"status":"ok","timestamp":1642396883146,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"NUiqa3QT9e0E","outputId":"9b286293-3ae7-4f23-d8be-f9cf28a46473"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.475672 using {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.459754, scores: [0.44637363 0.51102564 0.5062704  0.35509824 0.48      ]\n","On test set, Accuracy: 0.519512\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.67      1.00      0.80         2\n","           2       1.00      1.00      1.00         2\n","           3       1.00      0.50      0.67         2\n","           4       0.00      0.00      0.00         2\n","           5       0.50      0.50      0.50         2\n","           6       0.50      1.00      0.67         2\n","           7       1.00      0.50      0.67         2\n","           8       0.67      1.00      0.80         2\n","           9       0.00      0.00      0.00         2\n","          10       0.33      0.50      0.40         2\n","          11       0.67      1.00      0.80         2\n","          12       0.50      0.50      0.50         2\n","          13       0.50      1.00      0.67         2\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         2\n","          16       0.50      0.50      0.50         2\n","          17       0.67      1.00      0.80         2\n","          18       0.00      0.00      0.00         2\n","          19       0.33      0.50      0.40         2\n","          20       0.33      0.50      0.40         2\n","          21       0.00      0.00      0.00         2\n","          22       0.67      1.00      0.80         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      0.50      0.67         4\n","          25       0.00      0.00      0.00         4\n","          26       0.40      0.50      0.44         4\n","          27       0.67      1.00      0.80         2\n","          28       0.50      0.50      0.50         2\n","          29       1.00      1.00      1.00         2\n","          30       0.80      1.00      0.89         4\n","          31       0.00      0.00      0.00         2\n","          32       0.60      0.75      0.67         4\n","          33       0.00      0.00      0.00         2\n","          34       0.50      0.50      0.50         2\n","          35       0.67      1.00      0.80         2\n","\n","    accuracy                           0.57        82\n","   macro avg       0.50      0.58      0.52        82\n","weighted avg       0.51      0.57      0.52        82\n","\n","FPR: 0.012224\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.377739 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.389189, scores: [0.5139881  0.36944444 0.34832827 0.45602837 0.25815603]\n","On test set, Accuracy: 0.474603\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.50      0.50         2\n","           1       0.67      1.00      0.80         2\n","           2       0.00      0.00      0.00         2\n","           3       1.00      1.00      1.00         2\n","           4       0.50      0.50      0.50         2\n","           5       1.00      0.50      0.67         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      1.00      1.00         2\n","           8       0.50      0.50      0.50         2\n","          12       1.00      1.00      1.00         2\n","          13       0.00      0.00      0.00         2\n","          14       0.50      1.00      0.67         2\n","          15       0.00      0.00      0.00         2\n","          16       0.00      0.00      0.00         2\n","          17       0.33      0.50      0.40         2\n","          24       0.50      0.50      0.50         2\n","          25       0.50      0.50      0.50         2\n","          26       0.50      1.00      0.67         2\n","          30       0.67      1.00      0.80         2\n","          31       0.00      0.00      0.00         2\n","          32       0.00      0.00      0.00         2\n","          36       0.00      0.00      0.00         2\n","          37       0.50      0.50      0.50         2\n","          38       0.33      0.50      0.40         2\n","          39       0.40      1.00      0.57         2\n","          40       0.00      0.00      0.00         2\n","          41       0.00      0.00      0.00         2\n","          42       1.00      0.50      0.67         2\n","          43       0.67      1.00      0.80         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.53        60\n","   macro avg       0.46      0.53      0.47        60\n","weighted avg       0.46      0.53      0.47        60\n","\n","FPR: 0.016092\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.531175 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.545460, scores: [0.35111111 0.51190476 0.67619048 0.73809524 0.45      ]\n","On test set, Accuracy: 0.578307\n","              precision    recall  f1-score   support\n","\n","           0       0.40      1.00      0.57         2\n","           1       1.00      0.50      0.67         2\n","           2       0.00      0.00      0.00         2\n","           9       1.00      0.50      0.67         2\n","          10       1.00      0.50      0.67         2\n","          11       0.50      1.00      0.67         2\n","          33       0.67      1.00      0.80         2\n","          34       0.50      0.50      0.50         2\n","          35       1.00      0.50      0.67         2\n","\n","    accuracy                           0.61        18\n","   macro avg       0.67      0.61      0.58        18\n","weighted avg       0.67      0.61      0.58        18\n","\n","FPR: 0.048611\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.360421 using {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.358844, scores: [0.47728086 0.42846069 0.26085271 0.33284003 0.29478458]\n","On test set, Accuracy: 0.299118\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.50      0.67         2\n","           1       0.00      0.00      0.00         2\n","           2       0.33      0.50      0.40         2\n","           3       0.50      0.50      0.50         2\n","           4       0.33      1.00      0.50         2\n","           5       0.50      0.50      0.50         2\n","           6       1.00      0.50      0.67         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      1.00      1.00         2\n","          12       0.50      0.50      0.50         2\n","          13       0.00      0.00      0.00         2\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         2\n","          16       0.40      1.00      0.57         2\n","          17       0.00      0.00      0.00         2\n","          24       0.00      0.00      0.00         4\n","          25       0.20      0.50      0.29         4\n","          26       0.00      0.00      0.00         4\n","          30       0.17      0.25      0.20         4\n","          31       0.50      0.50      0.50         4\n","          32       0.00      0.00      0.00         4\n","\n","    accuracy                           0.35        54\n","   macro avg       0.34      0.39      0.34        54\n","weighted avg       0.30      0.35      0.30        54\n","\n","FPR: 0.032711\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.451356 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.440534, scores: [0.37828283 0.47070707 0.53030303 0.41125541 0.41212121]\n","On test set, Accuracy: 0.442713\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      0.50      0.67         2\n","           3       0.67      1.00      0.80         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       0.67      1.00      0.80         2\n","          14       1.00      1.00      1.00         2\n","          24       0.00      0.00      0.00         4\n","          25       0.14      0.25      0.18         4\n","          26       0.00      0.00      0.00         4\n","          30       0.50      0.50      0.50         4\n","          31       0.00      0.00      0.00         4\n","          32       0.00      0.00      0.00         4\n","\n","    accuracy                           0.45        42\n","   macro avg       0.60      0.58      0.57        42\n","weighted avg       0.46      0.45      0.44        42\n","\n","FPR: 0.040175\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.784667 using {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.784667, scores: [0.6        0.78666667 0.78666667 1.         0.75      ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.421944 using {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.420000, scores: [0.49444444 0.36111111 0.38611111 0.30555556 0.55277778]\n","On test set, Accuracy: 0.373333\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67         2\n","           1       1.00      0.50      0.67         2\n","           2       0.67      1.00      0.80         2\n","           6       0.33      0.50      0.40         2\n","           7       0.00      0.00      0.00         2\n","           8       0.00      0.00      0.00         2\n","           9       0.33      0.50      0.40         2\n","          10       0.00      0.00      0.00         2\n","          11       1.00      0.50      0.67         2\n","          15       0.00      0.00      0.00         2\n","          16       0.00      0.00      0.00         2\n","          17       0.50      0.50      0.50         2\n","          33       1.00      1.00      1.00         2\n","          34       0.00      0.00      0.00         2\n","          35       0.50      0.50      0.50         2\n","\n","    accuracy                           0.40        30\n","   macro avg       0.39      0.40      0.37        30\n","weighted avg       0.39      0.40      0.37        30\n","\n","FPR: 0.042857\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.282076 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.282076, scores: [0.17368742 0.34377289 0.28922306 0.34692982 0.25676692]\n","On test set, Accuracy: 0.396195\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.50      0.50         2\n","           1       0.50      0.50      0.50         2\n","           2       0.33      0.50      0.40         2\n","           3       0.33      0.50      0.40         2\n","           4       0.00      0.00      0.00         2\n","           5       1.00      0.50      0.67         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      0.50      0.67         2\n","          12       0.67      1.00      0.80         2\n","          13       0.00      0.00      0.00         2\n","          14       0.33      0.50      0.40         2\n","          24       0.00      0.00      0.00         4\n","          25       0.33      0.25      0.29         4\n","          26       1.00      0.50      0.67         4\n","          30       0.15      0.50      0.24         4\n","          31       0.00      0.00      0.00         4\n","          32       0.50      0.50      0.50         4\n","\n","    accuracy                           0.42        48\n","   macro avg       0.46      0.46      0.43        48\n","weighted avg       0.43      0.42      0.40        48\n","\n","FPR: 0.034695\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.486789 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.492596, scores: [0.48891626 0.54170772 0.45402299 0.45956558 0.51876915]\n","On test set, Accuracy: 0.532540\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67         2\n","           1       1.00      0.50      0.67         2\n","           2       0.50      0.50      0.50         2\n","           3       0.00      0.00      0.00         2\n","           4       0.00      0.00      0.00         2\n","           5       0.50      0.50      0.50         2\n","           6       1.00      0.50      0.67         2\n","           7       0.67      1.00      0.80         2\n","           8       1.00      0.50      0.67         2\n","           9       1.00      1.00      1.00         2\n","          10       1.00      1.00      1.00         2\n","          11       1.00      1.00      1.00         2\n","          12       0.50      0.50      0.50         2\n","          13       0.33      0.50      0.40         2\n","          14       0.00      0.00      0.00         2\n","          24       0.60      0.75      0.67         4\n","          25       0.25      0.25      0.25         4\n","          26       0.33      0.50      0.40         4\n","          30       0.00      0.00      0.00         4\n","          31       0.33      0.50      0.40         4\n","          32       0.33      0.25      0.29         4\n","          36       0.50      0.50      0.50         2\n","          37       1.00      0.50      0.67         2\n","          38       1.00      1.00      1.00         2\n","          39       1.00      0.50      0.67         2\n","          40       0.67      1.00      0.80         2\n","          41       0.50      0.50      0.50         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      0.50      0.67         2\n","\n","    accuracy                           0.54        72\n","   macro avg       0.62      0.57      0.57        72\n","weighted avg       0.57      0.54      0.53        72\n","\n","FPR: 0.015952\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.496668 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.501546, scores: [0.4097561  0.48833333 0.47035714 0.64119048 0.49809524]\n","On test set, Accuracy: 0.678665\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.50      0.67         2\n","           1       0.33      0.50      0.40         2\n","           2       0.00      0.00      0.00         2\n","           3       1.00      0.50      0.67         2\n","           4       0.50      0.50      0.50         2\n","           5       0.50      0.50      0.50         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       0.67      1.00      0.80         2\n","          24       0.60      1.00      0.75         3\n","          25       1.00      0.75      0.86         4\n","          26       1.00      0.50      0.67         2\n","          30       0.25      0.50      0.33         2\n","          31       0.67      1.00      0.80         2\n","          32       1.00      0.50      0.67         2\n","          36       0.67      1.00      0.80         2\n","          37       1.00      0.50      0.67         2\n","          38       1.00      1.00      1.00         2\n","          39       0.00      0.00      0.00         2\n","          40       0.00      0.00      0.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.69        51\n","   macro avg       0.72      0.68      0.67        51\n","weighted avg       0.72      0.69      0.68        51\n","\n","FPR: 0.013641\n","================================================================================\n","Federated Learning: Round: 1, Accuracy: 0.529499, FPR: 0.025696\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}],"source":["start_time_LR=time.time()\n","from sklearn.linear_model import LogisticRegression\n","penalty_LR1 = ['l1', 'l2']\n","solver_LR1 = ['liblinear']\n","C = [0.01, 0.1, 1, 10, 100]\n","# max_iter = [100, 200, 300]\n","\n","# solver_LR1 = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n","# multi_class_LR1 = ['auto', 'ovr', 'multinomial']\n","model_LR1 = LogisticRegression()\n","# grid_LR1 = dict(penalty = penalty_LR1, solver = solver_LR1, multi_class = multi_class_LR1)  \n","grid_LR1 = dict(penalty = penalty_LR1, solver = solver_LR1, C = C)  \n","federated_learning(1, model_LR1, grid_LR1, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_LR = time.time() - start_time_LR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":549103,"status":"ok","timestamp":1642397636533,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"tJ4_IjDEhqmM","outputId":"e711529c-4d14-452d-8a47-46d0e3f0c9d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.477079 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.481666, scores: [0.46373626 0.51025641 0.5513986  0.39165501 0.49128205]\n","On test set, Accuracy: 0.522764\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       0.67      1.00      0.80         2\n","           3       1.00      0.50      0.67         2\n","           4       0.00      0.00      0.00         2\n","           5       0.50      0.50      0.50         2\n","           6       0.50      1.00      0.67         2\n","           7       1.00      0.50      0.67         2\n","           8       0.67      1.00      0.80         2\n","           9       0.00      0.00      0.00         2\n","          10       0.33      0.50      0.40         2\n","          11       0.67      1.00      0.80         2\n","          12       0.50      0.50      0.50         2\n","          13       0.50      1.00      0.67         2\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         2\n","          16       1.00      0.50      0.67         2\n","          17       0.67      1.00      0.80         2\n","          18       0.00      0.00      0.00         2\n","          19       0.33      0.50      0.40         2\n","          20       0.25      0.50      0.33         2\n","          21       0.00      0.00      0.00         2\n","          22       0.67      1.00      0.80         2\n","          23       1.00      1.00      1.00         2\n","          24       1.00      0.50      0.67         4\n","          25       0.00      0.00      0.00         4\n","          26       0.40      0.50      0.44         4\n","          27       0.67      1.00      0.80         2\n","          28       0.50      0.50      0.50         2\n","          29       1.00      1.00      1.00         2\n","          30       0.80      1.00      0.89         4\n","          31       0.00      0.00      0.00         2\n","          32       0.60      0.75      0.67         4\n","          33       0.00      0.00      0.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.50      1.00      0.67         2\n","\n","    accuracy                           0.57        82\n","   macro avg       0.52      0.58      0.52        82\n","weighted avg       0.52      0.57      0.52        82\n","\n","FPR: 0.012224\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.369502 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.373042, scores: [0.48422619 0.35099206 0.39240122 0.41134752 0.22624113]\n","On test set, Accuracy: 0.448442\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.50      0.50         2\n","           1       1.00      1.00      1.00         2\n","           2       0.00      0.00      0.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      0.50      0.67         2\n","           5       1.00      0.50      0.67         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      0.50      0.67         2\n","           8       0.50      0.50      0.50         2\n","          12       1.00      1.00      1.00         2\n","          13       0.00      0.00      0.00         2\n","          14       0.67      1.00      0.80         2\n","          15       0.00      0.00      0.00         2\n","          16       0.00      0.00      0.00         2\n","          17       0.20      0.50      0.29         2\n","          24       0.00      0.00      0.00         2\n","          25       0.50      0.50      0.50         2\n","          26       0.00      0.00      0.00         2\n","          30       0.50      0.50      0.50         2\n","          31       0.00      0.00      0.00         2\n","          32       0.00      0.00      0.00         2\n","          36       0.00      0.00      0.00         2\n","          37       0.11      0.50      0.18         2\n","          38       0.33      0.50      0.40         2\n","          39       0.20      0.50      0.29         2\n","          40       0.00      0.00      0.00         2\n","          41       0.50      0.50      0.50         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.47        60\n","   macro avg       0.47      0.47      0.45        60\n","weighted avg       0.47      0.47      0.45        60\n","\n","FPR: 0.018391\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.461066 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.461066, scores: [0.51111111 0.42142857 0.48639456 0.26734694 0.61904762]\n","On test set, Accuracy: 0.540741\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      0.50      0.67         2\n","           2       1.00      0.50      0.67         2\n","           9       0.00      0.00      0.00         2\n","          10       0.25      0.50      0.33         2\n","          11       0.33      0.50      0.40         2\n","          33       0.67      1.00      0.80         2\n","          34       0.50      0.50      0.50         2\n","          35       0.50      0.50      0.50         2\n","\n","    accuracy                           0.56        18\n","   macro avg       0.58      0.56      0.54        18\n","weighted avg       0.58      0.56      0.54        18\n","\n","FPR: 0.055556\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.350340 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.354216, scores: [0.41085271 0.45277358 0.28100775 0.31317829 0.31326531]\n","On test set, Accuracy: 0.316402\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.50      0.67         2\n","           1       0.00      0.00      0.00         2\n","           2       0.33      0.50      0.40         2\n","           3       0.50      1.00      0.67         2\n","           4       0.50      1.00      0.67         2\n","           5       0.50      0.50      0.50         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       0.50      0.50      0.50         2\n","          13       0.00      0.00      0.00         2\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         2\n","          16       0.40      1.00      0.57         2\n","          17       0.00      0.00      0.00         2\n","          24       0.00      0.00      0.00         4\n","          25       0.33      0.25      0.29         4\n","          26       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00         4\n","          31       0.50      0.50      0.50         4\n","          32       0.00      0.00      0.00         4\n","\n","    accuracy                           0.35        54\n","   macro avg       0.36      0.42      0.37        54\n","weighted avg       0.31      0.35      0.32        54\n","\n","FPR: 0.032784\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.418393 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.414313, scores: [0.36767677 0.35909091 0.36262626 0.47134986 0.51082251]\n","On test set, Accuracy: 0.422751\n","              precision    recall  f1-score   support\n","\n","           0       0.67      1.00      0.80         2\n","           1       1.00      0.50      0.67         2\n","           2       0.50      0.50      0.50         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      0.50      0.67         2\n","          14       0.67      1.00      0.80         2\n","          24       0.00      0.00      0.00         4\n","          25       0.12      0.25      0.17         4\n","          26       0.20      0.25      0.22         4\n","          30       0.50      0.25      0.33         4\n","          31       0.00      0.00      0.00         4\n","          32       0.00      0.00      0.00         4\n","\n","    accuracy                           0.43        42\n","   macro avg       0.58      0.55      0.54        42\n","weighted avg       0.45      0.43      0.42        42\n","\n","FPR: 0.041842\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.784667 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.784667, scores: [0.6        0.78666667 0.78666667 1.         0.75      ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.420278 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.419444, scores: [0.46944444 0.36111111 0.35972222 0.34722222 0.55972222]\n","On test set, Accuracy: 0.365714\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67         2\n","           1       1.00      0.50      0.67         2\n","           2       0.67      1.00      0.80         2\n","           6       0.00      0.00      0.00         2\n","           7       0.20      0.50      0.29         2\n","           8       0.00      0.00      0.00         2\n","           9       0.33      0.50      0.40         2\n","          10       0.00      0.00      0.00         2\n","          11       1.00      0.50      0.67         2\n","          15       0.00      0.00      0.00         2\n","          16       0.00      0.00      0.00         2\n","          17       0.50      0.50      0.50         2\n","          33       1.00      1.00      1.00         2\n","          34       0.00      0.00      0.00         2\n","          35       0.50      0.50      0.50         2\n","\n","    accuracy                           0.40        30\n","   macro avg       0.38      0.40      0.37        30\n","weighted avg       0.38      0.40      0.37        30\n","\n","FPR: 0.042857\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.255525 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.263808, scores: [0.15323565 0.30177045 0.23659148 0.36679198 0.26065163]\n","On test set, Accuracy: 0.391667\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.50      0.50         2\n","           1       1.00      0.50      0.67         2\n","           2       0.25      0.50      0.33         2\n","           3       0.00      0.00      0.00         2\n","           4       0.00      0.00      0.00         2\n","           5       1.00      0.50      0.67         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      0.50      0.67         2\n","          12       0.67      1.00      0.80         2\n","          13       0.33      0.50      0.40         2\n","          14       0.33      0.50      0.40         2\n","          24       0.00      0.00      0.00         4\n","          25       0.50      0.25      0.33         4\n","          26       0.50      0.50      0.50         4\n","          30       0.17      0.50      0.25         4\n","          31       0.00      0.00      0.00         4\n","          32       0.50      0.50      0.50         4\n","\n","    accuracy                           0.42        48\n","   macro avg       0.47      0.46      0.43        48\n","weighted avg       0.42      0.42      0.39        48\n","\n","FPR: 0.034695\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.375752 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.399292, scores: [0.42298851 0.41133005 0.26970443 0.42560568 0.46683375]\n","On test set, Accuracy: 0.323593\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         2\n","           1       0.00      0.00      0.00         2\n","           2       0.00      0.00      0.00         2\n","           3       0.00      0.00      0.00         2\n","           4       0.00      0.00      0.00         2\n","           5       0.00      0.00      0.00         2\n","           6       0.25      0.50      0.33         2\n","           7       0.50      0.50      0.50         2\n","           8       1.00      0.50      0.67         2\n","           9       0.67      1.00      0.80         2\n","          10       0.67      1.00      0.80         2\n","          11       1.00      0.50      0.67         2\n","          12       0.00      0.00      0.00         2\n","          13       0.00      0.00      0.00         2\n","          14       0.00      0.00      0.00         2\n","          24       1.00      0.75      0.86         4\n","          25       0.00      0.00      0.00         4\n","          26       0.50      0.75      0.60         4\n","          30       0.00      0.00      0.00         4\n","          31       0.00      0.00      0.00         4\n","          32       0.33      0.25      0.29         4\n","          36       0.00      0.00      0.00         2\n","          37       0.33      0.50      0.40         2\n","          38       0.00      0.00      0.00         2\n","          39       0.50      0.50      0.50         2\n","          40       0.67      1.00      0.80         2\n","          41       1.00      0.50      0.67         2\n","          42       1.00      1.00      1.00         2\n","          43       0.22      1.00      0.36         2\n","          44       1.00      0.50      0.67         2\n","\n","    accuracy                           0.35        72\n","   macro avg       0.35      0.36      0.33        72\n","weighted avg       0.35      0.35      0.32        72\n","\n","FPR: 0.022563\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.414895 using {'C': 22, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.422892, scores: [0.32160279 0.42       0.32285714 0.50166667 0.54833333]\n","On test set, Accuracy: 0.623343\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.50      0.67         2\n","           1       0.50      0.50      0.50         2\n","           2       0.00      0.00      0.00         2\n","           3       0.00      0.00      0.00         2\n","           4       0.25      0.50      0.33         2\n","           5       1.00      0.50      0.67         2\n","          12       1.00      1.00      1.00         2\n","          13       0.00      0.00      0.00         2\n","          14       0.33      1.00      0.50         2\n","          24       0.75      1.00      0.86         3\n","          25       0.67      0.50      0.57         4\n","          26       1.00      0.50      0.67         2\n","          30       1.00      1.00      1.00         2\n","          31       1.00      1.00      1.00         2\n","          32       0.67      1.00      0.80         2\n","          36       0.67      1.00      0.80         2\n","          37       1.00      0.50      0.67         2\n","          38       1.00      1.00      1.00         2\n","          39       0.00      0.00      0.00         2\n","          40       0.33      0.50      0.40         2\n","          41       1.00      0.50      0.67         2\n","          42       1.00      1.00      1.00         2\n","          43       0.67      1.00      0.80         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.65        51\n","   macro avg       0.66      0.65      0.62        51\n","weighted avg       0.66      0.65      0.62        51\n","\n","FPR: 0.015360\n","================================================================================\n","Federated Learning: Round: 2, Accuracy: 0.495542, FPR: 0.027627\n","Time taken to run Federated Learning with Logistic Regression as initial model =  183.25239129066466 seconds\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["start_time_LR2=time.time()\n","# penalty_LR2 = ['l1']\n","# solver_LR2 = ['liblinear']\n","# multi_class_LR2 = ['auto']\n","model_LR2 = LogisticRegression()\n","penalty_LR1 = ['l1']\n","solver_LR1 = ['liblinear']\n","C = [22]\n","# grid_LR2 = dict(penalty = penalty_LR2, solver = solver_LR2, multi_class = multi_class_LR2) \n","grid_LR2 = dict(penalty = penalty_LR1, solver = solver_LR1, C = C) \n","federated_learning(2, model_LR2, grid_LR2, cv,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_LR2 = time.time() - start_time_LR2 + elapsed_time_LR\n","print(\"Time taken to run Federated Learning with Logistic Regression as initial model = \", elapsed_time_LR2/10, \"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"3_Wqd6M6FF2E"},"source":["### FL Group: attack type"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":703532,"status":"ok","timestamp":1642398342277,"user":{"displayName":"Zhang Nikki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5xTno-XzABIPMYD_zfylMEkYhlUvhBmV3t_S1=s64","userId":"17298851517668756572"},"user_tz":-660},"id":"hUg8S6DZFI-z","outputId":"5d5e42ce-2349-4e04-fdc3-abaa5c3474d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\n","0 Device: Samsung Smart Cam, MAC addresses: 00:16:6c:ab:6b:88\n","y_train      index  AttackType\n","0      25    4.923077\n","1      32    4.923077\n","2      30    4.923077\n","3      26    4.923077\n","4      24    4.923077\n","5       6    2.461538\n","6      12    2.461538\n","7      11    2.461538\n","8      10    2.461538\n","9       9    2.461538\n","10      8    2.461538\n","11      7    2.461538\n","12     35    2.461538\n","13     14    2.461538\n","14      5    2.461538\n","15      4    2.461538\n","16      3    2.461538\n","17      2    2.461538\n","18      1    2.461538\n","19     13    2.461538\n","20     17    2.461538\n","21     15    2.461538\n","22     16    2.461538\n","23     34    2.461538\n","24     19    2.461538\n","25     20    2.461538\n","26     21    2.461538\n","27     22    2.461538\n","28     23    2.461538\n","29     27    2.461538\n","30     28    2.461538\n","31     29    2.461538\n","32     31    2.461538\n","33     33    2.461538\n","34      0    2.461538\n","35     18    1.538462\n","y_test      index  AttackType\n","0      25    4.878049\n","1      32    4.878049\n","2      30    4.878049\n","3      26    4.878049\n","4      24    4.878049\n","5       6    2.439024\n","6      12    2.439024\n","7      11    2.439024\n","8      10    2.439024\n","9       9    2.439024\n","10      8    2.439024\n","11      7    2.439024\n","12     35    2.439024\n","13     14    2.439024\n","14      5    2.439024\n","15      4    2.439024\n","16      3    2.439024\n","17      2    2.439024\n","18      1    2.439024\n","19     13    2.439024\n","20     17    2.439024\n","21     15    2.439024\n","22     16    2.439024\n","23     34    2.439024\n","24     18    2.439024\n","25     19    2.439024\n","26     20    2.439024\n","27     21    2.439024\n","28     22    2.439024\n","29     23    2.439024\n","30     27    2.439024\n","31     28    2.439024\n","32     29    2.439024\n","33     31    2.439024\n","34     33    2.439024\n","35      0    2.439024\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.455056 using {'C': 50, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.477446, scores: [0.46886447 0.49871795 0.55480519 0.37355977 0.49128205]\n","On test set, Accuracy: 0.539295\n","              precision    recall  f1-score   support\n","\n","           0       0.67      1.00      0.80         2\n","           1       0.67      1.00      0.80         2\n","           2       1.00      0.50      0.67         2\n","           3       1.00      0.50      0.67         2\n","           4       0.00      0.00      0.00         2\n","           5       0.50      0.50      0.50         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      0.50      0.67         2\n","           8       0.67      1.00      0.80         2\n","           9       0.00      0.00      0.00         2\n","          10       0.33      0.50      0.40         2\n","          11       0.67      1.00      0.80         2\n","          12       0.50      0.50      0.50         2\n","          13       0.50      1.00      0.67         2\n","          14       0.00      0.00      0.00         2\n","          15       0.50      0.50      0.50         2\n","          16       1.00      0.50      0.67         2\n","          17       0.67      1.00      0.80         2\n","          18       0.00      0.00      0.00         2\n","          19       0.33      0.50      0.40         2\n","          20       0.25      0.50      0.33         2\n","          21       0.00      0.00      0.00         2\n","          22       0.67      1.00      0.80         2\n","          23       1.00      1.00      1.00         2\n","          24       0.50      0.50      0.50         4\n","          25       0.50      0.50      0.50         4\n","          26       1.00      0.25      0.40         4\n","          27       0.67      1.00      0.80         2\n","          28       0.50      0.50      0.50         2\n","          29       1.00      1.00      1.00         2\n","          30       0.80      1.00      0.89         4\n","          31       0.00      0.00      0.00         2\n","          32       0.60      0.75      0.67         4\n","          33       0.00      0.00      0.00         2\n","          34       1.00      0.50      0.67         2\n","          35       0.50      1.00      0.67         2\n","\n","    accuracy                           0.59        82\n","   macro avg       0.55      0.58      0.53        82\n","weighted avg       0.56      0.59      0.54        82\n","\n","FPR: 0.011868\n","================================================================================\n","1 Device: Phillip Hue Lightbulb, MAC addresses: 00:17:88:2b:9a:25\n","y_train      index  AttackType\n","0      44    3.375527\n","1      43    3.375527\n","2       1    3.375527\n","3       2    3.375527\n","4       3    3.375527\n","5       4    3.375527\n","6       5    3.375527\n","7       6    3.375527\n","8       7    3.375527\n","9       8    3.375527\n","10     12    3.375527\n","11     13    3.375527\n","12     15    3.375527\n","13     16    3.375527\n","14     17    3.375527\n","15     24    3.375527\n","16     25    3.375527\n","17     26    3.375527\n","18     30    3.375527\n","19     32    3.375527\n","20     37    3.375527\n","21     38    3.375527\n","22     39    3.375527\n","23     40    3.375527\n","24     41    3.375527\n","25     42    3.375527\n","26      0    3.375527\n","27     14    2.953586\n","28     31    2.953586\n","29     36    2.953586\n","y_test      index  AttackType\n","0      44    3.333333\n","1      43    3.333333\n","2       1    3.333333\n","3       2    3.333333\n","4       3    3.333333\n","5       4    3.333333\n","6       5    3.333333\n","7       6    3.333333\n","8       7    3.333333\n","9       8    3.333333\n","10     12    3.333333\n","11     13    3.333333\n","12     14    3.333333\n","13     15    3.333333\n","14     16    3.333333\n","15     17    3.333333\n","16     24    3.333333\n","17     25    3.333333\n","18     26    3.333333\n","19     30    3.333333\n","20     31    3.333333\n","21     32    3.333333\n","22     36    3.333333\n","23     37    3.333333\n","24     38    3.333333\n","25     39    3.333333\n","26     40    3.333333\n","27     41    3.333333\n","28     42    3.333333\n","29      0    3.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.340471 using {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.373089, scores: [0.45416667 0.41269841 0.36099291 0.41134752 0.22624113]\n","On test set, Accuracy: 0.525714\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.50      0.50         2\n","           1       1.00      1.00      1.00         2\n","           2       0.00      0.00      0.00         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      0.50      0.67         2\n","           5       1.00      0.50      0.67         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      0.50      0.67         2\n","           8       0.50      0.50      0.50         2\n","          12       1.00      1.00      1.00         2\n","          13       0.00      0.00      0.00         2\n","          14       0.67      1.00      0.80         2\n","          15       0.00      0.00      0.00         2\n","          16       0.00      0.00      0.00         2\n","          17       0.20      0.50      0.29         2\n","          24       0.67      1.00      0.80         2\n","          25       0.50      0.50      0.50         2\n","          26       0.67      1.00      0.80         2\n","          30       0.33      0.50      0.40         2\n","          31       0.50      0.50      0.50         2\n","          32       0.00      0.00      0.00         2\n","          36       0.00      0.00      0.00         2\n","          37       0.50      0.50      0.50         2\n","          38       0.33      0.50      0.40         2\n","          39       0.20      0.50      0.29         2\n","          40       0.00      0.00      0.00         2\n","          41       0.50      0.50      0.50         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.55        60\n","   macro avg       0.54      0.55      0.53        60\n","weighted avg       0.54      0.55      0.53        60\n","\n","FPR: 0.015517\n","================================================================================\n","2 Device: Amazon Echo, MAC addresses: 44:65:0d:56:cc:d3\n","y_train     index  AttackType\n","0     35   11.267606\n","1     33   11.267606\n","2     11   11.267606\n","3     10   11.267606\n","4      9   11.267606\n","5      2   11.267606\n","6      1   11.267606\n","7      0   11.267606\n","8     34    9.859155\n","y_test     index  AttackType\n","0      2   11.111111\n","1     33   11.111111\n","2     11   11.111111\n","3     10   11.111111\n","4      9   11.111111\n","5     35   11.111111\n","6     34   11.111111\n","7      1   11.111111\n","8      0   11.111111\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.545460 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.552571, scores: [0.38666667 0.51190476 0.67619048 0.73809524 0.45      ]\n","On test set, Accuracy: 0.578307\n","              precision    recall  f1-score   support\n","\n","           0       0.40      1.00      0.57         2\n","           1       1.00      0.50      0.67         2\n","           2       0.00      0.00      0.00         2\n","           9       1.00      0.50      0.67         2\n","          10       1.00      0.50      0.67         2\n","          11       0.50      1.00      0.67         2\n","          33       0.67      1.00      0.80         2\n","          34       0.50      0.50      0.50         2\n","          35       1.00      0.50      0.67         2\n","\n","    accuracy                           0.61        18\n","   macro avg       0.67      0.61      0.58        18\n","weighted avg       0.67      0.61      0.58        18\n","\n","FPR: 0.048611\n","================================================================================\n","3 Device: TP-Link Plug, MAC addresses: 50:c7:bf:00:56:39\n","y_train      index  AttackType\n","0      30    7.476636\n","1      26    7.476636\n","2      25    7.476636\n","3      24    7.476636\n","4      31    7.476636\n","5      32    7.009346\n","6       7    3.738318\n","7       1    3.738318\n","8       2    3.738318\n","9       3    3.738318\n","10      4    3.738318\n","11      5    3.738318\n","12      6    3.738318\n","13     13    3.738318\n","14      8    3.738318\n","15     12    3.738318\n","16     15    3.738318\n","17     16    3.738318\n","18     17    3.738318\n","19      0    3.738318\n","20     14    3.271028\n","y_test      index  AttackType\n","0      32    7.407407\n","1      30    7.407407\n","2      26    7.407407\n","3      25    7.407407\n","4      24    7.407407\n","5      31    7.407407\n","6       7    3.703704\n","7       1    3.703704\n","8       2    3.703704\n","9       3    3.703704\n","10      4    3.703704\n","11      5    3.703704\n","12      6    3.703704\n","13     13    3.703704\n","14      8    3.703704\n","15     12    3.703704\n","16     14    3.703704\n","17     15    3.703704\n","18     16    3.703704\n","19     17    3.703704\n","20      0    3.703704\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.357161 using {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.345825, scores: [0.40310078 0.44114568 0.26550388 0.31007752 0.30929705]\n","On test set, Accuracy: 0.300529\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.50      0.67         2\n","           1       0.00      0.00      0.00         2\n","           2       0.33      0.50      0.40         2\n","           3       0.50      1.00      0.67         2\n","           4       0.50      1.00      0.67         2\n","           5       0.50      0.50      0.50         2\n","           6       1.00      1.00      1.00         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      1.00      1.00         2\n","          12       0.50      0.50      0.50         2\n","          13       0.00      0.00      0.00         2\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         2\n","          16       0.40      1.00      0.57         2\n","          17       0.00      0.00      0.00         2\n","          24       0.00      0.00      0.00         4\n","          25       0.33      0.25      0.29         4\n","          26       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00         4\n","          31       0.33      0.25      0.29         4\n","          32       0.00      0.00      0.00         4\n","\n","    accuracy                           0.33        54\n","   macro avg       0.35      0.40      0.36        54\n","weighted avg       0.30      0.33      0.30        54\n","\n","FPR: 0.033736\n","================================================================================\n","4 Device: Netatmo Camera, MAC addresses: 70:ee:50:18:34:43\n","y_train      index  AttackType\n","0      32    9.696970\n","1      31    9.696970\n","2      30    9.696970\n","3      26    9.696970\n","4      25    9.696970\n","5      24    9.696970\n","6      14    4.848485\n","7      13    4.848485\n","8      12    4.848485\n","9       5    4.848485\n","10      4    4.848485\n","11      3    4.848485\n","12      2    4.848485\n","13      1    4.848485\n","14      0    3.030303\n","y_test      index  AttackType\n","0      32    9.523810\n","1      31    9.523810\n","2      30    9.523810\n","3      26    9.523810\n","4      25    9.523810\n","5      24    9.523810\n","6      14    4.761905\n","7      13    4.761905\n","8      12    4.761905\n","9       5    4.761905\n","10      4    4.761905\n","11      3    4.761905\n","12      2    4.761905\n","13      1    4.761905\n","14      0    4.761905\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.394969 using {'C': 50, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.408033, scores: [0.32698413 0.4004329  0.37777778 0.43944204 0.4955267 ]\n","On test set, Accuracy: 0.430241\n","              precision    recall  f1-score   support\n","\n","           0       0.67      1.00      0.80         2\n","           1       1.00      0.50      0.67         2\n","           2       0.50      0.50      0.50         2\n","           3       1.00      1.00      1.00         2\n","           4       1.00      1.00      1.00         2\n","           5       1.00      1.00      1.00         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      0.50      0.67         2\n","          14       0.67      1.00      0.80         2\n","          24       0.00      0.00      0.00         4\n","          25       0.00      0.00      0.00         4\n","          26       0.14      0.25      0.18         4\n","          30       0.50      0.25      0.33         4\n","          31       0.33      0.25      0.29         4\n","          32       0.00      0.00      0.00         4\n","\n","    accuracy                           0.43        42\n","   macro avg       0.59      0.55      0.55        42\n","weighted avg       0.47      0.43      0.43        42\n","\n","FPR: 0.041842\n","================================================================================\n","5 Device: iHome PowerPlug, MAC addresses: 74:c6:3b:29:d7:1d\n","y_train     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n","y_test     index  AttackType\n","0      2   33.333333\n","1      1   33.333333\n","2      0   33.333333\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.784667 using {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.784667, scores: [0.6        0.78666667 0.78666667 1.         0.75      ]\n","On test set, Accuracy: 1.000000\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       1.00      1.00      1.00         2\n","           2       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00         6\n","   macro avg       1.00      1.00      1.00         6\n","weighted avg       1.00      1.00      1.00         6\n","\n","FPR: 0.000000\n","================================================================================\n","6 Device: LiFX Bulb, MAC addresses: d0:73:d5:01:83:08\n","y_train      index  AttackType\n","0      35    6.666667\n","1      34    6.666667\n","2      33    6.666667\n","3      17    6.666667\n","4      16    6.666667\n","5      15    6.666667\n","6      11    6.666667\n","7      10    6.666667\n","8       9    6.666667\n","9       8    6.666667\n","10      7    6.666667\n","11      6    6.666667\n","12      2    6.666667\n","13      1    6.666667\n","14      0    6.666667\n","y_test      index  AttackType\n","0       2    6.666667\n","1      17    6.666667\n","2      16    6.666667\n","3      15    6.666667\n","4      33    6.666667\n","5      11    6.666667\n","6      10    6.666667\n","7       9    6.666667\n","8       8    6.666667\n","9       7    6.666667\n","10      6    6.666667\n","11     35    6.666667\n","12     34    6.666667\n","13      1    6.666667\n","14      0    6.666667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.427817 using {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.423056, scores: [0.46944444 0.36111111 0.37777778 0.34722222 0.55972222]\n","On test set, Accuracy: 0.365714\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67         2\n","           1       1.00      0.50      0.67         2\n","           2       0.67      1.00      0.80         2\n","           6       0.00      0.00      0.00         2\n","           7       0.20      0.50      0.29         2\n","           8       0.00      0.00      0.00         2\n","           9       0.33      0.50      0.40         2\n","          10       0.00      0.00      0.00         2\n","          11       1.00      0.50      0.67         2\n","          15       0.00      0.00      0.00         2\n","          16       0.00      0.00      0.00         2\n","          17       0.50      0.50      0.50         2\n","          33       1.00      1.00      1.00         2\n","          34       0.00      0.00      0.00         2\n","          35       0.50      0.50      0.50         2\n","\n","    accuracy                           0.40        30\n","   macro avg       0.38      0.40      0.37        30\n","weighted avg       0.38      0.40      0.37        30\n","\n","FPR: 0.042857\n","================================================================================\n","7 Device: Belkin Switch, MAC addresses: ec:1a:59:79:f4:89\n","y_train      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n","y_test      index  AttackType\n","0      32    8.333333\n","1      30    8.333333\n","2      26    8.333333\n","3      25    8.333333\n","4      24    8.333333\n","5      31    8.333333\n","6       5    4.166667\n","7       1    4.166667\n","8       2    4.166667\n","9       3    4.166667\n","10      4    4.166667\n","11      8    4.166667\n","12      6    4.166667\n","13      7    4.166667\n","14     12    4.166667\n","15     13    4.166667\n","16     14    4.166667\n","17      0    4.166667\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.255846 using {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.262327, scores: [0.17521368 0.30177045 0.2335213  0.34047619 0.26065163]\n","On test set, Accuracy: 0.391667\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.50      0.50         2\n","           1       1.00      0.50      0.67         2\n","           2       0.25      0.50      0.33         2\n","           3       0.00      0.00      0.00         2\n","           4       0.00      0.00      0.00         2\n","           5       1.00      0.50      0.67         2\n","           6       0.67      1.00      0.80         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      0.50      0.67         2\n","          12       0.67      1.00      0.80         2\n","          13       0.33      0.50      0.40         2\n","          14       0.33      0.50      0.40         2\n","          24       0.00      0.00      0.00         4\n","          25       0.50      0.25      0.33         4\n","          26       0.50      0.50      0.50         4\n","          30       0.17      0.50      0.25         4\n","          31       0.00      0.00      0.00         4\n","          32       0.50      0.50      0.50         4\n","\n","    accuracy                           0.42        48\n","   macro avg       0.47      0.46      0.43        48\n","weighted avg       0.42      0.42      0.39        48\n","\n","FPR: 0.034695\n","================================================================================\n","8 Device: Belkin Motion Sensor, MAC addresses: ec:1a:59:83:28:11\n","y_train      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n","y_test      index  AttackType\n","0      32    5.555556\n","1      24    5.555556\n","2      25    5.555556\n","3      26    5.555556\n","4      30    5.555556\n","5      31    5.555556\n","6      11    2.777778\n","7       9    2.777778\n","8       8    2.777778\n","9      44    2.777778\n","10      7    2.777778\n","11      6    2.777778\n","12      5    2.777778\n","13      4    2.777778\n","14      3    2.777778\n","15      2    2.777778\n","16      1    2.777778\n","17     10    2.777778\n","18     14    2.777778\n","19     12    2.777778\n","20     13    2.777778\n","21     43    2.777778\n","22     36    2.777778\n","23     37    2.777778\n","24     38    2.777778\n","25     39    2.777778\n","26     40    2.777778\n","27     41    2.777778\n","28     42    2.777778\n","29      0    2.777778\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.398004 using {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.382229, scores: [0.36986864 0.41789819 0.26970443 0.4109858  0.44269006]\n","On test set, Accuracy: 0.390917\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67         2\n","           1       0.00      0.00      0.00         2\n","           2       1.00      0.50      0.67         2\n","           3       0.00      0.00      0.00         2\n","           4       0.00      0.00      0.00         2\n","           5       0.00      0.00      0.00         2\n","           6       0.33      0.50      0.40         2\n","           7       0.50      0.50      0.50         2\n","           8       1.00      0.50      0.67         2\n","           9       1.00      1.00      1.00         2\n","          10       0.67      1.00      0.80         2\n","          11       1.00      0.50      0.67         2\n","          12       0.00      0.00      0.00         2\n","          13       0.00      0.00      0.00         2\n","          14       0.00      0.00      0.00         2\n","          24       1.00      0.75      0.86         4\n","          25       0.25      0.25      0.25         4\n","          26       0.67      0.50      0.57         4\n","          30       0.00      0.00      0.00         4\n","          31       0.00      0.00      0.00         4\n","          32       0.33      0.25      0.29         4\n","          36       0.00      0.00      0.00         2\n","          37       0.33      0.50      0.40         2\n","          38       0.00      0.00      0.00         2\n","          39       0.67      1.00      0.80         2\n","          40       0.67      1.00      0.80         2\n","          41       1.00      0.50      0.67         2\n","          42       1.00      1.00      1.00         2\n","          43       0.29      1.00      0.44         2\n","          44       1.00      0.50      0.67         2\n","\n","    accuracy                           0.40        72\n","   macro avg       0.44      0.42      0.40        72\n","weighted avg       0.43      0.40      0.39        72\n","\n","FPR: 0.020644\n","================================================================================\n","9 Device: Chromcast, MAC addresses: F4:F5:D8:8F:0A:3C\n","y_train      index  AttackType\n","0      25    7.960199\n","1      42    4.477612\n","2      44    3.980100\n","3       1    3.980100\n","4       2    3.980100\n","5       3    3.980100\n","6       4    3.980100\n","7       5    3.980100\n","8      12    3.980100\n","9      13    3.980100\n","10     14    3.980100\n","11     24    3.980100\n","12     26    3.980100\n","13     43    3.980100\n","14     30    3.980100\n","15     31    3.980100\n","16     32    3.980100\n","17     36    3.980100\n","18     37    3.980100\n","19     38    3.980100\n","20     39    3.980100\n","21     40    3.980100\n","22     41    3.980100\n","23      0    3.980100\n","y_test      index  AttackType\n","0      25    7.843137\n","1      24    5.882353\n","2      44    3.921569\n","3      43    3.921569\n","4       1    3.921569\n","5       2    3.921569\n","6       3    3.921569\n","7       4    3.921569\n","8       5    3.921569\n","9      12    3.921569\n","10     13    3.921569\n","11     14    3.921569\n","12     26    3.921569\n","13     30    3.921569\n","14     31    3.921569\n","15     32    3.921569\n","16     36    3.921569\n","17     37    3.921569\n","18     38    3.921569\n","19     39    3.921569\n","20     40    3.921569\n","21     41    3.921569\n","22     42    3.921569\n","23      0    3.921569\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Best: 0.494538 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"name":"stdout","output_type":"stream","text":["On all train set, mean of scores: 0.488668, scores: [0.38536585 0.48166667 0.47035714 0.60785714 0.49809524]\n","On test set, Accuracy: 0.678665\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.50      0.67         2\n","           1       0.33      0.50      0.40         2\n","           2       0.00      0.00      0.00         2\n","           3       1.00      0.50      0.67         2\n","           4       0.50      0.50      0.50         2\n","           5       0.50      0.50      0.50         2\n","          12       1.00      1.00      1.00         2\n","          13       1.00      1.00      1.00         2\n","          14       0.67      1.00      0.80         2\n","          24       0.60      1.00      0.75         3\n","          25       1.00      0.75      0.86         4\n","          26       1.00      0.50      0.67         2\n","          30       0.25      0.50      0.33         2\n","          31       0.67      1.00      0.80         2\n","          32       1.00      0.50      0.67         2\n","          36       0.67      1.00      0.80         2\n","          37       1.00      0.50      0.67         2\n","          38       1.00      1.00      1.00         2\n","          39       0.00      0.00      0.00         2\n","          40       0.00      0.00      0.00         2\n","          41       1.00      1.00      1.00         2\n","          42       1.00      1.00      1.00         2\n","          43       1.00      1.00      1.00         2\n","          44       1.00      1.00      1.00         2\n","\n","    accuracy                           0.69        51\n","   macro avg       0.72      0.68      0.67        51\n","weighted avg       0.72      0.69      0.68        51\n","\n","FPR: 0.013641\n","================================================================================\n","Camera group: Device 0 and Device 4, Accuracy: 0.484768\n","Appliances group: Device 9, Accuracy: 0.678665\n","Controller group: Device 2, Accuracy: 0.578307\n","Energy group: Device 1,3,5,6,7 and 8, Accuracy: 0.495757\n","Federated Group: Round: 2, Accuracy: 0.520105, FPR: 0.026341\n","Time taken to run Federated Learning with Logistic Regression as initial model =  198.79058549404144 seconds\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}],"source":["start_time_LR3 = time.time()\n","print(\"Centralized learning model aggregate the mean of the group parameters from locally trained models and start the second round\")\n","model_LR2 = model_camera = model_appliances = model_energy = model_controller = LogisticRegression()\n","cv_LR2 = cv_camera = cv_appliances = cv_energy = cv_controller = cv\n","\n","# 0, 4\n","penalty_camera = ['l1']\n","solver_camera = ['liblinear']\n","C = [50]\n","# multi_class_camera = ['auto']\n","# grid_camera = dict(penalty = penalty_camera, solver = solver_camera, multi_class = multi_class_camera)\n","grid_camera = dict(penalty = penalty_camera, solver = solver_camera, C = C)\n","# 9\n","penalty_appliances = ['l1']\n","solver_appliances = ['liblinear']\n","C = [0.01]\n","# multi_class_appliances = ['auto']\n","# grid_appliances = dict(penalty = penalty_appliances, solver = solver_appliances, multi_class = multi_class_appliances)\n","grid_appliances = dict(penalty = penalty_appliances, solver = solver_appliances, C = C)\n","# 1, 3, 5, 6, 7, 8\n","penalty_energy = ['l1']\n","solver_energy = ['liblinear']\n","# multi_class_energy = ['ovr']\n","C = [20]\n","# grid_energy = dict(penalty = penalty_energy, solver = solver_energy, multi_class = multi_class_energy)\n","grid_energy = dict(penalty = penalty_energy, solver = solver_energy, C = C)\n","# 2\n","penalty_controller = ['l1']\n","solver_controller = ['liblinear']\n","# multi_class_controller = ['auto']\n","C = [0.01]\n","# grid_controller = dict(penalty = penalty_controller, solver = solver_controller, multi_class = multi_class_controller)\n","grid_controller = dict(penalty = penalty_controller, solver = solver_controller, C = C)\n","federated_learning_group(2, model_camera, grid_camera, cv_camera,\n","                   model_appliances, grid_appliances, cv_appliances,\n","                   model_energy, grid_energy, cv_energy,\n","                   model_controller, grid_controller, cv_controller,\n","                   df_0_new, y_0_attacktype, df_1_new, y_1_attacktype, df_2_new, y_2_attacktype, df_3_new, y_3_attacktype, df_4_new, y_4_attacktype,\n","                   df_5_new, y_5_attacktype, df_6_new, y_6_attacktype, df_7_new, y_7_attacktype, df_8_new, y_8_attacktype, df_9_new, y_9_attacktype)\n","elapsed_time_LR3 = time.time() - start_time_LR3 + elapsed_time_LR\n","print(\"Time taken to run Federated Learning with Logistic Regression as initial model = \", elapsed_time_LR3/10, \"seconds\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPiNMAXqpbc28KXxo3KxOmB","machine_shape":"hm","name":"","toc_visible":true,"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
